# bot.py ‚Äî Memory Forever v0.4
# –®–∞–≥–∏: –°—é–∂–µ—Ç(—ã) ‚Üí –§–æ—Ä–º–∞—Ç ‚Üí –§–æ–Ω ‚Üí –ú—É–∑—ã–∫–∞ ‚Üí –§–æ—Ç–æ(1/2) ‚Üí Runway ‚Üí –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ (wm+audio+—Ç–∏—Ç—Ä) ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞
import os, io, time, uuid, base64, requests, subprocess, shutil, json
from datetime import datetime
from typing import List
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from PIL import ImageFilter

# rembg: –≥–¥–µ –ª–µ–∂–∞—Ç –º–æ–¥–µ–ª–∏ –∏ —Å–µ—Å—Å–∏–∏ –≤—ã—Ä–µ–∑–∫–∏
os.environ.setdefault("U2NET_HOME", os.path.join(os.getcwd(), "models"))
from rembg import remove, new_session
RMBG_SESSION = new_session("u2net")
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –≤–Ω—É—Ç—Ä–∏ smart_cutout)
RMBG_HUMAN = new_session("u2net_human_seg")
RMBG_ISNET  = new_session("isnet-general-use")

import telebot

# ---------- –ö–õ–Æ–ß–ò ----------
TG_TOKEN   = os.environ.get("TELEGRAM_BOT_TOKEN", "")
RUNWAY_KEY = os.environ.get("RUNWAY_API_KEY", "")
if not TG_TOKEN or not RUNWAY_KEY:
    print("‚ö†Ô∏è –ó–∞–¥–∞–π TELEGRAM_BOT_TOKEN –∏ RUNWAY_API_KEY –≤ Secrets.")
bot = telebot.TeleBot(TG_TOKEN, parse_mode="HTML")

# ---------- –†–ï–ñ–ò–ú–´/–û–¢–õ–ê–î–ö–ê (–±–µ–∑ OpenAI Assistants) ----------
# –≠—Ç–æ—Ç —Ñ–ª–∞–≥ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –æ–±—â–∏–π ¬´—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–æ–≥¬ª, –æ–Ω –ù–ï —Å–≤—è–∑–∞–Ω –±–æ–ª—å—à–µ —Å OpenAI.
OAI_DEBUG = os.environ.get("OAI_DEBUG", "0") == "1"   # –ø—Ä–æ—Å—Ç–æ —Ñ–ª–∞–≥ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –ª–æ–≥–∞
# –í–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–≤—å—é —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä–∞ –∏ –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–µ–¥ Runway)
PREVIEW_START_FRAME = os.environ.get("PREVIEW_START_FRAME", "0") == "1"  # 1 ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
DEBUG_TO_ADMIN      = os.environ.get("DEBUG_TO_ADMIN", "1") == "1"       # 1 ‚Äî —Å–ª–∞—Ç—å –ø—Ä–µ–≤—å—é –∞–¥–º–∏–Ω—É (–µ—Å–ª–∏ ADMIN_CHAT_ID –∑–∞–¥–∞–Ω)
RUNWAY_SEND_JPEG    = os.environ.get("RUNWAY_SEND_JPEG", "1") == "1"     # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä –≤ JPEG –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
START_OVERLAY_DEBUG = os.environ.get("START_OVERLAY_DEBUG", "0") == "1"  # —Ä–∏—Å–æ–≤–∞—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–º–∫–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ
MF_DEBUG            = OAI_DEBUG or (os.environ.get("MF_DEBUG", "0") == "1")

# –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∞–µ–º –ª—é–±—ã–µ ¬´–≤–æ—Ä–æ—Ç–∞/–ø—Ä–æ–≤–µ—Ä–∫–∏¬ª –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–∏ –Ω–∏–∂–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∏–≥–¥–µ)
ASSISTANT_GATE_ENABLED = False  # –∂—ë—Å—Ç–∫–æ OFF
# --- –û—Ç–ª–∞–¥–∫–∞/–ø—Ä–µ–≤—å—é (Assistant OpenAI —É–¥–∞–ª—ë–Ω) ---

def _safe_send_photo(chat_id: int, path: str, caption: str = ""):
    try:
        with open(path, "rb") as ph:
            bot.send_photo(chat_id, ph, caption=caption[:1024])
    except Exception as e:
        print(f"[DBG] send_photo error: {e}")

def _send_debug_preview(uid: int, scene_key: str, start_path: str, prompt: str, gate: dict | None = None):
    """
    –ü—Ä–µ–≤—å—é —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä–∞ –∏ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–æ–º–ø—Ç–∞.
    –ü–∞—Ä–∞–º–µ—Ç—Ä gate –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –≤—ã–∑–æ–≤–∞–º–∏,
    –Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è (–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –≤—ã–∫–ª—é—á–µ–Ω).
    """
    cap = (
        f"üéØ PREVIEW ‚Üí {scene_key}\n"
        f"prompt[{len(prompt)}]: {prompt[:500]}{'‚Ä¶' if len(prompt) > 500 else ''}\n"
        f"gate: disabled"
    )
    if PREVIEW_START_FRAME:
        _safe_send_photo(uid, start_path, cap)
    if DEBUG_TO_ADMIN and ADMIN_CHAT_ID:
        try:
            _safe_send_photo(int(ADMIN_CHAT_ID), start_path, f"[uid {uid}] {cap}")
        except Exception as e:
            print(f"[DBG] admin preview err: {e}")

def _is_admin(uid: int) -> bool:
    try:
        return ADMIN_CHAT_ID and str(uid) == str(int(ADMIN_CHAT_ID))
    except Exception:
        return False

# --- –ê–¥–º–∏–Ω –¥–ª—è —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ (ID —á–∞—Ç–∞/–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è/–≥—Ä—É–ø–ø—ã) ---
# –ü—Ä–∏–º–µ—Ä: "123456789" –¥–ª—è —é–∑–µ—Ä–∞, "-1001234567890" –¥–ª—è —Å—É–ø–µ—Ä–≥—Ä—É–ø–ø—ã.
_raw_admin = os.environ.get("ADMIN_CHAT_ID", "").strip()
ADMIN_CHAT_ID = int(_raw_admin) if _raw_admin.lstrip("-").isdigit() else None  # None, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

# --- –¢–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é ---
BTN_MENU_MAIN    = "üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
BTN_MENU_START   = "üé¨ –°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ"
BTN_MENU_PRICE   = "üí≤ –°—Ç–æ–∏–º–æ—Å—Ç—å"
BTN_MENU_SUPPORT = "üõü –¢–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞"
BTN_MENU_GUIDE   = "üìò –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ"
BTN_MENU_DEMO    = "üéû –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç"

# –ö–Ω–æ–ø–∫–∞ ¬´–¥–æ–º–æ–π¬ª –¥–ª—è –≤—Å–µ—Ö —à–∞–≥–æ–≤ –º–∞—Å—Ç–µ—Ä–∞
BTN_GO_HOME = "üè† –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"

def kb_main_menu() -> telebot.types.ReplyKeyboardMarkup:
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2, selective=True)
    kb.add(
        telebot.types.KeyboardButton(BTN_MENU_MAIN),
        telebot.types.KeyboardButton(BTN_MENU_START),
    )
    kb.add(
        telebot.types.KeyboardButton(BTN_MENU_PRICE),
        telebot.types.KeyboardButton(BTN_MENU_SUPPORT),
    )
    kb.add(
        telebot.types.KeyboardButton(BTN_MENU_GUIDE),
        telebot.types.KeyboardButton(BTN_MENU_DEMO),
    )
    return kb

def show_main_menu(uid: int, text: str | None = None) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é."""
    text = text or "–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ, –Ω–∞–∂–∞–≤ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª."
    try:
        bot.send_message(uid, text, reply_markup=kb_main_menu())
    except Exception as e:
        # –Ω–µ –ø–∞–¥–∞–µ–º –∏–∑-–∑–∞ —Ç–µ–ª–µ–≥—Ä–∞–º-–æ—à–∏–±–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–∫–ª—é—á–∏–ª –±–æ—Ç–∞)
        print(f"[WARN] show_main_menu({uid}) failed: {e}")

# ---------- –ü–ê–ü–ö–ò ----------
os.makedirs("uploads",  exist_ok=True)
os.makedirs("renders",  exist_ok=True)
os.makedirs("assets",   exist_ok=True)
os.makedirs("audio",    exist_ok=True)
WATERMARK_PATH = "assets/watermark_black.jpg"

# ---------- –°–¶–ï–ù–´ / –§–û–†–ú–ê–¢–´ / –§–û–ù–´ / –ú–£–ó–´–ö–ê ----------
SCENES = {
    "ü´Ç –û–±—ä—è—Ç–∏—è 5—Å - –ë–ï–°–ü–õ–ê–¢–ù–û":      {"duration": 5,  "kind": "hug",         "people": 2},
    "ü´Ç –û–±—ä—è—Ç–∏—è 10—Å - 100 —Ä—É–±–ª–µ–π":    {"duration": 10, "kind": "hug",         "people": 2},
    "üíè –ü–æ—Ü–µ–ª—É–π 10—Å - 100 —Ä—É–±–ª–µ–π":    {"duration": 10, "kind": "kiss_cheek",  "people": 2},
    "üëã –ü—Ä–æ—â–∞–Ω–∏–µ 10—Å - 100 —Ä—É–±–ª–µ–π":   {"duration": 10, "kind": "wave",        "people": 1},
    "ü™ú –£—Ö–æ–¥–∏—Ç –≤ –Ω–µ–±–µ—Å–∞ 10—Å - 100 —Ä—É–±–ª–µ–π": {"duration": 10, "kind": "stairs", "people": 2},
}

FORMATS = {
    "üßç –í —Ä–æ—Å—Ç":   "full-body shot",
    "üë®‚Äçüíº –ü–æ –ø–æ—è—Å": "waist-up shot",
    "üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å": "chest-up shot",
}

# –ï–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏—Å—Ç–∏–Ω—ã: —Ñ–æ–Ω ‚Üí –ø—É—Ç—å –∫ –∫–∞—Ä—Ç–∏–Ω–∫–µ
BG_FILES = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤": "assets/backgrounds/bg_stairs.jpg",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":            "assets/backgrounds/bg_gates.jpg",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":        "assets/backgrounds/bg_angels.jpg",
}

# –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ –∂–µ –∏–º—è (–∫–Ω–æ–ø–∫–∏ —Å–º–æ—Ç—Ä—è—Ç –Ω–∞ –∫–ª—é—á–∏ BACKGROUNDS)
BACKGROUNDS = BG_FILES  # –∞–ª–∏–∞—Å: —Ç–µ –∂–µ –∫–ª—é—á–∏ –∏ —Ç–µ –∂–µ –ø—É—Ç–∏

MUSIC = {
    "üéµ –°–ø–æ–∫–æ–π–Ω–∞—è": "audio/soft_pad.mp3",
    "üéµ –¶–µ—Ä–∫–æ–≤–Ω–∞—è": "audio/gentle_arpeggio.mp3",
    "üéµ –õ–∏—Ä–∏—á–Ω–∞—è":  "audio/strings_hymn.mp3",
}

# –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç–µ)
BG_TEXT = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤":
        "must animate only: very gentle cloud drift left-to-right (~2 px/s) and faint light breathing (¬±3% brightness); "
        "stairs and architecture must remain fixed; do not add or remove any objects",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":
        "must animate only: subtle light pulsing (¬±3% brightness) and tiny cloud drift (~1‚Äì2 px/s); "
        "gates and columns must remain fixed; do not add ornaments or statues",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":
        "must animate only: faint feather shimmer or tiny wing flicker (very rare) and minimal cloud drift (~1‚Äì2 px/s); "
        "angel figures must remain fixed; do not add or move elements",
}

# –†–µ—Å—ç–º–ø–ª–µ—Ä –ø–æ–¥ Pillow 10+
RESAMPLE = getattr(Image, "Resampling", Image)

# –ó–∞–∑–æ—Ä—ã –∏ —Ü–µ–Ω—Ç—Ä—ã
MIN_GAP_PX       = 24     # –±—ã–ª–æ 20 ‚Äî —á—É—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ –æ—Ç ¬´—Å–ª–∏–ø–∞–Ω–∏—è¬ª
IDEAL_GAP_FRAC   = 0.07   # –±—ã–ª–æ 0.05 ‚Äî —Ü–µ–ª–µ–≤–æ–π –∑–∞–∑–æ—Ä ~7% —à–∏—Ä–∏–Ω—ã
CENTER_BIAS_FRAC = 0.40   # –±—ã–ª–æ 0.42 ‚Äî –≤ —Å—Ç–∞—Ä–æ–π —Ä–∞—Å–∫–ª–∞–¥–∫–µ —É–≤–æ–¥–∏—Ç –ª—é–¥–µ–π —á—É—Ç—å –∫ –∫—Ä–∞—è–º

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–æ–ø—É—Å—Ç–∏–º—ã–π –∞–ø—Å–∫–µ–π–ª
MAX_UPSCALE = float(os.environ.get("MAX_UPSCALE", "1.45"))

# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ ¬´–≤–∏–¥–∏–º—ã–µ¬ª –≤—ã—Å–æ—Ç—ã (–∞–Ω—Ç–∏-–∫–∞—Ä–ª–∏–∫), –¥–æ–ª—è –æ—Ç –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞ H
MIN_VISIBLE_FRAC = {
    ("üßç –í —Ä–æ—Å—Ç", 1): 0.66,  # –±—ã–ª–æ 0.70
    ("üßç –í —Ä–æ—Å—Ç", 2): 0.64,  # –±—ã–ª–æ 0.70
    ("üë®‚Äçüíº –ü–æ –ø–æ—è—Å", 1): 0.56,  # –±—ã–ª–æ 0.60
    ("üë®‚Äçüíº –ü–æ –ø–æ—è—Å", 2): 0.54,  # –±—ã–ª–æ 0.60
    ("üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å", 1): 0.48,  # –±—ã–ª–æ 0.50
    ("üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å", 2): 0.46,  # –±—ã–ª–æ 0.50
}
def _min_frac_for(format_key: str, count_people: int) -> float:
    return MIN_VISIBLE_FRAC.get((format_key, count_people), 0.56)

# –¶–µ–ª–µ–≤—ã–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ –≤—ã—Å–æ—Ç—ã (–µ—â—ë —á—É—Ç—å –º–µ–Ω—å—à–µ, —á–µ–º —Ä–∞–Ω—å—à–µ)
TH_FULL_SINGLE   = 0.66   # –±—ã–ª–æ 0.70
TH_FULL_DOUBLE   = 0.64   # –±—ã–ª–æ 0.70
TH_WAIST_SINGLE  = 0.56   # –±—ã–ª–æ 0.60
TH_WAIST_DOUBLE  = 0.54   # –±—ã–ª–æ 0.60
TH_CHEST_SINGLE  = 0.48   # –±—ã–ª–æ 0.50
TH_CHEST_DOUBLE  = 0.46   # –±—ã–ª–æ 0.50

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –≤—ã—Å–æ—Ç—ã –≥—Ä—É–ø–ø—ã (–¥–ª—è ¬´–ø–æ–¥—Ä–æ—Å—Ç–∏—Ç—å¬ª, –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –º–µ–ª–∫–æ)
MIN_SINGLE_FRAC = {
    "–í —Ä–æ—Å—Ç":  0.66,
    "–ü–æ –ø–æ—è—Å": 0.56,
    "–ü–æ –≥—Ä—É–¥—å":0.48,
}
MIN_PAIR_FRAC = {
    "–í —Ä–æ—Å—Ç":  0.64,
    "–ü–æ –ø–æ—è—Å": 0.54,
    "–ü–æ –≥—Ä—É–¥—å":0.46,
}

# –ú—è–≥–∫–∏–π –ø—Ä–µ–¥–µ–ª –∞–ø—Å–∫–µ–π–ª–∞ –ø—Ä–∏ –¥–æ–≤–æ–¥–∫–µ (—á—Ç–æ–±—ã –≤–Ω–µ–∑–∞–ø–Ω–æ –Ω–µ ¬´—Ä–∞–∑–¥—É—Ç—å¬ª)
PAIR_UPSCALE_CAP   = 1.10   # –±—ã–ª–æ 1.22
SINGLE_UPSCALE_CAP = 1.12   # –±—ã–ª–æ 1.25

def _bg_layout_presets(bg_path: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º—è–≥–∫–∏–º–∏ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—è–º–∏ –∫–æ–º–ø–æ–Ω–æ–≤–∫–∏ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ–Ω.
    center_frac ‚Äî —Ü–µ–Ω—Ç—Ä ¬´–ø–æ–ª–æ—Å—ã¬ª –≤ –¥–æ–ª—è—Ö —à–∏—Ä–∏–Ω—ã,
    band_frac   ‚Äî —à–∏—Ä–∏–Ω–∞ ¬´–ø–æ–ª–æ—Å—ã¬ª (–≤ –¥–æ–ª—è—Ö —à–∏—Ä–∏–Ω—ã),
    top_headroom_min/max ‚Äî –¥–æ–ø—É—Å—Ç–∏–º—ã–π –∑–∞–∑–æ—Ä —Å–≤–µ—Ä—Ö—É (–¥–æ–ª–∏ –≤—ã—Å–æ—Ç—ã).
    """
    name = os.path.basename(str(bg_path)).lower()
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —à–∏—Ä–æ–∫–∞—è –ø–æ–ª–æ—Å–∞ –∏ —É–º–µ—Ä–µ–Ω–Ω—ã–π –ø–æ—Ç–æ–ª–æ–∫
    presets = dict(center_frac=0.50, band_frac=0.46, top_headroom_min=0.05, top_headroom_max=0.13)

    if "stairs" in name:
        # –¥–µ—Ä–∂–∏–º –ª—é–¥–µ–π –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É, —Å–≤–µ—Ä—Ö—É –¥–æ–ø—É—Å—Ç–∏–º–æ —á—É—Ç—å –±–æ–ª—å—à–µ –≤–æ–∑–¥—É—Ö–∞ (–±–ª–∏–∫)
        presets = dict(center_frac=0.50, band_frac=0.40, top_headroom_min=0.06, top_headroom_max=0.18)
    elif "gates" in name:
        presets = dict(center_frac=0.50, band_frac=0.44, top_headroom_min=0.05, top_headroom_max=0.15)
    # angels ‚Äî –æ—Å—Ç–∞–≤–∏–º –¥–µ—Ñ–æ–ª—Ç
    return presets

NEG_TAIL = (
    "no face morphing, no identity change, no makeup change, no aging, "
    "do not add new accessories, keep existing accessories, "
    "no extra fingers, no deformed hands, no melting faces, "
    "no background geometry changes, no new background objects, "
    "camera locked, very low creativity"
)

KISS_FALLBACKS = [
    "two people embrace cheek-to-cheek; tender cheek touch; no lip contact; hold briefly",
    "one person gives a gentle kiss on the forehead; respectful, brief; other person softly leans"
]

# –î–æ–±–∞–≤–∫–∏ –∫ –ø—Ä–æ–º–ø—Ç—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ–≥–¥–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/—Ç–∞–π–º–∞—É—Ç/–æ—à–∏–±–∫–∞
BACKUP_PROMPT_ADDITIONS = (
    "stabilize subject scale; prevent stretching or shrinking; "
    "keep feet grounded and fixed to floor plane; "
    "no zoom, no dolly; lock camera; "
    "refine edges softly (1-2px feather); avoid hallucinated limbs"
)

# ------------------------- PROMPT BUILDER (per scene) -------------------------

def _people_count_by_kind(kind: str) -> int:
    """–ï—Å–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–ª–∏ —è–≤–Ω–æ –ª—é–¥–µ–π ‚Äî –≤—ã–≤–æ–¥–∏–º –ø–æ —Ç–∏–ø—É —Å—Ü–µ–Ω—ã."""
    k = (kind or "").lower()
    if k in ("wave",):
        return 1
    # hug, kiss_cheek, stairs –∏ –ø—Ä–æ—á. ‚Äî –æ–±—ã—á–Ω–æ –ø–∞—Ä–∞
    return 2

SCENE_TEMPLATES = {
    # –¥–≤–∞ —á–µ–ª–æ–≤–µ–∫–∞, –º—è–≥–∫–æ–µ —Å–±–ª–∏–∂–µ–Ω–∏–µ –∏ –æ–±—ä—è—Ç–∏–µ
    "hug": (
        "{who} are already close to each other; gently approach and embrace; "
        "keep relative sizes constant; natural breathing; subtle micro-motions; {framing}. "
        "{bg_rules}"
    ),
    # ¬´–ø–æ—Ü–µ–ª—É–π¬ª –±–µ–∑ —Ä–∏—Å–∫–∞ ‚Äî —â–µ–∫–∞/–ª–æ–±
    "kiss_cheek": (
        "{who} are close; tender cheek-to-cheek moment or a soft forehead kiss; "
        "no lip contact; gentle leaning; hold briefly; {framing}. "
        "{bg_rules}"
    ),
    # –æ–¥–∏–Ω —á–µ–ª–æ–≤–µ–∫ ‚Äî –ø—Ä–æ—â–∞–Ω–∏–µ
    "wave": (
        "{who} stands in place and slowly waves a hand; small natural body sway; "
        "calm mood; {framing}. {bg_rules}"
    ),
    # ¬´—É—Ö–æ–¥–∏—Ç –≤ –Ω–µ–±–µ—Å–∞¬ª ‚Äî –º—è–≥–∫–æ–µ, –±–µ–∑ –ø—Ä—ã–∂–∫–æ–≤ –∫–∞–º–µ—Ä—ã
    "stairs": (
        "{who} gently ascend the stairs together; small synchronized steps; "
        "no rushing; keep sizes consistent; {framing}. {bg_rules}"
    ),
}

def build_prompt(kind: str, framing_text: str, bg_text: str, duration_s: int, people: int | None = None) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –±–µ–∑ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞:
    - –±–∞–∑–æ–≤—ã–π —Ç–µ–∫—Å—Ç –ø–æ —Å—Ü–µ–Ω–µ (SCENE_TEMPLATES)
    - —Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞ (framing_text)
    - –ø—Ä–∞–≤–∏–ª–∞ —Ñ–æ–Ω–∞ (bg_text)
    - —Å—Ç—Ä–∞—Ö—É—é—â–∏–µ –¥–æ–±–∞–≤–∫–∏: BACKUP_PROMPT_ADDITIONS + NEG_TAIL
    """
    k = (kind or "").lower()
    tpl = SCENE_TEMPLATES.get(k, "{who} are present; natural small motions; {framing}. {bg_rules}")
    n = people if (people and people > 0) else _people_count_by_kind(k)
    who = "two people" if n >= 2 else "one person"

    # –ë–∞–∑–æ–≤—ã–µ –∫—É—Å–æ—á–∫–∏
    core = tpl.format(
        who=who,
        framing=framing_text.strip(),
        bg_rules=(bg_text or "").strip()
    )

    # –ù–µ–±–æ–ª—å—à–∞—è –ø–æ–º–µ—Ç–∫–∞ –ø—Ä–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–±–µ–∑ –∂—ë—Å—Ç–∫–æ–≥–æ —Ç–∞–π–º–ª–∞–π–Ω–∞, —á—Ç–æ–±—ã –Ω–µ —É—Å–ª–æ–∂–Ω—è—Ç—å –ø–æ–∫–∞)
    dur_hint = f" overall duration about {int(duration_s)} seconds;"

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞
    prompt = (
        core.strip() + dur_hint + " " +
        BACKUP_PROMPT_ADDITIONS.strip() + " " +
        NEG_TAIL.strip()
    )
    return " ".join(prompt.split())

# ---------- –°–¢–ï–ô–¢ ----------
def new_state():
    return {
        "scenes": [],
        "format": None,
        "bg": None,
        "music": None,
        "photos": [],
        "ready": False,
        "support": False,   # –∂–¥—ë–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏
    }

users = {}  # uid -> state
# –ë—É—Ñ–µ—Ä –¥–ª—è –∞–ª—å–±–æ–º–æ–≤ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ, –ø—Ä–∏—à–µ–¥—à–∏—Ö –æ–¥–Ω–∏–º –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø–æ–π)
PENDING_ALBUMS = {}  # media_group_id -> {"uid": int, "need": int, "paths": list[str]}

# ---------- –ö–õ–ê–í–ò–ê–¢–£–†–´ ----------
def available_scene_keys(format_key: str | None) -> list[str]:
    # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ "–í —Ä–æ—Å—Ç" ‚Äî —É–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ü–µ–Ω—ã —Å kind == "stairs"
    keys = []
    for name, meta in SCENES.items():
        if format_key and "–í —Ä–æ—Å—Ç" not in format_key and meta.get("kind") == "stairs":
            continue
        keys.append(name)
    return keys

def kb_scenes(format_key: str | None = None):
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)

    # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ü–µ–Ω —Å —É—á—ë—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–∞
    scene_keys = available_scene_keys(format_key)
    scene_buttons = [telebot.types.KeyboardButton(k) for k in scene_keys]
    if scene_buttons:
        kb.add(*scene_buttons)

    # —Å–ª—É–∂–µ–±–Ω—ã–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏
    kb.add(
        telebot.types.KeyboardButton("‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ"),
        telebot.types.KeyboardButton("üîÅ –°–±—Ä–æ—Å–∏—Ç—å –≤—ã–±–æ—Ä —Å—é–∂–µ—Ç–æ–≤"),
    )
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_formats():
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=3)
    kb.add(*[telebot.types.KeyboardButton(k) for k in FORMATS.keys()])
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_backgrounds():
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True)
    for k in BACKGROUNDS.keys():
        kb.add(telebot.types.KeyboardButton(k))
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_music():
    """Inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º—É–∑—ã–∫–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è"""
    kb = telebot.types.InlineKeyboardMarkup(row_width=2)

    for name, path in MUSIC.items():
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ üéµ –¥–ª—è callback-–¥–∞–Ω–Ω—ã—Ö
        clean_name = name.replace("üéµ ", "")
        listen_btn = telebot.types.InlineKeyboardButton(
            f"üéß {clean_name}", callback_data=f"listen_{clean_name}"
        )
        select_btn = telebot.types.InlineKeyboardButton(
            f"‚úÖ {clean_name}", callback_data=f"select_music_{clean_name}"
        )
        kb.add(listen_btn, select_btn)

    # –ö–Ω–æ–ø–∫–∞ "–ë–µ–∑ –º—É–∑—ã–∫–∏"
    no_music_btn = telebot.types.InlineKeyboardButton(
        "üîá –ë–µ–∑ –º—É–∑—ã–∫–∏", callback_data="select_music_none"
    )
    kb.add(no_music_btn)

    # –ö–Ω–æ–ø–∫–∞ "–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
    home_btn = telebot.types.InlineKeyboardButton(
        "üè† –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="go_home"
    )
    kb.add(home_btn)

    return kb

# ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ----------
def alpha_metrics(img: Image.Image, thr: int = 20):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bbox, y_bottom) –ø–æ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –ø–∏–∫—Å–µ–ª—è–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞.
    bbox: (x0, y0, x1, y1) –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    y_bottom: –∏–Ω–¥–µ–∫—Å –Ω–∏–∂–Ω–µ–π —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (int)
    """
    a = img.split()[-1]
    arr = np.asarray(a, dtype=np.uint8)
    ys, xs = np.where(arr >= thr)
    if ys.size == 0:
        b = img.getbbox() or (0, 0, img.width, img.height)
        return b, b[3] - 1
    x0, y0 = int(xs.min()), int(ys.min())
    x1, y1 = int(xs.max()) + 1, int(ys.max()) + 1
    return (x0, y0, x1, y1), (y1 - 1)

def _save_layout_debug(canvas_rgba: Image.Image, metrics: dict, base_id: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
      - renders/temp/metrics_<base_id>.json ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–º–ø–æ–Ω–æ–≤–∫–∏
      - renders/temp/annot_<base_id>.png    ‚Äî –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–≤—å—é —Å —Ä–∞–º–∫–∞–º–∏
    """
    try:
        os.makedirs("renders/temp", exist_ok=True)
    except Exception:
        pass

    # 1) JSON
    try:
        mpath = f"renders/temp/metrics_{base_id}.json"
        with open(mpath, "w", encoding="utf-8") as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        print(f"[DEBUG] metrics -> {mpath}")
    except Exception as e:
        print(f"[DEBUG] metrics save error: {e}")

    # 2) –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞
    try:
        im = canvas_rgba.convert("RGB")
        draw = ImageDraw.Draw(im)
        font = None
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 16)
        except Exception:
            font = ImageFont.load_default()

        # –†–∞–º–∫–∏ –∏ –ø–æ–¥–ø–∏—Å–∏
        colors = {"L": (46, 204, 113), "R": (52, 152, 219)}  # –∑–µ–ª—ë–Ω—ã–π/—Å–∏–Ω–∏–π
        for side in ("L", "R"):
            if side not in metrics: 
                continue
            r = metrics[side]["rect_abs"]  # [x0,y0,x1,y1]
            c = colors[side]
            # —Ä–∞–º–∫–∞
            draw.rectangle(r, outline=c, width=3)
            # –ø–æ–¥–ø–∏—Å—å
            label = (f"{side}: h={metrics[side]['height_px']} "
                     f"({int(round(metrics[side]['height_frac']*100))}% H), "
                     f"w={metrics[side]['width_px']}, "
                     f"cx={int(round(metrics[side]['center_x_frac']*100))}%, "
                     f"scale‚âà{metrics[side]['scale']:.2f}")
            tx, ty = r[0] + 4, max(4, r[1] - 18)
            draw.rectangle([tx-2, ty-2, tx+draw.textlength(label, font=font)+6, ty+18], fill=(0,0,0,128))
            draw.text((tx, ty), label, fill=(255,255,255), font=font)

            # –æ—Ç–º–µ—Ç–∫–∞ ¬´–ø–æ–ª¬ª
            fy = metrics[side].get("floor_y")
            if isinstance(fy, int):
                draw.line([(r[0], fy), (r[2], fy)], fill=c, width=2)

        # –ó–∞–∑–æ—Ä –º–µ–∂–¥—É –ª—é–¥—å–º–∏
        gap = metrics.get("gap_px")
        if gap is not None:
            text = f"gap={gap}px ({int(round(metrics.get('gap_frac',0)*100))}% W)"
            draw.rectangle([10, 10, 10+draw.textlength(text, font=font)+12, 10+22], fill=(0,0,0,128))
            draw.text((16, 12), text, fill=(255,255,255), font=font)

        apath = f"renders/temp/annot_{base_id}.png"
        im.save(apath, "PNG")
        print(f"[DEBUG] annot -> {apath}")
    except Exception as e:
        print(f"[DEBUG] annot save error: {e}")

def compact_prompt(s: str, max_len: int = 900) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã –ø—Ä–æ–±–µ–ª–æ–≤, –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å—Ç—Ä–æ–∫ –∏ —Ä–µ–∂–µ–º –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã."""
    s = " ".join(str(s).split())
    if len(s) > max_len:
        s = s[:max_len-3] + "..."
    return s

# --- –ó–∞–≥–ª—É—à–∫–∞ –ø–æ–¥ —Å—Ç–∞—Ä—ã–µ –≤—ã–∑–æ–≤—ã –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (—É–¥–∞–ª–∏–º –ø–æ–∑–∂–µ –≤–º–µ—Å—Ç–µ —Å –Ω–∏–º–∏) ---
def _is_minor_only(reasons: list[str] | None) -> bool:
    """–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç–∫–ª—é—á—ë–Ω: –º–∏–Ω–æ—Ä/–º–∞–∂–æ—Ä –ø—Ä–∏—á–∏–Ω—ã –Ω–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º."""
    return False

def validate_photo(path: str) -> tuple[bool, list[str]]:
    """
    –ú—è–≥–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ç–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok, warnings). ok=False ‚Äî –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ñ–æ—Ç–æ, –Ω–æ –ø–∞–π–ø–ª–∞–π–Ω –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º.
    """
    warns = []
    ok = True
    try:
        im = Image.open(path)
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é –ø–æ EXIF (–µ—Å–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–ª)
        try:
            from PIL import ImageOps
            im = ImageOps.exif_transpose(im)
        except Exception:
            pass
    except Exception as e:
        return False, [f"–Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª ({e})"]

    w, h = im.size
    min_dim = min(w, h)

    # 1) –†–∞–∑–º–µ—Ä/—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    if min_dim < 300:
        ok = False
        warns.append(f"–æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ({w}√ó{h}) ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –∏—Å–∫–∞–∑–∏—Ç—å—Å—è")
    elif min_dim < 600:
        warns.append(f"–Ω–∏–∑–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ({w}√ó{h}) ‚Äî –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ ‚â• 800px –ø–æ –º–µ–Ω—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ")

    # 2) –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è (–¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –ª—É—á—à–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è)
    ratio = w / h if h else 1.0
    if ratio > 0.9:
        warns.append("—Ñ–æ—Ç–æ –Ω–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ ‚Äî –ø–æ—Ä—Ç—Ä–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –≤—ã–≥–ª—è–¥–∏—Ç –≤ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏")

    # 3) –¢–µ–º–Ω–æ—Ç–∞/—ç–∫—Å–ø–æ–∑–∏—Ü–∏—è (–æ—á–µ–Ω—å –≥—Ä—É–±–æ)
    gray = im.convert("L")
    arr = np.asarray(gray, dtype=np.float32)
    mean = float(arr.mean())
    if mean < 55:
        warns.append("—Ñ–æ—Ç–æ —Ç—ë–º–Ω–æ–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª–µ–µ —Å–≤–µ—Ç–ª–æ–µ/–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ")

    # 4) –†–∞–∑–º—ã—Ç–æ—Å—Ç—å (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ ¬´–∫—Ä–∞—è¬ª)
    edges = gray.filter(ImageFilter.FIND_EDGES)
    earr = np.asarray(edges, dtype=np.float32)
    sharpness = float(earr.std())
    if sharpness < 8:
        warns.append("–≤–æ–∑–º–æ–∂–Ω–∞—è —Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å/—à—É–º ‚Äî –∫–æ–Ω—Ç—É—Ä—ã —Å–ª–∞–±—ã–µ")

    return ok, warns

def _visible_bbox_height(img: Image.Image) -> int:
    b = img.getbbox() or (0, 0, img.width, img.height)
    return max(1, b[3] - b[1])

def smart_cutout(img_rgba: Image.Image) -> Image.Image:
    """
    –í—ã—Ä–µ–∑–∫–∞ —á–µ–ª–æ–≤–µ–∫–∞:
      1) –ø—Ä–æ–±—É–µ–º –ø–æ—Ä—Ç—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å, –∏–Ω–∞—á–µ –±–∞–∑–æ–≤—É—é;
      2) –µ—Å–ª–∏ —Å–∏–ª—É—ç—Ç —Å–ª–∏—à–∫–æ–º –º–∞–ª ‚Äî –ø—Ä–æ–±—É–µ–º ISNet;
      3) —É–±–∏—Ä–∞–µ–º ¬´–æ—Ä–µ–æ–ª¬ª –∏ —á—É—Ç—å —Å–º—è–≥—á–∞–µ–º –∫—Ä–∞–π.
    """
    def _run(session):
        out = remove(img_rgba, session=session, post_process_mask=True)
        if isinstance(out, (bytes, bytearray)):
            out = Image.open(io.BytesIO(out)).convert("RGBA")
        else:
            out = out.convert("RGBA")
        return out

    # 1) –ü–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è –º–æ–¥–µ–ª—å ‚Üí fallback
    try:
        cut = _run(RMBG_HUMAN)
    except Exception:
        cut = _run(RMBG_SESSION)

    # 2) –ï—Å–ª–∏ —Å–∏–ª—É—ç—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π ‚Äî –ø—Ä–æ–±—É–µ–º ISNet
    try:
        bb = cut.getbbox() or (0, 0, cut.width, cut.height)
        area = (bb[2] - bb[0]) * (bb[3] - bb[1])
        if area < 0.12 * cut.width * cut.height:
            try:
                alt = _run(RMBG_ISNET)
                bb2 = alt.getbbox() or (0, 0, alt.width, alt.height)
                area2 = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])
                if area2 > area:
                    cut = alt
            except Exception:
                pass
    except Exception:
        pass

    # 3) –†–∞—Ñ–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å–∫–∏: —á—É—Ç—å ¬´–ø–æ–¥–∂–∞—Ç—å¬ª –∏ –¥–∞—Ç—å –ø–µ—Ä–æ
    a = cut.split()[-1]
    a = a.filter(ImageFilter.MinFilter(3))       # ~1px —ç—Ä–æ–∑–∏—è ‚Äî —É–±–∏—Ä–∞–µ–º –æ—Ä–µ–æ–ª
    a = a.filter(ImageFilter.GaussianBlur(1.2))  # –º—è–≥–∫–æ–µ –ø–µ—Ä–æ ~1‚Äì2px
    cut.putalpha(a)
    return cut
    
# ---------- RUNWAY ----------
RUNWAY_API = "https://api.dev.runwayml.com/v1"
HEADERS = {
    "Authorization": f"Bearer {RUNWAY_KEY}",
    "X-Runway-Version": "2024-11-06",
    "Content-Type": "application/json",
}

def encode_image_datauri(path: str) -> str:
    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    ext = path.lower().split(".")[-1]
    mime = "image/jpeg" if ext in ["jpg","jpeg"] else "image/png"
    return f"data:{mime};base64,{b64}"

def ensure_jpeg_copy(path: str, quality: int = 88) -> str:
    """
    –î–µ–ª–∞–µ—Ç JPEG-–∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ .jpg.
    """
    im = Image.open(path).convert("RGB")
    out = os.path.splitext(path)[0] + ".jpg"
    im.save(out, "JPEG", quality=quality, optimize=True, progressive=True)
    try:
        os.sync()  # –Ω–µ —É –≤—Å–µ—Ö –û–° –µ—Å—Ç—å, –æ–∫ –µ—Å–ª–∏ —Å–≤–∞–ª–∏—Ç—Å—è
    except Exception:
        pass
    return out

def encode_image_as_jpeg_datauri(path: str, quality: int = 88) -> str:
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ JPEG (RGB) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dataURI.
    –≠—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å PNG –∏ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤ Runway.
    """
    im = Image.open(path).convert("RGB")
    bio = io.BytesIO()
    im.save(bio, format="JPEG", quality=quality, optimize=True, progressive=True)
    b64 = base64.b64encode(bio.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"

def cut_foreground_to_png(in_path: str) -> str:
    """–í—ã—Ä–µ–∑–∞–µ—Ç —Ñ–æ–Ω –∏–∑ JPG/PNG –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç PNG —Å –∞–ª—å—Ñ–æ–π."""
    with open(in_path, "rb") as f:
        raw = f.read()
    out = remove(raw, session=RMBG_SESSION)
    out_path = os.path.splitext(in_path)[0] + "_cut.png"
    with open(out_path, "wb") as f:
        f.write(out)
    return out_path

def _to_jpeg_copy(src_path: str, quality: int = 88) -> str:
    im = Image.open(src_path).convert("RGB")
    out_path = os.path.join("uploads", f"startframe_{uuid.uuid4().hex}.jpg")
    im.save(out_path, "JPEG", quality=quality, optimize=True, progressive=True)
    return out_path

def ensure_runway_datauri_under_limit(path: str, limit: int = 5_000_000) -> tuple[str, str]:
    data = encode_image_datauri(path)
    if len(data) <= limit:
        return data, path

    last_path = path
    for q in (88, 80, 72):
        try:
            jpg = _to_jpeg_copy(path, quality=q)
            last_path = jpg
            data = encode_image_datauri(jpg)
            if len(data) <= limit:
                print(f"[Runway] using JPEG q={q}, data_uri={len(data)} bytes")
                return data, jpg
        except Exception as e:
            print(f"[Runway] jpeg fallback q={q} failed: {e}")

    print(f"[Runway] still heavy after JPEG attempts, length={len(data)}")
    return data, last_path

def _post_runway(payload: dict) -> dict | None:
    try:
        _pl = ""
        try:
            _pl = (payload.get("promptText") or payload.get("prompt") or "") if isinstance(payload, dict) else ""
        except Exception:
            pass

        model = payload.get("model")
        ratio = payload.get("ratio") or payload.get("aspect_ratio")
        dur   = payload.get("duration")

        msg = f"[Runway] model={model} dur={dur} ratio={ratio}"
        if _pl:
            msg += f" prompt[:200]={_pl[:200].replace(chr(10),' ')}..."
        print(msg)

        if MF_DEBUG:
            try:
                os.makedirs("renders/temp", exist_ok=True)
                preview = {
                    "model": model,
                    "duration": dur,
                    "ratio": ratio,
                    "prompt_len": len(_pl),
                    "image_data_uri_len": len(payload.get("promptImage") or payload.get("image") or ""),
                }
                with open(os.path.join("renders/temp", f"runway_payload_{int(time.time())}.json"), "w", encoding="utf-8") as f:
                    json.dump(preview, f, ensure_ascii=False, indent=2)
                print("[Runway] payload preview saved")
            except Exception as _e:
                print(f"[Runway] payload preview save err: {_e}")

        r = requests.post(f"{RUNWAY_API}/image_to_video", headers=HEADERS, json=payload, timeout=60)
        if r.status_code == 200:
            return r.json()
        print(f"[Runway {r.status_code}] {r.text}")
        return None
    except requests.RequestException as e:
        print(f"[Runway transport error] {e}")
        return None

def runway_start(prompt_image_datauri: str, prompt_text: str, duration: int):
    """
    –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ø—ã—Ç–æ–∫:
    1) gen4_turbo + promptImage/promptText + ratio (—Ç–µ–∫—É—â–∞—è —Å—Ö–µ–º–∞ —ç—Ç–æ–≥–æ API)
    2) gen4_turbo + image/prompt + aspect_ratio (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è)
    3) gen3a_turbo + image/prompt + aspect_ratio (–∑–∞–ø–∞—Å–Ω–æ–π)
    """
    variants = [
        {
            "model": "gen4_turbo",
            "promptImage": prompt_image_datauri,   # <-- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
            "promptText":  prompt_text,
            "ratio": "720:1280",
            "duration": int(duration),
        },
        {
            "model": "gen4_turbo",
            "image": prompt_image_datauri,
            "prompt": prompt_text,
            "aspect_ratio": "9:16",
            "duration": int(duration),
        },
        {
            "model": "gen3a_turbo",
            "image": prompt_image_datauri,
            "prompt": prompt_text,
            "aspect_ratio": "9:16",
            "duration": int(duration),
        },
    ]

    last_keys = ""
    for payload in variants:
        resp = _post_runway(payload)
        if resp:
            return resp
        last_keys = f"{list(payload.keys())}"

    raise RuntimeError(f"Runway returned 400/4xx for all variants (payload={last_keys}). Check logs above.")

def runway_poll(task_id: str, timeout_sec=900, every=5):
    start = time.time()
    while True:
        rr = requests.get(f"{RUNWAY_API}/tasks/{task_id}", headers=HEADERS, timeout=60)
        rr.raise_for_status()
        data = rr.json()
        st = data.get("status")
        if st in ("SUCCEEDED","FAILED","ERROR","CANCELED"):
            return data
        if time.time() - start > timeout_sec:
            return {"status":"TIMEOUT","raw":data}
        time.sleep(every)

def download(url: str, save_path: str):
    with requests.get(url, stream=True, timeout=300) as r:
        r.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in r.iter_content(8192):
                if chunk: f.write(chunk)
    return save_path

def _log_fail(uid: int, reason: str, payload: dict | None = None, response: dict | None = None):
    try:
        os.makedirs("renders/temp", exist_ok=True)
        path = os.path.join("renders/temp", f"fail_{uid}_{int(time.time())}_{uuid.uuid4().hex}.json")
        with open(path, "w", encoding="utf-8") as f:
            json.dump({
                "ts": datetime.utcnow().isoformat() + "Z",
                "uid": uid,
                "reason": reason,
                "payload": payload or {},
                "response": response or {}
            }, f, ensure_ascii=False, indent=2)
        print(f"[FAILLOG] {reason} -> {path}")
        # –µ—Å–ª–∏ –∑–∞–¥–∞–Ω ADMIN_CHAT_ID ‚Äî —à–ª—ë–º –∫–æ—Ä–æ—Ç–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        if ADMIN_CHAT_ID:
            try:
                bot.send_message(int(ADMIN_CHAT_ID), f"‚ö†Ô∏è FAIL {reason} (uid={uid})\n{os.path.basename(path)} —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
            except Exception:
                pass
    except Exception as e:
        print(f"[FAILLOG] write error: {e}")

def oai_gate_check(start_frame_path: str, base_prompt: str, meta: dict, timeout_sec: int = 120) -> dict | None:
    """
    –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Ç–∫–ª—é—á—ë–Ω: –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º None, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ —à—ë–ª –ø–æ ¬´–±–µ–∑ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞¬ª –≤–µ—Ç–∫–µ.
    """
    return None

# ---------- –í–´–†–ï–ó–ê–ù–ò–ï –ò –°–¢–ê–†–¢-–ö–ê–î–† ----------
def cutout(path: str) -> Image.Image:
    im = Image.open(path).convert("RGBA")
    cut = remove(im, session=RMBG_SESSION)  # –≤–∞–∂–Ω–æ–µ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Å–µ—Å—Å–∏—é
    # rembg –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å bytes ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ PIL.Image
    if isinstance(cut, (bytes, bytearray)):
        cut = Image.open(io.BytesIO(cut)).convert("RGBA")
    return cut

def _resize_fit_center(img: Image.Image, W: int, H: int) -> Image.Image:
    """–í–ø–∏—Å–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ —Ö–æ–ª—Å—Ç W√óH —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ –∫—Ä–æ–ø–æ–º –ø–æ —Ü–µ–Ω—Ç—Ä—É."""
    wr, hr = W / img.width, H / img.height
    scale = max(wr, hr)
    new = img.resize((int(img.width * scale), int(img.height * scale)), RESAMPLE.LANCZOS)
    x = (new.width - W) // 2
    y = (new.height - H) // 2
    return new.crop((x, y, x + W, y + H))

def make_start_frame(photo_paths: List[str], framing_key: str, bg_file: str, layout: dict | None = None) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –∫–∞–¥—Ä. –í–µ—Ç–∫—É –¥–ª—è 2—Ö –ª—é–¥–µ–π —É–ø—Ä–æ—Å—Ç–∏–ª–∏ (LEAN v0):
    - –æ–¥–∏–Ω–∞–∫–æ–≤–∞—è –≤–∏–¥–∏–º–∞—è –≤—ã—Å–æ—Ç–∞ —Å–∏–ª—É—ç—Ç–æ–≤ (~70% H, –Ω–æ –Ω–µ –±–æ–ª—å—à–µ MAX_VISIBLE_FRAC);
    - –∂—ë—Å—Ç–∫–∏–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∑–∞–∑–æ—Ä >= 5% —à–∏—Ä–∏–Ω—ã;
    - –±–µ–∑ –∞–≤—Ç–æ–ø–æ–¥—Ç—è–∂–µ–∫/—Ä–æ—Å—Ç–æ–≤; —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è, –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–∞—è –≥–µ–æ–º–µ—Ç—Ä–∏—è.
    """

    def _min_target_for(framing: str, people_count: int) -> float:
        if "–í —Ä–æ—Å—Ç" in framing:
            return 0.82 if people_count >= 2 else 0.90
        elif "–ü–æ –ø–æ—è—Å" in framing:
            return 0.66 if people_count >= 2 else 0.72
        else:  # –ü–æ –≥—Ä—É–¥—å
            return 0.58 if people_count >= 2 else 0.62

    W, H = 720, 1280
    base_id = uuid.uuid4().hex
    floor_margin = 10

    # –≤–µ—Ä—Ö–Ω–∏–π ¬´–≤–æ–∑–¥—É—Ö¬ª
    if "–ü–æ –≥—Ä—É–¥—å" in framing_key:
        HEADROOM_FRAC = 0.06
    elif "–ü–æ –ø–æ—è—Å" in framing_key:
        HEADROOM_FRAC = 0.04
    else:
        HEADROOM_FRAC = 0.02

    # 1) —Ñ–æ–Ω
    bg = Image.open(bg_file).convert("RGB")
    bg = _resize_fit_center(bg, W, H)
    bg = bg.filter(ImageFilter.GaussianBlur(radius=0.8))
    canvas = bg.convert("RGBA")

    # 2) –≤—ã—Ä–µ–∑–∞–µ–º –ª—é–¥–µ–π
    cuts = []
    for p in photo_paths:
        im = Image.open(p).convert("RGBA")
        try:
            cut_rgba = smart_cutout(im)
        except NameError:
            cut_rgba = remove(im)
            if isinstance(cut_rgba, (bytes, bytearray)):
                cut_rgba = Image.open(io.BytesIO(cut_rgba)).convert("RGBA")
        cuts.append(cut_rgba)

    if MF_DEBUG:
        try:
            for i, c in enumerate(cuts):
                bb, yb = alpha_metrics(c)
                eff_h = max(1, (yb - bb[1] + 1))
                print(f"[LAYOUT] person#{i+1}: img={c.width}x{c.height} eff_h={eff_h} bbox={bb}")
        except Exception as _e:
            print(f"[LAYOUT] cut metrics err: {_e}")

    # 3) —Ü–µ–ª–µ–≤–∞—è –≤—ã—Å–æ—Ç–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–∞–¥—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –æ–¥–∏–Ω–æ—á–Ω–æ–π –≤–µ—Ç–∫–µ)
    two = (len(photo_paths) > 1)
    if "–í —Ä–æ—Å—Ç" in framing_key:
        target_h = TH_FULL_DOUBLE if two else TH_FULL_SINGLE
    elif "–ü–æ –ø–æ—è—Å" in framing_key:
        target_h = TH_WAIST_DOUBLE if two else TH_WAIST_SINGLE
    else:  # ¬´–ü–æ –≥—Ä—É–¥—å¬ª
        target_h = TH_CHEST_DOUBLE if two else TH_CHEST_SINGLE

    # –º–∏–Ω–∏–º—É–º (–∞–Ω—Ç–∏-–∫–∞—Ä–ª–∏–∫)
    target_h_min = _min_target_for(framing_key, len(photo_paths))
    if target_h < target_h_min:
        target_h = target_h_min

    def scale_to_target_effective(img: Image.Image, target: float) -> Image.Image:
        bbox, yb = alpha_metrics(img)
        eff_h = max(1, (yb - bbox[1] + 1))
        scale = (H * target) / eff_h
        if scale > MAX_UPSCALE:
            scale = MAX_UPSCALE
        nw, nh = max(1, int(img.width * scale)), max(1, int(img.height * scale))
        return img.resize((nw, nh), RESAMPLE.LANCZOS)

    def place_y_for_floor(img: Image.Image) -> int:
        bbox, yb = alpha_metrics(img)
        eff_h = (yb - bbox[1] + 1)
        y_top_content = H - floor_margin - eff_h
        y_img = y_top_content - bbox[1]
        return int(y_img)

    def draw_with_shadow(base: Image.Image, person: Image.Image, x: int, y: int):
        alpha = person.split()[-1]
        soft = alpha.filter(ImageFilter.GaussianBlur(6))
        shadow = Image.new("RGBA", person.size, (0, 0, 0, 0))
        shadow.putalpha(soft.point(lambda a: int(a * 0.45)))
        base.alpha_composite(shadow, (x, y + 8))
        base.alpha_composite(person, (x, y))

    def _rect_at(x, y, img):
        bx, by, bx1, by1 = alpha_metrics(img)[0]
        return (x + bx, y + by, x + bx1, y + by1)

    def _draw_debug_boxes(base: Image.Image, rects: list[tuple[int,int,int,int]]):
        if not START_OVERLAY_DEBUG:
            return
        ov = Image.new("RGBA", base.size, (0,0,0,0))
        g = ImageDraw.Draw(ov)
        for r in rects:
            g.rectangle(r, outline=(255, 0, 0, 200), width=3)
        m = 20
        g.rectangle((m, m, base.width - m, base.height - m), outline=(0, 255, 0, 180), width=2)
        base.alpha_composite(ov)

    # ------------------------------- 1 —á–µ–ª–æ–≤–µ–∫ -------------------------------
    if len(cuts) == 1:
        P = scale_to_target_effective(cuts[0], target_h)
        x = (W - P.width) // 2
        y = place_y_for_floor(P)

        # –æ—Ü–µ–Ω–∫–∞ –≤–∏–¥–∏–º–æ–π –≤—ã—Å–æ—Ç—ã
        def rect_at_single(px, py, img):
            bx, by, bx1, by1 = alpha_metrics(img)[0]
            return (px + bx, py + by, px + bx1, py + by1)

        r = rect_at_single(x, y, P)
        group_h = r[3] - r[1]
        fmt = "–í —Ä–æ—Å—Ç" if "–í —Ä–æ—Å—Ç" in framing_key else ("–ü–æ –ø–æ—è—Å" if "–ü–æ –ø–æ—è—Å" in framing_key else "–ü–æ –≥—Ä—É–¥—å")
        min_h_frac = MIN_SINGLE_FRAC[fmt]

        if group_h < int(min_h_frac * H):
            need = (min_h_frac * H) / max(1, group_h)
            cap = SINGLE_UPSCALE_CAP
            new_target = min(target_h * need, target_h * cap)
            if new_target > target_h:
                P = scale_to_target_effective(cuts[0], new_target)
                x = (W - P.width) // 2
                y = place_y_for_floor(P)

        margin = 20
        x = max(margin, min(W - P.width - margin, x))
        top_margin = max(margin, int(HEADROOM_FRAC * H))
        y = max(top_margin, min(H - P.height - margin, y))

        # –º—è–≥–∫–∏–π —Ä—É—á–Ω–æ–π layout –¥–ª—è 1 —á–µ–ª–æ–≤–µ–∫–∞ (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø—Ä–∏–ª–µ—Ç–∏—Ç)
        if layout and isinstance(layout, dict):
            scl = int(layout.get("scale_left_pct", 0) or 0)
            dxl = int(layout.get("shift_left_px", 0) or 0)
            if scl != 0:
                k = 1.0 + max(-0.20, min(0.20, scl / 100.0))
                nw, nh = max(1, int(P.width * k)), max(1, int(P.height * k))
                P = P.resize((nw, nh), RESAMPLE.LANCZOS)
                y = place_y_for_floor(P)
            if dxl != 0:
                x += int(-dxl)
            x = max(margin, min(W - P.width - margin, x))
            y = max(margin, min(H - P.height - margin, y))

        # –∞–Ω—Ç–∏-–∫–∞—Ä–ª–∏–∫ –¥–ª—è –æ–¥–∏–Ω–æ—á–∫–∏
        def _visible_frac(img: Image.Image) -> float:
            bb, yb = alpha_metrics(img)
            eff_h = max(1, (yb - bb[1] + 1))
            return eff_h / H

        grow_tries = 0
        while _visible_frac(P) < _min_target_for(framing_key, 1) and grow_tries < 12:
            new_target = min(target_h * 1.04, 0.98)
            newP = scale_to_target_effective(cuts[0], new_target)
            cx = x + P.width // 2
            cy_floor = place_y_for_floor(newP)
            newx = cx - newP.width // 2
            margin = 20
            newx = max(margin, min(W - newP.width - margin, newx))
            newy = max(margin, min(H - newP.height - margin, cy_floor))
            if newy <= margin or newx <= margin or (newx + newP.width) >= (W - margin):
                break
            P, x, y = newP, newx, newy
            target_h = new_target
            grow_tries += 1

        draw_with_shadow(canvas, P, x, y)
        try:
            _draw_debug_boxes(canvas, [_rect_at(x, y, P)])
        except Exception:
            pass

    # ------------------------------ 2 —á–µ–ª–æ–≤–µ–∫–∞ (LEAN v1) ------------------------------
    else:
        L = cuts[0]
        R = cuts[1]

        # –ú–µ—Ç—Ä–∏–∫–∏ –∏ –º–∞—Å—à—Ç–∞–± –ø–æ –≤–∏–¥–∏–º–æ–π –≤—ã—Å–æ—Ç–µ (bbox –ø–æ –∞–ª—å—Ñ–µ)
        def _vis_h(img: Image.Image) -> int:
            bb, yb = alpha_metrics(img)
            return max(1, (yb - bb[1] + 1))

        def _vis_frac(img: Image.Image) -> float:
            return _vis_h(img) / H

        def _scale_to_vis_frac(img: Image.Image, target_frac: float) -> Image.Image:
            cur = _vis_frac(img)
            if cur <= 1e-6:
                return img
            k = max(0.4, min(MAX_UPSCALE, target_frac / cur))
            nw = max(1, int(img.width * k))
            nh = max(1, int(img.height * k))
            return img.resize((nw, nh), RESAMPLE.LANCZOS)

        def rect_at(x, y, img):
            bx, by, bx1, by1 = alpha_metrics(img)[0]
            return (x + bx, y + by, x + bx1, y + by1)

        def _inner_gap_px(a, b):
            return max(0, b[0] - a[2])

        MARGIN = 20
        is_full = ("–í —Ä–æ—Å—Ç" in framing_key) or ("–≤ —Ä–æ—Å—Ç" in framing_key)

        # –ñ—ë—Å—Ç–∫–∏–µ –ø—Ä–µ–¥–µ–ª—ã –≤–∏–¥–∏–º–æ–π –≤—ã—Å–æ—Ç—ã
        MAX_VISIBLE_FRAC = LEAN_MAX_VISIBLE_FRAC if is_full else max(LEAN_MAX_VISIBLE_FRAC, 0.76)
        TARGET_VISIBLE_FRAC = min(LEAN_TARGET_VISIBLE_FRAC, MAX_VISIBLE_FRAC)

        # 1) –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–∏–¥–∏–º—É—é –≤—ã—Å–æ—Ç—É –æ–±–æ–∏—Ö –ø–æ–¥ –æ–¥–∏–Ω —Ç–∞—Ä–≥–µ—Ç, –Ω–æ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ–º MAX
        L = _scale_to_vis_frac(L, TARGET_VISIBLE_FRAC)
        R = _scale_to_vis_frac(R, TARGET_VISIBLE_FRAC)
        if _vis_frac(L) > MAX_VISIBLE_FRAC:
            L = _scale_to_vis_frac(L, MAX_VISIBLE_FRAC)
        if _vis_frac(R) > MAX_VISIBLE_FRAC:
            R = _scale_to_vis_frac(R, MAX_VISIBLE_FRAC)

        # 2) ¬´–ü–æ—Å—Ç–∞–≤–∏—Ç—å –Ω–∞ –ø–æ–ª¬ª
        yl = place_y_for_floor(L)
        yr = place_y_for_floor(R)

        # 3) –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã –ø–æ X (—Å–ª–µ–≤–∞/—Å–ø—Ä–∞–≤–∞)
        cxL = int(W * LEAN_CX_LEFT)
        cxR = int(W * LEAN_CX_RIGHT)
        lx  = cxL - L.width // 2
        rx  = cxR - R.width // 2

        # 4) (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –º—è–≥–∫–∏–π —Ä—É—á–Ω–æ–π layout, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –ø–µ—Ä–µ–¥–∞–Ω layout
        if layout and isinstance(layout, dict):
            scl_l = int(layout.get("scale_left_pct", 0)  or 0)
            scl_r = int(layout.get("scale_right_pct", 0) or 0)
            dx_l  = int(layout.get("shift_left_px", 0)   or 0)
            dx_r  = int(layout.get("shift_right_px", 0)  or 0)

            def _apply_scale_soft(img: Image.Image, pct: int) -> Image.Image:
                if pct == 0:
                    return img
                k = 1.0 + max(-0.15, min(0.15, pct / 100.0))  # –º—è–≥—á–µ: ¬±15%
                nw, nh = max(1, int(img.width * k)), max(1, int(img.height * k))
                return img.resize((nw, nh), RESAMPLE.LANCZOS)

            if scl_l:
                L = _apply_scale_soft(L, scl_l)
                yl = place_y_for_floor(L)
                lx = cxL - L.width // 2
            if scl_r:
                R = _apply_scale_soft(R, scl_r)
                yr = place_y_for_floor(R)
                rx = cxR - R.width // 2
            if dx_l:
                # shift_left_px > 0 ‚Äî ¬´–≤–ª–µ–≤–æ¬ª, —Ç.–µ. x -= dx
                lx += int(-dx_l)
            if dx_r:
                # shift_right_px > 0 ‚Äî ¬´–≤–ø—Ä–∞–≤–æ¬ª, —Ç.–µ. x += dx
                rx += int(dx_r)

        # 5) –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –∂—ë—Å—Ç–∫–∏–π –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∑–∞–∑–æ—Ä (>= max(MIN_GAP_PX, LEAN_MIN_GAP_FRAC * W))
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)
        min_gap = max(MIN_GAP_PX, int(LEAN_MIN_GAP_FRAC * W))
        tries = 0
        while (_inner_gap_px(ra, rb) < min_gap) and tries < 80:
            center = W // 2
            # —Ä–∞–∑–≤–æ–¥–∏–º –æ—Ç —Ü–µ–Ω—Ç—Ä–∞, –Ω–æ –Ω–µ –≤—ã—Ö–æ–¥–∏–º –∑–∞ –ø–æ–ª—è
            lx = max(MARGIN, lx - 2) if (lx + L.width // 2) <= center else min(W - L.width - MARGIN, lx + 2)
            rx = min(W - R.width - MARGIN, rx + 2) if (rx + R.width // 2) >= center else max(MARGIN, rx - 2)
            ra = rect_at(lx, yl, L)
            rb = rect_at(rx, yr, R)
            tries += 1

        # 6) –î–µ—Ä–∂–∏–º –ø–∞—Ä—É –≤–Ω—É—Ç—Ä–∏ ¬´–ø–æ–ª–æ—Å—ã¬ª –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ —Ñ–æ–Ω–∞ (—á—Ç–æ–±—ã –Ω–µ ¬´—Å—ä–µ–¥–∞–ª–∏¬ª –≤–∞–∂–Ω—É—é –≥–µ–æ–º–µ—Ç—Ä–∏—é)
        p = _bg_layout_presets(bg_file)
        band_left  = int(W * (p["center_frac"] - p["band_frac"] / 2.0))
        band_right = int(W * (p["center_frac"] + p["band_frac"] / 2.0))

        # –ï—Å–ª–∏ –ª—é–±–∞—è –∏–∑ —Ä–∞–º–æ–∫ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –ø–æ–ª–æ—Å—É ‚Äî —Å–º–µ—â–∞–µ–º –ø–∞—Ä—É —Ü–µ–ª–∏–∫–æ–º, —Å–æ—Ö—Ä–∞–Ω—è—è –∑–∞–∑–æ—Ä
        ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
        shift = 0
        if ra[0] < band_left:
            shift = max(shift, band_left - ra[0])
        if rb[2] > band_right:
            shift = min(shift, band_right - rb[2])  # –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–∞–¥–æ —Å–¥–≤–∏–Ω—É—Ç—å –≤–ª–µ–≤–æ
        lx = max(MARGIN, min(W - L.width - MARGIN, lx + shift))
        rx = max(MARGIN, min(W - R.width - MARGIN, rx + shift))

        # 7) –°—Ç—Ä–∞—Ö–æ–≤–∫–∞ ¬´headroom¬ª (–µ—Å–ª–∏ –ø–æ–¥–ø–∏—Ä–∞–µ–º –≤–µ—Ä—Ö ‚Äî –æ–¥–∏–Ω —Ä–∞–∑ —á—É—Ç—å —É–º–µ–Ω—å—à–∞–µ–º –æ–±–µ)
        ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
        def _headroom_ok(r): return r[1] > int(HEADROOM_FRAC * H)
        if not _headroom_ok(ra) or not _headroom_ok(rb):
            L = _scale_to_vis_frac(L, min(_vis_frac(L) * 0.96, MAX_VISIBLE_FRAC))
            R = _scale_to_vis_frac(R, min(_vis_frac(R) * 0.96, MAX_VISIBLE_FRAC))
            yl = place_y_for_floor(L); yr = place_y_for_floor(R)
            lx = cxL - L.width // 2; rx = cxR - R.width // 2
            # –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º —Ç—Ä–µ–±—É–µ–º—ã–π –∑–∞–∑–æ—Ä (–∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ—Ö–æ–¥)
            ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
            for _ in range(40):
                if _inner_gap_px(ra, rb) >= min_gap: break
                lx = max(MARGIN, lx - 2)
                rx = min(W - R.width - MARGIN, rx + 2)
                ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)

        # 8) –†–∏—Å—É–µ–º
        draw_with_shadow(canvas, L, lx, yl)
        draw_with_shadow(canvas, R, rx, yr)
        try:
            _draw_debug_boxes(canvas, [_rect_at(lx, yl, L), _rect_at(rx, yr, R)])
        except Exception:
            pass

    # --- –º–µ—Ç—Ä–∏–∫–∏/—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ---
    out = f"uploads/start_{base_id}.png"
    metrics = {"W": W, "H": H, "framing": framing_key}

    def _abs_rect(x, y, img):
        (bx, by, bx1, by1), yb = alpha_metrics(img)
        return [x + bx, y + by, x + bx1, y + by1], yb + y

    if len(cuts) == 1:
        rP, fy = _abs_rect(x, y, P)
        h_px = rP[3] - rP[1]
        w_px = rP[2] - rP[0]
        metrics["L"] = {
            "rect_abs": rP, "height_px": int(h_px), "width_px": int(w_px),
            "height_frac": float(h_px) / H,
            "center_x_frac": float((rP[0]+rP[2])/2) / W,
            "scale": float(P.width) / max(1.0, cuts[0].width),
            "floor_y": int(fy)
        }
    else:
        rL, fyl = _abs_rect(lx, yl, L)
        rR, fyr = _abs_rect(rx, yr, R)
        hL = rL[3]-rL[1]; wL = rL[2]-rL[0]
        hR = rR[3]-rR[1]; wR = rR[2]-rR[0]
        gap_px = max(0, rR[0] - rL[2])
        metrics["L"] = {
            "rect_abs": rL, "height_px": int(hL), "width_px": int(wL),
            "height_frac": float(hL)/H,
            "center_x_frac": float((rL[0]+rL[2])/2)/W,
            "scale": float(L.width)/max(1.0, cuts[0].width),
            "floor_y": int(fyl)
        }
        metrics["R"] = {
            "rect_abs": rR, "height_px": int(hR), "width_px": int(wR),
            "height_frac": float(hR)/H,
            "center_x_frac": float((rR[0]+rR[2])/2)/W,
            "scale": float(R.width)/max(1.0, cuts[1].width),
            "floor_y": int(fyr)
        }
        metrics["gap_px"]  = int(gap_px)
        metrics["gap_frac"]= float(gap_px)/W

    if OAI_DEBUG or PREVIEW_START_FRAME:
        _save_layout_debug(canvas, metrics, base_id)
    canvas.save(out, "PNG")
    return out

# ---------- –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê —á–µ—Ä–µ–∑ ffmpeg (wm + –º—É–∑—ã–∫–∞ + —Ç–∏—Ç—Ä + —Å–∫–ª–µ–π–∫–∞) ----------
def create_title_image(width: int, height: int, text: str, output_path: str):
    """–°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–∏—Ç—Ä–æ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–¥–±–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞"""
    title_img = Image.new("RGB", (width, height), (0, 0, 0))
    d = ImageDraw.Draw(title_img)

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞
    max_width = width - 40  # –û—Ç—Å—Ç—É–ø 20 –ø–∏–∫—Å–µ–ª–µ–π —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã
    font_size = 60  # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–æ–ª—å—à–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞

    while font_size > 12:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            font = ImageFont.load_default()

        # –ò–∑–º–µ—Ä—è–µ–º —à–∏—Ä–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ —Å —Ç–µ–∫—É—â–∏–º —à—Ä–∏—Ñ—Ç–æ–º
        bbox = d.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]

        if text_width <= max_width:
            break  # –®—Ä–∏—Ñ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç

        font_size -= 2  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞

    # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ —Ü–µ–Ω—Ç—Ä—É
    d.text((width//2, height//2), text, fill=(255,255,255), font=font, anchor="mm")
    title_img.save(output_path)
    return output_path

def postprocess_concat_ffmpeg(video_paths: List[str], music_path: str|None, title_text: str, save_as: str, bg_overlay_file: str|None = None) -> str:
    """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ ffmpeg (—Å–∫–ª–µ–π–∫–∞ + —Ñ–æ–Ω-–∞–Ω–∏–º–∞—Ü–∏—è + –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫ + –º—É–∑—ã–∫–∞). –° —Ñ–æ–ª–±—ç–∫–æ–º, faststart –∏ –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω–æ–π –∫–æ–ø–∏–µ–π."""
    import tempfile

    def _escape_concat_path(p: str) -> str:
        # —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –¥–ª—è concat-—Ñ–∞–π–ª–∞
        return os.path.abspath(p).replace("'", "'\\''")

    temp_dir = "renders/temp"
    os.makedirs(temp_dir, exist_ok=True)

    # 1) –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∏—Ç—Ä (PNG)
    title_img_path = f"{temp_dir}/title.png"
    create_title_image(720, 1280, title_text, title_img_path)

    # 2) 2-—Å–µ–∫—É–Ω–¥–Ω—ã–π —Ä–æ–ª–∏–∫ –∏–∑ —Ç–∏—Ç—Ä–∞
    title_video_path = f"{temp_dir}/title_video.mp4"
    subprocess.run([
        "ffmpeg", "-y", "-loop", "1", "-i", title_img_path,
        "-t", "2", "-r", "24", "-c:v", "libx264", "-pix_fmt", "yuv420p",
        "-movflags", "+faststart",
        title_video_path
    ], check=True, capture_output=True)

    # 3) –§–∞–π–ª –¥–ª—è concat
    concat_list_path = f"{temp_dir}/concat_list.txt"
    with open(concat_list_path, "w", encoding="utf-8") as f:
        for vp in video_paths:
            f.write(f"file '{_escape_concat_path(vp)}'\n")
        f.write(f"file '{_escape_concat_path(title_video_path)}'\n")

    # 4) –°–∫–ª–µ–π–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ –±–µ–∑ –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)
    concat_video_path = f"{temp_dir}/concat_video.mp4"
    try:
        subprocess.run([
            "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", concat_list_path,
            "-c", "copy", "-movflags", "+faststart",
            concat_video_path
        ], check=True, capture_output=True)
    except subprocess.CalledProcessError:
        # –§–æ–ª–±—ç–∫: –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –æ–±—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å
        subprocess.run([
            "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", concat_list_path,
            "-r", "24",
            "-c:v", "libx264", "-crf", "18", "-preset", "veryfast",
            "-pix_fmt", "yuv420p",
            "-c:a", "aac", "-b:a", "192k", "-ar", "44100",
            "-movflags", "+faststart",
            concat_video_path
        ], check=True, capture_output=True)

    # 4.5) –î–µ–ª–∏–∫–∞—Ç–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è —Ñ–æ–Ω–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞)
    bg_anim_video_path = concat_video_path
    if bg_overlay_file and os.path.isfile(bg_overlay_file):
        try:
            bg_anim_video_path = f"{temp_dir}/with_bg_anim.mp4"
            subprocess.run([
                "ffmpeg", "-y",
                "-i", concat_video_path,
                "-loop", "1", "-i", bg_overlay_file,
                "-filter_complex",
                "[1:v]scale=720:1280,boxblur=25:1,format=rgba,colorchannelmixer=aa=0.08,setsar=1[ov];"
                "[0:v][ov]overlay=x='t*2':y=0:shortest=1,format=yuv420p[v]",
                "-map", "[v]", "-map", "0:a?", "-c:a", "copy",
                "-movflags", "+faststart",
                bg_anim_video_path
            ], check=True, capture_output=True)
        except Exception as e:
            print(f"BG overlay skipped: {e}")
    else:
        print("BG overlay disabled (no file)")

    # 5) –í–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫
    wm_video_path = bg_anim_video_path
    if os.path.isfile(WATERMARK_PATH):
        wm_video_path = f"{temp_dir}/with_watermark.mp4"
        subprocess.run([
            "ffmpeg", "-y", "-i", bg_anim_video_path, "-i", WATERMARK_PATH,
            "-filter_complex", "[1:v]scale=120:-1[wm];[0:v][wm]overlay=W-w-24:24",
            "-c:a", "copy",
            "-movflags", "+faststart",
            wm_video_path
        ], check=True, capture_output=True)

    # 6) –ú—É–∑—ã–∫–∞ (–∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å)
    if music_path and os.path.isfile(music_path):
        # –∑–∞—Ü–∏–∫–ª–∏—Ç—å –º—É–∑—ã–∫—É –∏ –ø–æ–¥–ª–æ–∂–∏—Ç—å –ø–æ–¥ –≤–∏–¥–µ–æ
        subprocess.run([
            "ffmpeg", "-y",
            "-stream_loop", "-1", "-i", music_path,     # –±–µ—Å–∫–æ–Ω–µ—á–Ω–∞—è –º—É–∑—ã–∫–∞
            "-i", wm_video_path,                         # –≤–∏–¥–µ–æ
            "-map", "1:v", "-map", "0:a",
            "-c:v", "copy",
            "-c:a", "aac", "-ar", "44100",
            "-shortest", "-af", "volume=0.6",
            "-movflags", "+faststart",
            save_as
        ], check=True, capture_output=True)
    else:
        # –ø–æ—Ä—Ç–∞—Ç–∏–≤–Ω–∞—è –∫–æ–ø–∏—è + faststart
        import shutil
        shutil.copyfile(wm_video_path, save_as)
        try:
            tmp_fast = f"{temp_dir}/faststart.mp4"
            subprocess.run([
                "ffmpeg", "-y", "-i", save_as, "-c", "copy", "-movflags", "+faststart", tmp_fast
            ], check=True, capture_output=True)
            shutil.move(tmp_fast, save_as)
        except Exception:
            pass

    return save_as

def cleanup_dir_keep_last_n(dir_path: str, keep_n: int = 10, extensions: tuple[str, ...] = ()):
    try:
        items = []
        for name in os.listdir(dir_path):
            p = os.path.join(dir_path, name)
            if os.path.isfile(p):
                if not extensions or name.lower().endswith(extensions):
                    items.append((p, os.path.getmtime(p)))
        items.sort(key=lambda x: x[1], reverse=True)
        for p, _ in items[keep_n:]:
            try:
                os.remove(p)
            except Exception:
                pass
    except FileNotFoundError:
        pass

def cleanup_artifacts(keep_last: int = 10):
    # –ü–æ–ª–Ω–æ—Å—Ç—å—é —á–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É —Ä–µ–Ω–¥–µ—Ä–æ–≤ (–∫—Ä–æ–º–µ —Ä–µ–∂–∏–º–∞ –æ—Ç–ª–∞–¥–∫–∏)
    if not OAI_DEBUG:
        shutil.rmtree("renders/temp", ignore_errors=True)
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ –∏ —Ñ–∏–Ω–∞–ª–æ–≤
    cleanup_dir_keep_last_n("uploads", keep_n=keep_last, extensions=(".jpg", ".jpeg", ".png", ".webp"))
    cleanup_dir_keep_last_n("renders", keep_n=keep_last, extensions=(".mp4", ".mov", ".mkv", ".webm"))

def _download_tg_photo(file_id: str, uid: int) -> str:
    fi = bot.get_file(file_id)
    content = requests.get(f"https://api.telegram.org/file/bot{TG_TOKEN}/{fi.file_path}", timeout=120).content
    pth = f"uploads/{uid}_{int(time.time())}_{uuid.uuid4().hex}.jpg"
    with open(pth, "wb") as f:
        f.write(content)
    return pth

# ---------- –•–≠–ù–î–õ–ï–†–´ ----------
@bot.message_handler(commands=["start","reset"])
def start_cmd(m: telebot.types.Message):
    uid = m.from_user.id
    # –°–±—Ä–æ—Å —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –ø–æ–∫–∞–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
    users[uid] = new_state()
    show_main_menu(uid, '–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ, –Ω–∞–∂–∞–≤ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª.')

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é (–∫–Ω–æ–ø–∫–∞)
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_MAIN)
def on_menu_main(m: telebot.types.Message):
    uid = m.from_user.id
    # –ù–µ —Ç—Ä–æ–≥–∞–µ–º —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é
    show_main_menu(uid)

# –ó–∞–ø—É—Å–∫ –º–∞—Å—Ç–µ—Ä–∞ (–∫–Ω–æ–ø–∫–∞ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª)
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_START)
def on_menu_start_wizard(m: telebot.types.Message):
    uid = m.from_user.id
    users[uid] = new_state()
    bot.send_message(
        uid,
        "–®–∞–≥ 1/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞</b>.",
        reply_markup=kb_formats()
    )

# –°—Ç–æ–∏–º–æ—Å—Ç—å
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_PRICE)
def on_menu_price(m: telebot.types.Message):
    uid = m.from_user.id
    price_text = (
        "<b>–°—Ç–æ–∏–º–æ—Å—Ç—å</b>\n\n"
        "‚Ä¢ 5 —Å–µ–∫ ‚Äî <b>–±–µ—Å–ø–ª–∞—Ç–Ω–æ</b>\n"
        "‚Ä¢ –õ—é–±–æ–π –¥—Ä—É–≥–æ–π —Å—é–∂–µ—Ç (10—Å) ‚Äî <b>100</b>\n"
        "‚Ä¢ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—é–∂–µ—Ç–æ–≤ ‚Äî —Å—É–º–º–∞ —Ü–µ–Ω –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—é–∂–µ—Ç–æ–≤\n"
        "‚Ä¢ –ú—É–∑—ã–∫–∞ ‚Äî <b>50</b>\n"
        "‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–∏—Ç—Ä—ã ‚Äî <b>50</b>\n"
        "‚Ä¢ –í—Ç–æ—Ä–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è (–¥—Ä—É–≥–æ–π —Å–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏) ‚Äî <b>+50%</b> –∫ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n"
    )
    bot.send_message(uid, price_text, reply_markup=kb_main_menu())

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_GUIDE)
def on_menu_guide(m: telebot.types.Message):
    uid = m.from_user.id
    guide = (
        "<b>–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ</b>\n"
        "1) –ù–∞–∂–º–∏—Ç–µ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª.\n"
        "2) –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞.\n"
        "3) –í—ã–±–µ—Ä–∏—Ç–µ —Å—é–∂–µ—Ç—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ) ‚Üí ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.\n"
        "4) –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ–Ω.\n"
        "5) –í—ã–±–µ—Ä–∏—Ç–µ –º—É–∑—ã–∫—É (–∏–ª–∏ ¬´–ë–µ–∑ –º—É–∑—ã–∫–∏¬ª).\n"
        "6) –ü—Ä–∏—à–ª–∏—Ç–µ 1‚Äì2 —Ñ–æ—Ç–æ –∞–Ω—Ñ–∞—Å (–∫–∞–∂–¥–æ–≥–æ ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ).\n"
        "7) –î–æ–∂–¥–∏—Ç–µ—Å—å —Ä–µ–Ω–¥–µ—Ä–∞ ‚Äî –∏—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ –ø—Ä–∏–¥—ë—Ç —Å—é–¥–∞.\n\n"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: —á–µ–º –ª—É—á—à–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç —Å —Ñ–æ–Ω–æ–º –Ω–∞ —Ñ–æ—Ç–æ ‚Äî —Ç–µ–º —á–∏—â–µ –≤—ã—Ä–µ–∑–∞–Ω–∏–µ."
    )
    bot.send_message(uid, guide, reply_markup=kb_main_menu())

# –ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_DEMO)
def on_menu_demo(m: telebot.types.Message):
    uid = m.from_user.id
    demo_dir = "assets/examples"
    paths = [
        os.path.join(demo_dir, "example1.mp4"),
        os.path.join(demo_dir, "example2.mp4"),
        os.path.join(demo_dir, "example3.mp4"),
    ]
    sent = False
    for p in paths:
        if os.path.isfile(p):
            with open(p, "rb") as f:
                bot.send_video(uid, f)
            sent = True
    if not sent:
        bot.send_message(uid, "–ó–∞–≥—Ä—É–∑–∏—Ç–µ 3 —Ñ–∞–π–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –ø–∞–ø–∫—É <code>assets/examples</code> –ø–æ–¥ –∏–º–µ–Ω–∞–º–∏ example1.mp4, example2.mp4, example3.mp4", reply_markup=kb_main_menu())

# –¢–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_SUPPORT)
def on_menu_support(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["support"] = True
    bot.send_message(uid, "–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ú—ã —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏. (–î–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞–∂–º–∏—Ç–µ ¬´–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é¬ª).", reply_markup=kb_main_menu())

@bot.message_handler(func=lambda msg: msg.text=="üîÅ –°–±—Ä–æ—Å–∏—Ç—å –≤—ã–±–æ—Ä —Å—é–∂–µ—Ç–æ–≤")
def reset_scenes(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["scenes"] = []
    bot.send_message(uid, "–°—é–∂–µ—Ç—ã –æ—á–∏—â–µ–Ω—ã. –í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.", reply_markup=kb_scenes(st.get("format")))

@bot.message_handler(func=lambda msg: msg.text=="‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ")
def after_scenes(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    if not st["scenes"]:
        bot.send_message(uid, "–ü–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ. –û—Ç–º–µ—Ç—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å—é–∂–µ—Ç.",
                         reply_markup=kb_scenes(st.get("format")))
        return
    bot.send_message(uid, "–®–∞–≥ 3/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Ñ–æ–Ω</b>.", reply_markup=kb_backgrounds())

@bot.message_handler(func=lambda msg: msg.text in SCENES.keys())
def choose_scene(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –µ—â—ë –Ω–µ –≤—ã–±—Ä–∞–Ω (–Ω–∞ –≤—Å—è–∫–∏–π) ‚Äî –ø—Ä–æ—Å–∏–º –≤—ã–±—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç
    if not st.get("format"):
        bot.send_message(uid, "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞ (–®–∞–≥ 1/5).", reply_markup=kb_formats())
        return

    allowed = set(available_scene_keys(st["format"]))
    if m.text not in allowed:
        # –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è ¬´–ª–µ—Å—Ç–Ω–∏—Ü—ã¬ª
        if SCENES.get(m.text, {}).get("kind") == "stairs":
            bot.send_message(uid, "–°—é–∂–µ—Ç ¬´–£—Ö–æ–¥–∏—Ç –≤ –Ω–µ–±–µ—Å–∞¬ª –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ ¬´üßç –í —Ä–æ—Å—Ç¬ª. "
                                  "–ü–æ–º–µ–Ω—è–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π —Å—é–∂–µ—Ç.",
                             reply_markup=kb_scenes(st["format"]))
        else:
            bot.send_message(uid, "–≠—Ç–æ—Ç —Å—é–∂–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞.", reply_markup=kb_scenes(st["format"]))
        return

    if m.text not in st["scenes"]:
        st["scenes"].append(m.text)

    picked = " ¬∑ ".join(st["scenes"])
    bot.send_message(uid, f"–í—ã–±—Ä–∞–Ω–æ: {picked}\n–î–æ–±–∞–≤—å—Ç–µ –µ—â—ë –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.",
                     reply_markup=kb_scenes(st["format"]))

@bot.message_handler(func=lambda msg: msg.text in FORMATS.keys())
def choose_format(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["format"] = m.text
    st["scenes"] = []  # –æ–±–Ω—É–ª—è–µ–º –≤—ã–±–æ—Ä —Å—Ü–µ–Ω –ø–æ–¥ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
    bot.send_message(
        uid,
        "–®–∞–≥ 2/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Å—é–∂–µ—Ç—ã</b> (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ). –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–∂–º–∏—Ç–µ ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.",
        reply_markup=kb_scenes(st["format"])
    )

@bot.message_handler(func=lambda msg: msg.text in BACKGROUNDS.keys())
def choose_background(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["bg"] = m.text
    bot.send_message(uid, "–®–∞–≥ 4/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º—É–∑—ã–∫—É</b> (–∏–ª–∏ ¬´–ë–µ–∑ –º—É–∑—ã–∫–∏¬ª).", reply_markup=kb_music())

@bot.message_handler(func=lambda msg: msg.text in MUSIC.keys() or msg.text=="üîá –ë–µ–∑ –º—É–∑—ã–∫–∏")
def choose_music(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["music"] = None if m.text=="üîá –ë–µ–∑ –º—É–∑—ã–∫–∏" else m.text
    # –°–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –Ω–∞–¥–æ?
    if not st["scenes"]:
        bot.send_message(uid, "–û—à–∏–±–∫–∞: –Ω–µ –≤—ã–±—Ä–∞–Ω—ã —Å—é–∂–µ—Ç—ã. –ù–∞—á–Ω–∏—Ç–µ —Å /start")
        return
    need_people = max(SCENES[k]["people"] for k in st["scenes"])
    bot.send_message(uid, f"–®–∞–≥ 5/5. –ü—Ä–∏—à–ª–∏—Ç–µ {need_people} —Ñ–æ—Ç–æ (–∞–Ω—Ñ–∞—Å).")

@bot.message_handler(func=lambda msg: msg.text == BTN_GO_HOME)
def go_home(m: telebot.types.Message):
    uid = m.from_user.id
    # –ù–µ –ª–æ–º–∞–µ–º —Ç–µ–∫—É—â—É—é –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é
    show_main_menu(uid)

@bot.message_handler(content_types=["photo"])
def on_photo(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ—à–ª–∏ —à–∞–≥–∏ –¥–æ —Ñ–æ—Ç–æ
    # –ú—É–∑—ã–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å ¬´–±–µ–∑ –º—É–∑—ã–∫–∏¬ª, –ø–æ—ç—Ç–æ–º—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —á—Ç–æ —Å—Ü–µ–Ω–∏–π/—Ñ–æ—Ä–º–∞—Ç/—Ñ–æ–Ω –≤—ã–±—Ä–∞–Ω—ã
    if not (st["scenes"] and st["format"] and st["bg"]):
        bot.send_message(uid, "–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ —à–∞–≥–∏: –§–æ—Ä–º–∞—Ç ‚Üí –°—é–∂–µ—Ç(—ã) ‚Üí –§–æ–Ω ‚Üí (–ú—É–∑—ã–∫–∞ ‚Äî –º–æ–∂–Ω–æ ¬´–ë–µ–∑ –º—É–∑—ã–∫–∏¬ª).")
        return

    need_people = max(SCENES[k]["people"] for k in st["scenes"])

    # 1) –ï—Å–ª–∏ —Å—Ü–µ–Ω–∞ —Å 1 —á–µ–ª–æ–≤–µ–∫–æ–º –∏ —Ñ–æ—Ç–æ —É–∂–µ –µ—Å—Ç—å ‚Äî –≤–µ–∂–ª–∏–≤–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
    if need_people == 1 and len(st["photos"]) >= 1:
        bot.send_message(uid, "–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—é–∂–µ—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ç–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é –ø–µ—Ä–≤–æ–µ.")
        return

    # 2) –°–∫–∞—á–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–æ—Ç–∫—É
    file_id = m.photo[-1].file_id
    saved_path = _download_tg_photo(file_id, uid)

    # --- –ú—è–≥–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ç–æ ---
    ok_photo, warns = validate_photo(saved_path)
    if warns:
        bot.send_message(uid, "‚ö†Ô∏è –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ —Ñ–æ—Ç–æ:\n" + "\n".join(f"‚Ä¢ {w}" for w in warns))
    if not ok_photo:
        bot.send_message(uid, "–§–æ—Ç–æ –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –ú–æ–∂–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Ö—É–∂–µ. "
                              "–ï—Å–ª–∏ –µ—Å—Ç—å –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ ‚Äî –ø—Ä–∏—à–ª–∏—Ç–µ –µ—â—ë –æ–¥–Ω–æ. –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ.")

    # 3) –ï—Å–ª–∏ —ç—Ç–æ –∞–ª—å–±–æ–º (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ —Å –æ–¥–Ω–∏–º media_group_id)
    if m.media_group_id:
        rec = PENDING_ALBUMS.setdefault(m.media_group_id, {"uid": uid, "need": need_people, "paths": []})
        # –ï—Å–ª–∏ –∞–ª—å–±–æ–º –ø—Ä–∏—à—ë–ª –∫ –¥—Ä—É–≥–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é/–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ‚Äî –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º –ø–æ–¥ —Ç–µ–∫—É—â–µ–≥–æ
        rec["uid"] = uid
        rec["need"] = need_people
        rec["paths"].append(saved_path)

        # –ö–æ–≥–¥–∞ —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å—é–∂–µ—Ç–∞ ‚Äî –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ —Å—Ç–µ–π—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        if len(rec["paths"]) >= need_people:
            # –ë–µ—Ä—ë–º —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            st["photos"].extend(rec["paths"][:need_people])
            # –ß–∏—Å—Ç–∏–º –±—É—Ñ–µ—Ä –∞–ª—å–±–æ–º–∞
            PENDING_ALBUMS.pop(m.media_group_id, None)

            bot.send_message(uid, "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é‚Ä¶")
            try:
                run_all_and_send(uid, st)
            except Exception as e:
                print("GEN ERR:", e)
                bot.send_message(uid, f"–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫: {e}")
            finally:
                users[uid] = new_state()
                show_main_menu(uid)
        # –ï—Å–ª–∏ –ø–æ–∫–∞ —Ñ–æ—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –≥–æ–≤–æ—Ä–∏–º (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ ¬´–û—Å—Ç–∞–ª–æ—Å—å 1¬ª –Ω–∞ –ø–µ—Ä–≤–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ –∞–ª—å–±–æ–º–∞)
        return

    # 4) –û–±—ã—á–Ω–æ–µ –æ–¥–∏–Ω–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–æ—Ç–æ (–Ω–µ –∞–ª—å–±–æ–º)
    st["photos"].append(saved_path)

    if len(st["photos"]) < need_people:
        left = need_people - len(st["photos"])
        bot.send_message(uid, f"–§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ ‚úÖ  –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏—Å–ª–∞—Ç—å –µ—â—ë {left}.")
        return

    # –°–æ–±—Ä–∞–ª–∏ –≤—Å—ë ‚Äî –≥–µ–Ω–µ—Ä–∏–º
    bot.send_message(uid, "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é‚Ä¶")
    try:
        run_all_and_send(uid, st)
    except Exception as e:
        print("GEN ERR:", e)
        bot.send_message(uid, f"–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫: {e}")
    finally:
        users[uid] = new_state()
        show_main_menu(uid)

@bot.message_handler(commands=["cfg"])
def cmd_cfg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    txt = (
        f"<b>Config</b>\n"
        f"PREVIEW_START_FRAME: {PREVIEW_START_FRAME}\n"
        f"DEBUG_TO_ADMIN: {DEBUG_TO_ADMIN}\n"
        f"RUNWAY_SEND_JPEG: {RUNWAY_SEND_JPEG}\n"
    )
    bot.reply_to(m, txt)

@bot.message_handler(commands=["preview_on", "preview_off"])
def cmd_preview(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global PREVIEW_START_FRAME
    PREVIEW_START_FRAME = (m.text == "/preview_on")
    bot.reply_to(m, f"PREVIEW_START_FRAME = {PREVIEW_START_FRAME}")

@bot.message_handler(commands=["admdbg_on", "admdbg_off"])
def cmd_admdbg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global DEBUG_TO_ADMIN
    DEBUG_TO_ADMIN = (m.text == "/admdbg_on")
    bot.reply_to(m, f"DEBUG_TO_ADMIN = {DEBUG_TO_ADMIN}")

@bot.message_handler(commands=["jpeg_on", "jpeg_off"])
def cmd_jpeg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global RUNWAY_SEND_JPEG
    RUNWAY_SEND_JPEG = (m.text == "/jpeg_on")
    bot.reply_to(m, f"RUNWAY_SEND_JPEG = {RUNWAY_SEND_JPEG}")

# ---------- –ü–ê–ô–ü–õ–ê–ô–ù ----------
# === HARD-OFF for OpenAI Assistants (safe stub layer) =========================
# –û—Ç–∫–ª—é—á–∞–µ–º –ª—é–±—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏/–¥–æ–±–∞–≤–∫–∏ –æ—Ç Assistant'–∞ –∏ –¥–µ–ª–∞–µ–º —Ñ—É–Ω–∫—Ü–∏–∏-—Å—Ç–∞–±—ã.

try:
    ASSISTANT_GATE_ENABLED = False  # –Ω–∞ –≤—Å—è–∫–∏–π ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ OFF
except NameError:
    pass

def _short_gate(g: dict | None) -> str:  # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø—Ä–µ–≤—å—é ‚Äî –æ—Å—Ç–∞–≤–∏–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
    return "gate: disabled"

def _normalize_gate(g: dict | None) -> dict | None:
    return None

def oai_upload_image(path: str) -> str | None:
    # –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –Ω–∏—á–µ–≥–æ –≤ Assistants
    return None

def oai_create_thread_with_image(user_text: str, file_id: str) -> str | None:
    # –Ω–µ —Å–æ–∑–¥–∞—ë–º thread –≤ Assistants
    return None

def oai_gate_check(start_frame_path: str, base_prompt: str, meta: dict, timeout_sec: int = 120) -> dict | None:
    # –≤—Å–µ–≥–¥–∞ ¬´–±–µ–∑ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–∞¬ª: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    return None

# ==============================================================================
def run_all_and_send(uid: int, st: dict):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ-—É—Å—Ç–æ–π—á–∏–≤—ã–π –ø–∞–π–ø–ª–∞–π–Ω –±–µ–∑ OpenAI Assistants:
    - —Å—Ç—Ä–æ–∏–º —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä;
    - —Å–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç (–ø–ª—é—Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –¥–æ–±–∞–≤–∫–∏);
    - –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–≤—å—é (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ);
    - –≥–æ–Ω—è–µ–º Runway (c —Ñ–æ–ª–±—ç–∫–æ–º –Ω–∞ 5—Å –ø—Ä–∏ 4xx);
    - –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    framing_text = FORMATS[st["format"]]
    bg_prompt    = BG_TEXT[st["bg"]]                      # –º—è–≥–∫–∞—è –∞–Ω–∏–º–∞—Ü–∏—è —Ñ–æ–Ω–∞
    music_path   = MUSIC.get(st["music"]) if st["music"] else None
    bg_file      = BG_FILES[st["bg"]]                     # ¬´–ø–ª–µ–π—Ç¬ª (–∫–∞—Ä—Ç–∏–Ω–∫–∞ —Ñ–æ–Ω–∞)

    out_videos = []

    for scene_key in st["scenes"]:
        scene = SCENES[scene_key]

        # 1) –°—Ç–∞—Ä—Ç-–∫–∞–¥—Ä (–±–µ–∑ —Ä—É—á–Ω–æ–≥–æ layout ‚Äî –æ–Ω —É–∂–µ –≤–Ω—É—Ç—Ä–∏ make_start_frame –¥–µ–ª–∞–µ—Ç LEAN-—Ä–∞—Å–∫–ª–∞–¥–∫—É)
        start_frame = make_start_frame(st["photos"], st["format"], bg_file, layout=None)

        # 2) –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç + –∂–µ—Å—Ç–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –≥–µ–æ–º–µ—Ç—Ä–∏—é + ¬´—Å—Ç—Ä–∞—Ö—É—é—â–∏–µ¬ª –¥–æ–±–∞–≤–∫–∏ (–≤—Å–µ–≥–¥–∞)
        base_prompt = build_prompt(scene["kind"], framing_text, bg_prompt, scene["duration"])
        base_prompt += (
            "; lock geometry exactly as in the provided start frame (positions and scales)"
            "; no zoom, no dolly, no push-in/out, no drift; keep constant relative size"
            "; full-body shot; preserve limb topology; no body/limb deformation; no warping"
            "; do not change background plate geometry; do not crop heads, hands, or feet"
        )
        prompt = compact_prompt(base_prompt + " " + BACKUP_PROMPT_ADDITIONS)

        # 3) –ü—Ä–µ–≤—å—é (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        try:
            if PREVIEW_START_FRAME:
                _send_debug_preview(uid, scene_key, start_frame, prompt, gate=None)  # gate –æ—Ç–∫–ª—é—á–µ–Ω
        except Exception as _e:
            print(f"[DBG] preview send err: {_e}")

        # 4) –ì–æ—Ç–æ–≤–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Runway (JPEG –ø–æ —Ñ–ª–∞–≥—É + –∫–æ–Ω—Ç—Ä–æ–ª—å –ª–∏–º–∏—Ç–∞ data URI)
        send_path = ensure_jpeg_copy(start_frame) if RUNWAY_SEND_JPEG else start_frame
        data_uri, used_path = ensure_runway_datauri_under_limit(send_path)
        try:
            fs = os.path.getsize(used_path)
            print(f"[Runway] start_frame path={used_path} size={fs} bytes (jpeg={RUNWAY_SEND_JPEG})")
        except Exception:
            pass
        if not data_uri or len(data_uri) < 64:
            bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª: –ø—É—Å—Ç–æ–π data URI —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä–∞")
            continue
        if len(data_uri) > 5_000_000:
            print(f"[Runway warn] data URI length {len(data_uri)} > 5MB; consider lower JPEG quality.")

        # 5) –ó–∞–ø—É—Å–∫ Runway —Å —Ñ–æ–ª–±—ç–∫–æ–º –Ω–∞ 5—Å –ø—Ä–∏ 4xx
        try:
            start_resp = runway_start(data_uri, prompt, scene["duration"])
        except RuntimeError as e:
            msg = str(e)
            if "400/4xx" in msg and int(scene["duration"]) > 5:
                bot.send_message(uid, f"‚ö†Ô∏è Runway –æ—Ç–∫–∞–∑–∞–ª –≤ {scene['duration']}—Å –¥–ª—è ¬´{scene_key}¬ª. –ü—Ä–æ–±—É—é 5—Å.")
                prompt_short = compact_prompt(
                    build_prompt(scene["kind"], framing_text, bg_prompt, 5) + " " + BACKUP_PROMPT_ADDITIONS
                )
                try:
                    start_resp = runway_start(data_uri, prompt_short, 5)
                    prompt = prompt_short  # —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç/–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ—Ç–ª–∞–¥–∫–µ
                except Exception as e2:
                    bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª —É–ø–∞–ª–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ: {e2}")
                    _log_fail(uid, "runway_4xx_fallback_failed",
                              {"scene": scene_key, "prompt_len": len(prompt)}, str(e2))
                    continue
            else:
                bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª —É–ø–∞–ª–∞ —Å –æ—à–∏–±–∫–æ–π: {e}")
                _log_fail(uid, "runway_start_failed",
                          {"scene": scene_key, "prompt_len": len(prompt)}, str(e))
                continue

        task_id = start_resp.get("id") or start_resp.get("task", {}).get("id")
        if not task_id:
            bot.send_message(uid, f"–ù–µ –ø–æ–ª—É—á–∏–ª id –∑–∞–¥–∞—á–∏ –æ—Ç Runway –¥–ª—è ¬´{scene_key}¬ª. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
            _log_fail(uid, "no_task_id", {"scene": scene_key, "prompt_len": len(prompt)}, start_resp)
            continue

        # 6) –û–∂–∏–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        poll = runway_poll(task_id)
        if poll.get("status") != "SUCCEEDED":
            msg = (f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª –Ω–µ —É–¥–∞–ª–∞—Å—å: {poll.get('status')}. "
                   f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–æ–Ω –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç ¬´üßç –í —Ä–æ—Å—Ç¬ª, –∏ —Ñ–æ—Ç–æ, –≥–¥–µ —á–µ–ª–æ–≤–µ–∫(–∏) –≤–∏–¥–Ω—ã —Ü–µ–ª–∏–∫–æ–º.")
            bot.send_message(uid, msg)
            _log_fail(uid, "poll_failed", {"scene": scene_key, "prompt_len": len(prompt)}, poll)
            continue

        out = poll.get("output") or []
        url = out[0] if isinstance(out[0], str) else (out[0].get("url") if out else None)
        if not url:
            bot.send_message(uid, f"Runway –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É –¥–ª—è ¬´{scene_key}¬ª.")
            _log_fail(uid, "no_url", {"scene": scene_key}, poll)
            continue

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        save_as = f"renders/{uid}_{timestamp}_{uuid.uuid4().hex}.mp4"
        download(url, save_as)
        out_videos.append(save_as)

        # 7) –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –¥–∞–º–ø (–∫–æ—Ä–æ—Ç–∫–∏–π)
        try:
            if OAI_DEBUG:
                os.makedirs("renders/temp", exist_ok=True)
                dbg_path = os.path.join("renders/temp", f"runway_dbg_{uid}_{uuid.uuid4().hex}.json")
                with open(dbg_path, "w", encoding="utf-8") as f:
                    json.dump({
                        "scene": scene_key,
                        "format": st["format"],
                        "background": st["bg"],
                        "start_frame": used_path,
                        "final_prompt": prompt
                    }, f, ensure_ascii=False, indent=2)
                print(f"[RUNWAY DBG] saved {dbg_path}\n[RUNWAY DBG] final_prompt_len={len(prompt)}")
        except Exception as _e:
            print(f"[RUNWAY DBG] save error: {_e}")

    # --- –§–∏–Ω–∞–ª: –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ ---
    if not out_videos:
        bot.send_message(uid, "–ù–∏ –æ–¥–Ω–∞ —Å—Ü–µ–Ω–∞ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ç–æ.")
        users[uid] = new_state()
        show_main_menu(uid)
        return

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    final_path = f"renders/{uid}_{timestamp}_{uuid.uuid4().hex}_FINAL.mp4"
    title_text = "Memory Forever ‚Äî –ü–∞–º—è—Ç—å –Ω–∞–≤—Å–µ–≥–¥–∞ —Å –≤–∞–º–∏"

    try:
        postprocess_concat_ffmpeg(out_videos, music_path, title_text, final_path, bg_overlay_file=bg_file)
    except Exception as e:
        print(f"Postprocess error: {e}")
        bot.send_message(uid, f"–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å ({e}). –®–ª—é —Å—ã—Ä—ã–µ —Å—Ü–µ–Ω—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏.")
        for i, p in enumerate(out_videos, 1):
            with open(p, "rb") as f:
                bot.send_video(uid, f, caption=f"–°—Ü–µ–Ω–∞ {i}")
        cleanup_artifacts(keep_last=10)
        users[uid] = new_state()
        show_main_menu(uid, "–ì–æ—Ç–æ–≤–æ! –í–∏–¥–µ–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã (–ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å).")
        return

    with open(final_path, "rb") as f:
        cap = " ¬∑ ".join(st["scenes"]) + f" ¬∑ {st['format']}"
        bot.send_video(uid, f, caption=cap)

    cleanup_artifacts(keep_last=10)
    users[uid] = new_state()
    show_main_menu(uid, "–ì–æ—Ç–æ–≤–æ! –í–∏–¥–µ–æ —Å–æ–∑–¥–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ.")
# ==============================================================================

# ---------- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò CALLBACK-–ö–ù–û–ü–û–ö –ú–£–ó–´–ö–ò ----------
@bot.callback_query_handler(func=lambda call: call.data.startswith("listen_"))
def on_music_listen(call):
    uid = call.from_user.id
    music_name = call.data.replace("listen_", "")
    music_path = MUSIC_BY_CLEAN.get(music_name)   # ‚Üê –±–µ–∑ find_music_by_name

    if music_path and os.path.isfile(music_path):
        try:
            with open(music_path, 'rb') as audio:
                bot.send_audio(uid, audio, title=music_name, performer="Memory Forever")
            bot.answer_callback_query(call.id, f"üéß –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è: {music_name}")
        except Exception as e:
            bot.answer_callback_query(call.id, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ: {e}")
    else:
        bot.answer_callback_query(call.id, "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")


@bot.callback_query_handler(func=lambda call: call.data.startswith("select_music_"))
def on_music_select(call):
    uid = call.from_user.id
    st = users.setdefault(uid, new_state())

    music_choice = call.data.replace("select_music_", "")

    if music_choice == "none":
        st["music"] = None
        bot.answer_callback_query(call.id, "üîá –í—ã–±—Ä–∞–Ω–æ: –ë–µ–∑ –º—É–∑—ã–∫–∏")
    else:
        if music_choice in MUSIC_BY_CLEAN:
            st["music"] = f"üéµ {music_choice}"        # —Ö—Ä–∞–Ω–∏–º –∫–ª—é—á, –∫–∞–∫ –≤ –º–µ–Ω—é
            bot.answer_callback_query(call.id, f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: {music_choice}")
        else:
            bot.answer_callback_query(call.id, "–ú—É–∑—ã–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

    if not st["scenes"]:
        bot.send_message(uid, "–û—à–∏–±–∫–∞: –Ω–µ –≤—ã–±—Ä–∞–Ω—ã —Å—é–∂–µ—Ç—ã. –ù–∞—á–Ω–∏—Ç–µ —Å /start")
        return

    need_people = max(SCENES[k]["people"] for k in st["scenes"])
    bot.send_message(uid, f"–®–∞–≥ 5/5. –ü—Ä–∏—à–ª–∏—Ç–µ {need_people} —Ñ–æ—Ç–æ (–∞–Ω—Ñ–∞—Å).")

@bot.callback_query_handler(func=lambda call: call.data == "go_home")
def on_go_home_callback(call):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–∫–∏ '–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é' –∏–∑ inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã"""
    uid = call.from_user.id
    bot.answer_callback_query(call.id, "üè† –ü–µ—Ä–µ—Ö–æ–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
    show_main_menu(uid)

@bot.message_handler(func=lambda msg: True, content_types=["text"])
def fallback_text(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –ï—Å–ª–∏ –∂–¥—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ ‚Äî –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º –∞–¥–º–∏–Ω—É –∏ –≤—ã—Ö–æ–¥–∏–º –≤ –º–µ–Ω—é
    if st.get("support"):
        if ADMIN_CHAT_ID:
            # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ñ–æ—Ä–≤–∞—Ä–¥
            ok = True
            try:
                bot.forward_message(int(ADMIN_CHAT_ID), uid, m.message_id)
            except Exception:
                ok = False
            # –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ñ–æ—Ä–≤–∞—Ä–¥–æ–º ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
            if not ok:
                uname = (m.from_user.username or "")
                header = f"–°–æ–æ–±—â–µ–Ω–∏–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –æ—Ç @{uname} (id {uid}):"
                bot.send_message(int(ADMIN_CHAT_ID), f"{header}\n\n{m.text}")
        else:
            bot.send_message(uid, "–ê–¥—Ä–µ—Å –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –£–∫–∞–∂–∏—Ç–µ ADMIN_CHAT_ID –≤ Secrets.")

        st["support"] = False
        show_main_menu(uid, "–°–ø–∞—Å–∏–±–æ! –°–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–Ω–æ. –ú—ã —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏.")
        return

    # –ò–Ω–∞—á–µ ‚Äî –≤–µ–∂–ª–∏–≤—ã–π –Ω–∞–º—ë–∫, —á—Ç–æ –Ω–∞–¥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–Ω–æ–ø–∫–∞–º–∏
    # (–Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–º–∞–µ–º, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é)
    show_main_menu(uid, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.")

# ---------- RUN ----------
if __name__ == "__main__":
    print("Memory Forever v0.3 started.")
    bot.infinity_polling(skip_pending=True, timeout=60) 
