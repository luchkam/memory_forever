# bot.py ‚Äî Memory Forever v0.3
# –®–∞–≥–∏: –°—é–∂–µ—Ç(—ã) ‚Üí –§–æ—Ä–º–∞—Ç ‚Üí –§–æ–Ω ‚Üí –ú—É–∑—ã–∫–∞ ‚Üí –§–æ—Ç–æ(1/2) ‚Üí Runway ‚Üí –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ (wm+audio+—Ç–∏—Ç—Ä) ‚Üí –æ—Ç–ø—Ä–∞–≤–∫–∞
import os, io, time, uuid, base64, requests, subprocess, shutil, json
from datetime import datetime
from typing import List
from PIL import Image, ImageDraw, ImageFont
import numpy as np
from PIL import ImageFilter
os.environ.setdefault("U2NET_HOME", os.path.join(os.getcwd(), "models"))
from rembg import remove, new_session
RMBG_SESSION = new_session("u2net")
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤
RMBG_HUMAN = new_session("u2net_human_seg")
RMBG_ISNET  = new_session("isnet-general-use")
import telebot

# ---------- –ö–õ–Æ–ß–ò ----------
TG_TOKEN   = os.environ.get("TELEGRAM_BOT_TOKEN", "")
RUNWAY_KEY = os.environ.get("RUNWAY_API_KEY", "")
if not TG_TOKEN or not RUNWAY_KEY:
    print("‚ö†Ô∏è –ó–∞–¥–∞–π TELEGRAM_BOT_TOKEN –∏ RUNWAY_API_KEY –≤ Secrets.")
bot = telebot.TeleBot(TG_TOKEN, parse_mode="HTML")
OPENAI_API_KEY   = os.environ.get("OPENAI_API_KEY", "")
OAI_ASSISTANT_ID = os.environ.get("OAI_ASSISTANT_ID", "")  # id –∏–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (asst_...)
OAI_BASE = "https://api.openai.com/v1"
OAI_HEADERS = {
    "Authorization": f"Bearer {OPENAI_API_KEY}",
    "Content-Type": "application/json",
    "OpenAI-Beta": "assistants=v2",
}
OAI_DEBUG = os.environ.get("OAI_DEBUG", "0") == "1"  # –≤–∫–ª—é—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ª–æ–≥, –µ—Å–ª–∏ –Ω–∞–¥–æ
# –í–∏–∑—É–∞–ª—å–Ω–æ–µ –ø—Ä–µ–≤—å—é —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä–∞ –∏ –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–µ–¥ Runway)
PREVIEW_START_FRAME = os.environ.get("PREVIEW_START_FRAME", "0") == "1"  # 1 ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
DEBUG_TO_ADMIN      = os.environ.get("DEBUG_TO_ADMIN", "1") == "1"       # 1 ‚Äî —Å–ª–∞—Ç—å –ø—Ä–µ–≤—å—é –∞–¥–º–∏–Ω—É (–µ—Å–ª–∏ ADMIN_CHAT_ID –∑–∞–¥–∞–Ω)
ASSISTANT_GATE_ENABLED = os.environ.get("ASSISTANT_GATE_ENABLED", "1") == "1"
RUNWAY_SEND_JPEG     = os.environ.get("RUNWAY_SEND_JPEG", "1") == "1"  # –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä –≤ JPEG –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
START_OVERLAY_DEBUG  = os.environ.get("START_OVERLAY_DEBUG", "0") == "1"  # —Ä–∏—Å–æ–≤–∞—Ç—å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–º–∫–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ
MF_DEBUG = OAI_DEBUG or (os.environ.get("MF_DEBUG", "0") == "1")

if not OPENAI_API_KEY or not OAI_ASSISTANT_ID:
    print("‚ÑπÔ∏è –î–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —É–∫–∞–∂–∏—Ç–µ OPENAI_API_KEY –∏ OAI_ASSISTANT_ID (–∏–Ω–∞—á–µ –±—É–¥–µ—Ç —Ñ–æ–ª–±—ç–∫ –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏).")

def _log_oai(kind: str, url: str, status: int, body: str, payload_preview: str = ""):
    head = f"[OAI {kind}] {status} {url}"
    if payload_preview:
        print(head + f"\npayload: {payload_preview}\nresp: {body[:1000]}")
    else:
        print(head + f"\nresp: {body[:1000]}")

def _json_preview(d: dict, clip_keys=("image_url", "image_file")) -> str:
    try:
        j = dict(d)
        # –Ω–µ –ø–µ—á–∞—Ç–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ü–µ–ª–∏–∫–æ–º
        def shorten(v):
            s = str(v)
            return (s[:180] + "‚Ä¶") if len(s) > 200 else s
        def scrub(obj):
            if isinstance(obj, dict):
                return {k: ("<omitted>" if k in clip_keys else scrub(v)) for k, v in obj.items()}
            if isinstance(obj, list):
                return [scrub(x) for x in obj]
            if isinstance(obj, (str, bytes)):
                return shorten(obj)
            return obj
        return json.dumps(scrub(j), ensure_ascii=False)
    except Exception:
        return "<n/a>"

def _safe_send_photo(chat_id: int, path: str, caption: str = ""):
    try:
        with open(path, "rb") as ph:
            bot.send_photo(chat_id, ph, caption=caption[:1024])
    except Exception as e:
        print(f"[DBG] send_photo error: {e}")

def _short_gate(g: dict | None) -> str:
    if not g:
        return "gate: n/a"
    v = g.get("verdict")
    rs = g.get("reasons") or []
    return f"gate: {v} | reasons: {', '.join(rs[:4])}"

def _send_debug_preview(uid: int, scene_key: str, start_path: str, prompt: str, gate: dict | None):
    cap = (f"üéØ PREVIEW ‚Üí {scene_key}\n"
           f"prompt[{len(prompt)}]: {prompt[:500]}{'‚Ä¶' if len(prompt)>500 else ''}\n"
           f"{_short_gate(gate)}")
    if PREVIEW_START_FRAME:
        _safe_send_photo(uid, start_path, cap)
    if DEBUG_TO_ADMIN and ADMIN_CHAT_ID:
        try:
            _safe_send_photo(int(ADMIN_CHAT_ID), start_path, f"[uid {uid}] {cap}")
        except Exception as e:
            print(f"[DBG] admin preview err: {e}")

def _is_admin(uid: int) -> bool:
    try:
        return ADMIN_CHAT_ID and str(uid) == str(int(ADMIN_CHAT_ID))
    except Exception:
        return False

# --- –ê–¥–º–∏–Ω –¥–ª—è —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ (ID —á–∞—Ç–∞/ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è/–≥—Ä—É–ø–ø—ã) ---
# –ó–∞–ø–æ–ª–Ω–∏ ADMIN_CHAT_ID –≤ Secrets –∏–ª–∏ –≤–ø–∏—à–∏ —á–∏—Å–ª–æ –∑–¥–µ—Å—å:
ADMIN_CHAT_ID = os.environ.get("ADMIN_CHAT_ID", "").strip()  # –ø—Ä–∏–º–µ—Ä: "123456789"

# --- –¢–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é ---
BTN_MENU_MAIN   = "üìã –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
BTN_MENU_START  = "üé¨ –°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ"
BTN_MENU_PRICE  = "üí≤ –°—Ç–æ–∏–º–æ—Å—Ç—å"
BTN_MENU_SUPPORT= "üõü –¢–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞"
BTN_MENU_GUIDE  = "üìò –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ"
BTN_MENU_DEMO   = "üéû –ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç"

# –ö–Ω–æ–ø–∫–∞ ¬´–¥–æ–º–æ–π¬ª –¥–ª—è –≤—Å–µ—Ö —à–∞–≥–æ–≤ –º–∞—Å—Ç–µ—Ä–∞
BTN_GO_HOME = "üè† –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"

def kb_main_menu():
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)
    kb.add(telebot.types.KeyboardButton(BTN_MENU_MAIN),  telebot.types.KeyboardButton(BTN_MENU_START))
    kb.add(telebot.types.KeyboardButton(BTN_MENU_PRICE), telebot.types.KeyboardButton(BTN_MENU_SUPPORT))
    kb.add(telebot.types.KeyboardButton(BTN_MENU_GUIDE), telebot.types.KeyboardButton(BTN_MENU_DEMO))
    return kb

def show_main_menu(uid: int, text: str = None):
    text = text or '–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ, –Ω–∞–∂–∞–≤ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª.'
    bot.send_message(uid, text, reply_markup=kb_main_menu())

# ---------- –ü–ê–ü–ö–ò ----------
os.makedirs("uploads",  exist_ok=True)
os.makedirs("renders",  exist_ok=True)
os.makedirs("assets",   exist_ok=True)
os.makedirs("audio",    exist_ok=True)
WATERMARK_PATH = "assets/watermark_black.jpg"

# ---------- –°–¶–ï–ù–´ / –§–û–†–ú–ê–¢–´ / –§–û–ù–´ / –ú–£–ó–´–ö–ê ----------
SCENES = {
    "ü´Ç –û–±—ä—è—Ç–∏—è 5—Å - –ë–ï–°–ü–õ–ê–¢–ù–û":    {"duration": 5,  "kind": "hug",        "people": 2},
    "ü´Ç –û–±—ä—è—Ç–∏—è 10—Å - 100 —Ä—É–±–ª–µ–π":   {"duration": 10, "kind": "hug",        "people": 2},
    "üíè –ü–æ—Ü–µ–ª—É–π 10—Å - 100 —Ä—É–±–ª–µ–π":       {"duration": 10, "kind": "kiss_cheek", "people": 2},
    "üëã –ü—Ä–æ—â–∞–Ω–∏–µ 10—Å - 100 —Ä—É–±–ª–µ–π": {"duration": 10, "kind": "wave",       "people": 1},
    "ü™ú –£—Ö–æ–¥–∏—Ç –≤ –Ω–µ–±–µ—Å–∞ 10—Å - 100 —Ä—É–±–ª–µ–π": {"duration": 10, "kind": "stairs", "people": 2},
}

FORMATS = {
    "üßç –í —Ä–æ—Å—Ç":  "full-body shot",
    "üë®‚Äçüíº –ü–æ –ø–æ—è—Å": "waist-up shot",
    "üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å":  "chest-up shot",
}

BACKGROUNDS = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤": "assets/backgrounds/bg_stairs.png",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":            "assets/backgrounds/bg_gates.png",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":        "assets/backgrounds/bg_angels.png",
}

BG_IMAGE_PATHS = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤": "assets/backgrounds/bg_stairs.jpg",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":            "assets/backgrounds/bg_gates.jpg",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":        "assets/backgrounds/bg_angels.jpg",
}

MUSIC = {
    "üéµ –°–ø–æ–∫–æ–π–Ω–∞—è":   "audio/soft_pad.mp3",
    "üéµ –¶–µ—Ä–∫–æ–≤–Ω–∞—è":   "audio/gentle_arpeggio.mp3",
    "üéµ –õ–∏—Ä–∏—á–Ω–∞—è":    "audio/strings_hymn.mp3",
}

# –ö–∞—Ä—Ç–∏–Ω–∫–∏ —Ñ–æ–Ω–æ–≤ (–∫–∞–∫ —Ç—ã –∏ –ø–æ–ª–æ–∂–∏–ª)
BG_FILES = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤": "assets/backgrounds/bg_stairs.jpg",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":            "assets/backgrounds/bg_gates.jpg",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":        "assets/backgrounds/bg_angels.jpg",
}

# –ö–æ—Ä–æ—Ç–∫–∏–µ ¬´–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ¬ª –ø–æ–¥—Å–∫–∞–∑–∫–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ñ–æ–Ω—É
BG_TEXT = {
    "‚òÅÔ∏è –õ–µ—Å—Ç–Ω–∏—Ü–∞ —Å—Ä–µ–¥–∏ –æ–±–ª–∞–∫–æ–≤":
        "must animate only: very gentle cloud drift left-to-right (~2 px/s) and faint light breathing (¬±3% brightness); "
        "stairs and architecture must remain fixed; do not add or remove any objects",
    "üîÜ –í—Ä–∞—Ç–∞ —Å–≤–µ—Ç–∞":
        "must animate only: subtle light pulsing (¬±3% brightness) and tiny cloud drift (~1‚Äì2 px/s); "
        "gates and columns must remain fixed; do not add ornaments or statues",
    "ü™Ω –ê–Ω–≥–µ–ª—ã –∏ –∫—Ä—ã–ª—å—è":
        "must animate only: faint feather shimmer or tiny wing flicker (very rare) and minimal cloud drift (~1‚Äì2 px/s); "
        "angel figures must remain fixed; do not add or move elements",
}

# –†–µ—Å—ç–º–ø–ª–µ—Ä –ø–æ–¥ Pillow 10+
RESAMPLE = getattr(Image, "Resampling", Image)
MIN_GAP_PX = 20  # –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –∑–∞–∑–æ—Ä –º–µ–∂–¥—É –ø–µ—Ä—Å–æ–Ω–∞–º–∏
IDEAL_GAP_FRAC = 0.05      # —Ü–µ–ª–µ–≤–æ–π –∑–∞–∑–æ—Ä –º–µ–∂–¥—É –ª—é–¥—å–º–∏ ~5% —à–∏—Ä–∏–Ω—ã –∫–∞–¥—Ä–∞
CENTER_BIAS_FRAC = 0.42    # —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã –ª—é–¥–µ–π: 42% –∏ 58% —à–∏—Ä–∏–Ω—ã
# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –¥–æ–ø—É—Å—Ç–∏–º—ã–π –∞–ø—Å–∫–µ–π–ª (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ ¬´–Ω–∞ –≤—Å—è–∫–∏–π¬ª)
MAX_UPSCALE = float(os.environ.get("MAX_UPSCALE", "1.45"))

# –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ ¬´–≤–∏–¥–∏–º—ã–µ¬ª –≤—ã—Å–æ—Ç—ã —Å–∏–ª—É—ç—Ç–æ–≤ (–¥–æ–ª—è –æ—Ç H), —á—Ç–æ–±—ã –Ω–µ –≤—ã–≥–ª—è–¥–µ–ª–∏ ¬´–∫–∞—Ä–ª–∏–∫–∞–º–∏¬ª
# –ö–ª—é—á: (—Ñ–æ—Ä–º–∞—Ç, count_people) -> –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∏–¥–∏–º–∞—è –≤—ã—Å–æ—Ç–∞ bbox –ø–æ –∞–ª—å—Ñ–µ / H
MIN_VISIBLE_FRAC = {
    ("üßç –í —Ä–æ—Å—Ç", 1): 0.86,
    ("üßç –í —Ä–æ—Å—Ç", 2): 0.80,
    ("üë®‚Äçüíº –ü–æ –ø–æ—è—Å", 1): 0.66,
    ("üë®‚Äçüíº –ü–æ –ø–æ—è—Å", 2): 0.60,
    ("üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å", 1): 0.56,
    ("üë®‚Äçüíº –ü–æ –≥—Ä—É–¥—å", 2): 0.50,
}

def _min_frac_for(format_key: str, count_people: int) -> float:
    # –ë–∞–∑–æ–≤—ã–π –¥–µ—Ñ–æ–ª—Ç –Ω–∞ —Å–ª—É—á–∞–π –Ω–æ–≤—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
    return MIN_VISIBLE_FRAC.get((format_key, count_people), 0.60)
# --- –¶–µ–ª–µ–≤—ã–µ –≤—ã—Å–æ—Ç—ã —Å–∏–ª—É—ç—Ç–æ–≤ (–¥–æ–ª—è –æ—Ç –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞) ---
TH_FULL_SINGLE   = 0.73
TH_FULL_DOUBLE   = 0.68
TH_WAIST_SINGLE  = 0.68
TH_WAIST_DOUBLE  = 0.64
TH_CHEST_SINGLE  = 0.62
TH_CHEST_DOUBLE  = 0.58

# Audio files are now real MP3 files provided by user
# No need to create placeholder sounds anymore

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞, –∫–æ—Ç–æ—Ä—É—é –¥–æ–ª–∂–Ω–∞ –∑–∞–Ω–∏–º–∞—Ç—å —Ñ–∏–≥—É—Ä–∞/–≥—Ä—É–ø–ø–∞ (anti-micro-people)
MIN_SINGLE_FRAC = {
    "–í —Ä–æ—Å—Ç": 0.86,
    "–ü–æ –ø–æ—è—Å": 0.76,
    "–ü–æ –≥—Ä—É–¥—å": 0.68,
}
MIN_PAIR_FRAC = {
    "–í —Ä–æ—Å—Ç": 0.72,
    "–ü–æ –ø–æ—è—Å": 0.65,
    "–ü–æ –≥—Ä—É–¥—å": 0.60,
}
# –ú—è–≥–∫–∏–π –ø—Ä–µ–¥–µ–ª –∞–ø—Å–∫–µ–π–ª–∞ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ ¬´–ø–æ–¥—Ä–∞—Å—Ç–∞–Ω–∏—è¬ª (–æ—Ç —Ç–µ–∫—É—â–µ–≥–æ target_h)
PAIR_UPSCALE_CAP = 1.22   # –Ω–µ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤—É—é –≤—ã—Å–æ—Ç—É –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 22% –∑–∞ –æ–¥–∏–Ω –ø–∞—Å—Å
SINGLE_UPSCALE_CAP = 1.25 # –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π —Ñ–∏–≥—É—Ä—ã

def _bg_layout_presets(bg_path: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º—è–≥–∫–∏–º–∏ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—è–º–∏ –∫–æ–º–ø–æ–Ω–æ–≤–∫–∏ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–æ–Ω.
    center_frac ‚Äî —Ü–µ–Ω—Ç—Ä ¬´–ø–æ–ª–æ—Å—ã¬ª –≤ –¥–æ–ª—è—Ö —à–∏—Ä–∏–Ω—ã,
    band_frac   ‚Äî —à–∏—Ä–∏–Ω–∞ ¬´–ø–æ–ª–æ—Å—ã¬ª (–≤ –¥–æ–ª—è—Ö —à–∏—Ä–∏–Ω—ã),
    top_headroom_min/max ‚Äî –¥–æ–ø—É—Å—Ç–∏–º—ã–π –∑–∞–∑–æ—Ä —Å–≤–µ—Ä—Ö—É (–¥–æ–ª–∏ –≤—ã—Å–æ—Ç—ã).
    """
    name = os.path.basename(str(bg_path)).lower()
    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî —à–∏—Ä–æ–∫–∞—è –ø–æ–ª–æ—Å–∞ –∏ —É–º–µ—Ä–µ–Ω–Ω—ã–π –ø–æ—Ç–æ–ª–æ–∫
    presets = dict(center_frac=0.50, band_frac=0.46, top_headroom_min=0.05, top_headroom_max=0.13)

    if "stairs" in name:
        # –¥–µ—Ä–∂–∏–º –ª—é–¥–µ–π –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É, —Å–≤–µ—Ä—Ö—É –¥–æ–ø—É—Å—Ç–∏–º–æ —á—É—Ç—å –±–æ–ª—å—à–µ –≤–æ–∑–¥—É—Ö–∞ (–±–ª–∏–∫)
        presets = dict(center_frac=0.50, band_frac=0.40, top_headroom_min=0.06, top_headroom_max=0.18)
    elif "gates" in name:
        presets = dict(center_frac=0.50, band_frac=0.44, top_headroom_min=0.05, top_headroom_max=0.15)
    # angels ‚Äî –æ—Å—Ç–∞–≤–∏–º –¥–µ—Ñ–æ–ª—Ç
    return presets

NEG_TAIL = (
    "no face morphing, no identity change, no makeup change, no aging, "
    "do not add new accessories, keep existing accessories, "
    "no extra fingers, no deformed hands, no melting faces, "
    "no background geometry changes, no new background objects, "
    "camera locked, very low creativity"
)

KISS_FALLBACKS = [
    "two people embrace cheek-to-cheek; tender cheek touch; no lip contact; hold briefly",
    "one person gives a gentle kiss on the forehead; respectful, brief; other person softly leans"
]

# –î–æ–±–∞–≤–∫–∏ –∫ –ø—Ä–æ–º–ø—Ç—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –∫–æ–≥–¥–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω/—Ç–∞–π–º–∞—É—Ç/–æ—à–∏–±–∫–∞
BACKUP_PROMPT_ADDITIONS = (
    "stabilize subject scale; prevent stretching or shrinking; "
    "keep feet grounded and fixed to floor plane; "
    "no zoom, no dolly; lock camera; "
    "refine edges softly (1-2px feather); avoid hallucinated limbs"
)

# ---------- –°–¢–ï–ô–¢ ----------
def new_state():
    return {
        "scenes": [],
        "format": None,
        "bg": None,
        "music": None,
        "photos": [],
        "ready": False,
        "support": False,   # –∂–¥—ë–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏
    }

users = {}  # uid -> state
# –ë—É—Ñ–µ—Ä –¥–ª—è –∞–ª—å–±–æ–º–æ–≤ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ, –ø—Ä–∏—à–µ–¥—à–∏—Ö –æ–¥–Ω–∏–º –º–µ–¥–∏–∞-–≥—Ä—É–ø–ø–æ–π)
PENDING_ALBUMS = {}  # media_group_id -> {"uid": int, "need": int, "paths": list[str]}

# ---------- –ö–õ–ê–í–ò–ê–¢–£–†–´ ----------
def available_scene_keys(format_key: str | None) -> list[str]:
    # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –Ω–µ "–í —Ä–æ—Å—Ç" ‚Äî —É–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ü–µ–Ω—ã —Å kind == "stairs"
    keys = []
    for name, meta in SCENES.items():
        if format_key and "–í —Ä–æ—Å—Ç" not in format_key and meta.get("kind") == "stairs":
            continue
        keys.append(name)
    return keys

def kb_scenes(format_key: str | None = None):
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=2)

    # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ü–µ–Ω —Å —É—á—ë—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–∞
    scene_keys = available_scene_keys(format_key)
    scene_buttons = [telebot.types.KeyboardButton(k) for k in scene_keys]
    if scene_buttons:
        kb.add(*scene_buttons)

    # —Å–ª—É–∂–µ–±–Ω—ã–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏
    kb.add(
        telebot.types.KeyboardButton("‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ"),
        telebot.types.KeyboardButton("üîÅ –°–±—Ä–æ—Å–∏—Ç—å –≤—ã–±–æ—Ä —Å—é–∂–µ—Ç–æ–≤"),
    )
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_formats():
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True, row_width=3)
    kb.add(*[telebot.types.KeyboardButton(k) for k in FORMATS.keys()])
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_backgrounds():
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True)
    for k in BACKGROUNDS.keys():
        kb.add(telebot.types.KeyboardButton(k))
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

def kb_music():
    """Inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º—É–∑—ã–∫–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è"""
    kb = telebot.types.InlineKeyboardMarkup(row_width=2)

    for name, path in MUSIC.items():
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ üéµ –¥–ª—è callback-–¥–∞–Ω–Ω—ã—Ö
        clean_name = name.replace("üéµ ", "")
        listen_btn = telebot.types.InlineKeyboardButton(
            f"üéß {clean_name}", callback_data=f"listen_{clean_name}"
        )
        select_btn = telebot.types.InlineKeyboardButton(
            f"‚úÖ {clean_name}", callback_data=f"select_music_{clean_name}"
        )
        kb.add(listen_btn, select_btn)

    # –ö–Ω–æ–ø–∫–∞ "–ë–µ–∑ –º—É–∑—ã–∫–∏"
    no_music_btn = telebot.types.InlineKeyboardButton(
        "üîá –ë–µ–∑ –º—É–∑—ã–∫–∏", callback_data="select_music_none"
    )
    kb.add(no_music_btn)

    # –ö–Ω–æ–ø–∫–∞ "–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é"
    home_btn = telebot.types.InlineKeyboardButton(
        "üè† –í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="go_home"
    )
    kb.add(home_btn)

    return kb

def kb_music_old():
    """–°—Ç–∞—Ä–æ–µ –º–µ–Ω—é –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    kb = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True)
    for k in MUSIC.keys():
        kb.add(telebot.types.KeyboardButton(k))
    kb.add(telebot.types.KeyboardButton("üîá –ë–µ–∑ –º—É–∑—ã–∫–∏"))
    kb.add(telebot.types.KeyboardButton(BTN_GO_HOME))
    return kb

# ---------- –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ----------
def find_music_by_name(name: str) -> str|None:
    """–ù–∞—Ö–æ–¥–∏—Ç –ø—É—Ç—å –∫ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–º—É —Ñ–∞–π–ª—É –ø–æ –∏–º–µ–Ω–∏"""
    for key, path in MUSIC.items():
        if key.replace("üéµ ", "") == name:
            return path
    return None
def alpha_metrics(img: Image.Image, thr: int = 20):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bbox, y_bottom) –ø–æ –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –ø–∏–∫—Å–µ–ª—è–º –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞.
    bbox: (x0, y0, x1, y1) –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    y_bottom: –∏–Ω–¥–µ–∫—Å –Ω–∏–∂–Ω–µ–π —Å—Ç—Ä–æ–∫–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (int)
    """
    a = img.split()[-1]
    arr = np.asarray(a, dtype=np.uint8)
    ys, xs = np.where(arr >= thr)
    if ys.size == 0:
        b = img.getbbox() or (0, 0, img.width, img.height)
        return b, b[3] - 1
    x0, y0 = int(xs.min()), int(ys.min())
    x1, y1 = int(xs.max()) + 1, int(ys.max()) + 1
    return (x0, y0, x1, y1), (y1 - 1)

def _save_layout_debug(canvas_rgba: Image.Image, metrics: dict, base_id: str):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç:
      - renders/temp/metrics_<base_id>.json ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–º–ø–æ–Ω–æ–≤–∫–∏
      - renders/temp/annot_<base_id>.png    ‚Äî –∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–≤—å—é —Å —Ä–∞–º–∫–∞–º–∏
    """
    try:
        os.makedirs("renders/temp", exist_ok=True)
    except Exception:
        pass

    # 1) JSON
    try:
        mpath = f"renders/temp/metrics_{base_id}.json"
        with open(mpath, "w", encoding="utf-8") as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        print(f"[DEBUG] metrics -> {mpath}")
    except Exception as e:
        print(f"[DEBUG] metrics save error: {e}")

    # 2) –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞
    try:
        im = canvas_rgba.convert("RGB")
        draw = ImageDraw.Draw(im)
        font = None
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 16)
        except Exception:
            font = ImageFont.load_default()

        # –†–∞–º–∫–∏ –∏ –ø–æ–¥–ø–∏—Å–∏
        colors = {"L": (46, 204, 113), "R": (52, 152, 219)}  # –∑–µ–ª—ë–Ω—ã–π/—Å–∏–Ω–∏–π
        for side in ("L", "R"):
            if side not in metrics: 
                continue
            r = metrics[side]["rect_abs"]  # [x0,y0,x1,y1]
            c = colors[side]
            # —Ä–∞–º–∫–∞
            draw.rectangle(r, outline=c, width=3)
            # –ø–æ–¥–ø–∏—Å—å
            label = (f"{side}: h={metrics[side]['height_px']} "
                     f"({int(round(metrics[side]['height_frac']*100))}% H), "
                     f"w={metrics[side]['width_px']}, "
                     f"cx={int(round(metrics[side]['center_x_frac']*100))}%, "
                     f"scale‚âà{metrics[side]['scale']:.2f}")
            tx, ty = r[0] + 4, max(4, r[1] - 18)
            draw.rectangle([tx-2, ty-2, tx+draw.textlength(label, font=font)+6, ty+18], fill=(0,0,0,128))
            draw.text((tx, ty), label, fill=(255,255,255), font=font)

            # –æ—Ç–º–µ—Ç–∫–∞ ¬´–ø–æ–ª¬ª
            fy = metrics[side].get("floor_y")
            if isinstance(fy, int):
                draw.line([(r[0], fy), (r[2], fy)], fill=c, width=2)

        # –ó–∞–∑–æ—Ä –º–µ–∂–¥—É –ª—é–¥—å–º–∏
        gap = metrics.get("gap_px")
        if gap is not None:
            text = f"gap={gap}px ({int(round(metrics.get('gap_frac',0)*100))}% W)"
            draw.rectangle([10, 10, 10+draw.textlength(text, font=font)+12, 10+22], fill=(0,0,0,128))
            draw.text((16, 12), text, fill=(255,255,255), font=font)

        apath = f"renders/temp/annot_{base_id}.png"
        im.save(apath, "PNG")
        print(f"[DEBUG] annot -> {apath}")
    except Exception as e:
        print(f"[DEBUG] annot save error: {e}")

def compact_prompt(s: str, max_len: int = 900) -> str:
    """–£–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—ã –ø—Ä–æ–±–µ–ª–æ–≤, –ø–µ—Ä–µ–≤–æ–¥–æ–≤ —Å—Ç—Ä–æ–∫ –∏ —Ä–µ–∂–µ–º –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã."""
    s = " ".join(str(s).split())
    if len(s) > max_len:
        s = s[:max_len-3] + "..."
    return s

# --- Heuristic: treat some reasons as "minor", suitable for warn instead of block
MINOR_REASON_MARKERS = (
    # ru
    "–æ–±—Ä–µ–∑–∞–Ω –ø–∞–ª–µ—Ü", "–æ–±—Ä–µ–∑–∞–Ω—ã –ø–∞–ª—å—Ü—ã", "–º–µ–ª–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã", "–ª–µ–≥–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã", "–∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤—ã—Ä–µ–∑–∫–∏",
    "—Ç–æ–Ω–∫–∏–π –æ—Ä–µ–æ–ª", "–æ—Ä–µ–æ–ª –ø–æ –∫–æ–Ω—Ç—É—Ä—É", "–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ", "—á—É—Ç—å –æ–±—Ä–µ–∑–∞–Ω–æ", "—Å–ª–µ–≥–∫–∞ –æ–±—Ä–µ–∑–∞–Ω–æ",
    "–Ω–µ–º–Ω–æ–≥–æ —à—É–º", "—Å–ª–µ–≥–∫–∞ —Å–º–µ—â–µ–Ω–æ", "–º–µ–ª–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã –º–∞—Å–∫–∏",
    # en (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    "minor", "slight", "tiny", "halo", "soft edge", "edge halo", "mask artifact",
    "partial finger", "fingers cut", "small artifact", "slight misalignment"
)
MAJOR_BLOCK_MARKERS = (
    # ru
    "–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Ñ–∏–≥—É—Ä", "–ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç –¥—Ä—É–≥ –¥—Ä—É–≥–∞", "–≤—ã–ª–µ–∑–∞–µ—Ç –∑–∞ –∫–∞–¥—Ä", "–≤–Ω–µ –∫–∞–¥—Ä–∞", "–Ω–µ—Ç –Ω–æ–≥",
    "–Ω–µ—Ç –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏", "—Å–∏–ª—å–Ω–∞—è –¥–µ—Ñ–æ—Ä–º–∞—Ü–∏—è", "—Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞", "–º–∞—Å—à—Ç–∞–± —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è",
    "–≥–æ–ª–æ–≤–∞ –æ–±—Ä–µ–∑–∞–Ω–∞", "–∫—Ä–∏—Ç–∏—á–Ω–æ –æ–±—Ä–µ–∑–∞–Ω–æ",
    # en
    "overlap", "outside frame", "out of frame", "missing limb", "severe deformation",
    "too far apart", "cropped head", "wild scaling"
)

def _is_minor_only(reasons: list[str] | None) -> bool:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –ø—Ä–∏—á–∏–Ω—ã ‚Äî —Ç–æ–ª—å–∫–æ ¬´–º–µ–ª–∫–∏–µ¬ª (–∏ –Ω–µ—Ç —Å–µ—Ä—å—ë–∑–Ω—ã—Ö)."""
    if not reasons:
        return False
    text = " | ".join(str(r).lower() for r in reasons)
    if any(m in text for m in MAJOR_BLOCK_MARKERS):
        return False
    return any(m in text for m in MINOR_REASON_MARKERS)

def validate_photo(path: str) -> tuple[bool, list[str]]:
    """
    –ú—è–≥–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ç–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok, warnings). ok=False ‚Äî –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ñ–æ—Ç–æ, –Ω–æ –º—ã –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –ø–∞–π–ø–ª–∞–π–Ω.
    """
    warns = []
    ok = True
    try:
        im = Image.open(path)
    except Exception as e:
        return False, [f"–Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª ({e})"]

    w, h = im.size
    min_dim = min(w, h)

    # 1) –†–∞–∑–º–µ—Ä/—Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    if min_dim < 300:
        ok = False
        warns.append(f"–æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ({w}√ó{h}) ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –∏—Å–∫–∞–∑–∏—Ç—å—Å—è")
    elif min_dim < 600:
        warns.append(f"–Ω–∏–∑–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ ({w}√ó{h}) ‚Äî –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ ‚â• 800px –ø–æ –º–µ–Ω—å—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ")

    # 2) –û—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è (–¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–æ–≤ –ª—É—á—à–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è)
    ratio = w / h if h else 1.0
    if ratio > 0.9:
        warns.append("—Ñ–æ—Ç–æ –Ω–µ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ ‚Äî –ø–æ—Ä—Ç—Ä–µ—Ç –æ–±—ã—á–Ω–æ –ª—É—á—à–µ –≤—ã–≥–ª—è–¥–∏—Ç –≤ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏")

    # 3) –¢–µ–º–Ω–æ—Ç–∞/—ç–∫—Å–ø–æ–∑–∏—Ü–∏—è
    gray = im.convert("L")
    arr = np.asarray(gray, dtype=np.float32)
    mean = float(arr.mean())
    if mean < 55:
        warns.append("—Ñ–æ—Ç–æ —Ç—ë–º–Ω–æ–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –±–æ–ª–µ–µ —Å–≤–µ—Ç–ª–æ–µ/–∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ–µ")

    # 4) –†–∞–∑–º—ã—Ç–æ—Å—Ç—å (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —á–µ—Ä–µ–∑ ¬´–∫—Ä–∞—è¬ª)
    edges = gray.filter(ImageFilter.FIND_EDGES)
    earr = np.asarray(edges, dtype=np.float32)
    sharpness = float(earr.std())
    if sharpness < 8:
        warns.append("–≤–æ–∑–º–æ–∂–Ω–∞—è —Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å/—à—É–º ‚Äî –∫–æ–Ω—Ç—É—Ä—ã —Å–ª–∞–±—ã–µ")

    return ok, warns

def _visible_bbox_height(img: Image.Image) -> int:
    b = img.getbbox() or (0, 0, img.width, img.height)
    return max(1, b[3] - b[1])

def smart_cutout(img_rgba: Image.Image) -> Image.Image:
    """
    1) –ü–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è –º–æ–¥–µ–ª—å -> –∑–∞–ø–∞—Å–Ω–∞—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è.
    2) –ú—è–≥–∫–∞—è ¬´–ø–æ–¥—Ä–µ–∑–∫–∞ –æ—Ä–µ–æ–ª–∞¬ª + –ª–µ–≥–∫–æ–µ –ø–µ—Ä–æ –∫—Ä–∞—ë–≤.
    """
    def _run(session):
        out = remove(img_rgba, session=session, post_process_mask=True)
        if isinstance(out, (bytes, bytearray)):
            out = Image.open(io.BytesIO(out)).convert("RGBA")
        return out

    # 1. –ü—ã—Ç–∞–µ–º—Å—è human_seg
    try:
        cut = _run(RMBG_HUMAN)
    except Exception:
        cut = _run(RMBG_SESSION)

    # 2. –ï—Å–ª–∏ —Å–∏–ª—É—ç—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π ‚Äî –ø—Ä–æ–±—É–µ–º ISNet
    try:
        bb = cut.getbbox() or (0, 0, cut.width, cut.height)
        area = (bb[2] - bb[0]) * (bb[3] - bb[1])
        if area < 0.12 * cut.width * cut.height:
            alt = _run(RMBG_ISNET)
            bb2 = alt.getbbox() or (0, 0, alt.width, alt.height)
            area2 = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])
            if area2 > area:
                cut = alt
    except Exception:
        pass

    # 3. –†–∞—Ñ–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞—Å–∫–∏: —á—É—Ç—å ¬´–ø–æ–¥–∂–∞—Ç—å¬ª –∏ –¥–∞—Ç—å –ø–µ—Ä–æ
    a = cut.split()[-1]
    # —Å–ª–µ–≥–∫–∞ —É–±—Ä–∞—Ç—å –æ—Ä–µ–æ–ª
    a = a.filter(ImageFilter.MinFilter(3))       # 1px —ç—Ä–æ–∑–∏—è
    # –º—è–≥–∫–æ–µ –ø–µ—Ä–æ
    a = a.filter(ImageFilter.GaussianBlur(1.2))  # ~1‚Äì2px
    cut.putalpha(a)
    return cut

# ---------- PROMPT BUILDER ----------
def build_prompt(kind: str, framing: str, bg_prompt: str, duration_sec: int):
    # –ü–ª–∞–≤–Ω–æ—Å—Ç—å/—Ç–µ–º–ø
    if duration_sec <= 5:
        pace = ("very slow, subtle motion; limit head yaw to ~10-15 degrees; "
                "avoid quick turns; ease-in, ease-out; hold pose at the end")
        turn_portion = "first 50% of the duration"
    else:
        pace = ("slow, smooth motion; limit head yaw to ~15-20 degrees; "
                "no quick snaps; ease-in, ease-out; hold pose at the end")
        turn_portion = "first 60% of the duration"

    # –°—Ü–µ–Ω—ã
    if kind == "hug":
        main = (
            "two people are already close to each other (small inner gap ~4‚Äì6% of frame width); "
            f"over the {turn_portion} they gently lean toward each other and embrace; "
            "do not drift them apart; keep their apparent size constant; hold the embrace at the end; "
            "maintain safe margins from frame edges; keep full silhouettes visible; "
            "ensure no cropping of heads, hands, or feet"
        )
    elif kind == "kiss_cheek":
        main = (f"two people slowly turn toward each other over the {turn_portion}; "
                "a tender cheek or forehead touch; hold the moment, no lip contact")
    elif kind == "wave":
        main = ("one person faces camera and gives a slow farewell wave (2‚Äì3 cycles) with wrist only; "
                "body stays mostly still; end with a soft pause")
    elif kind == "stairs":
        main = ("one person slowly walks upstairs into the heavenly light while the other person stays below watching; "
                "the walking person may look back kindly; end with a soft fade into light")
    else:
        main = "two people gently approach each other and hug"

    # –§–æ–Ω ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª
    bg_anim = (
        "preserve the provided background plate exactly as in the image (geometry and composition fixed); "
        "do not add or remove objects; "
        f"{bg_prompt}"
    )

    # –ó–∞–ø—Ä–µ—Ç—ã –Ω–∞ –∫–∞–º–µ—Ä—É –∏ –º–∞—Å—à—Ç–∞–±
    camera_lock = (
        "camera locked; no zoom; no pan; no tilt; no roll; no dolly; "
        "keep field of view constant; no lens breathing"
    )
    scale_lock_pair = (
        "subjects must keep constant apparent size relative to the frame; "
        "strictly no scaling or stretching of people; no growth or shrink; "
        "keep their pixel-to-pixel silhouette alignment within ¬±2px tolerance"
    )
    scale_lock_stairs = (
        "subject size may change only minimally and smoothly due to going up the stairs (<=5% over the whole clip); "
        "no sudden jumps; no stretching"
    )

    # –§–∏–∫—Å–∞—Ü–∏—è –æ–ø–æ—Ä—ã/–ø–æ–∑–∏—Ü–∏–π
    if kind == "stairs":
        ground_lock = (
            "respect the stair plane; feet step naturally upward; "
            "no lateral sliding; apparent size change must be minimal and smooth; "
            + scale_lock_stairs
        )
    else:
        ground_lock = (
            "subjects remain on the ground plane; no forward/backward translation; "
            "if approach is needed, allow only a tiny horizontal slide toward each other (<=6% of frame width per subject); "
            + scale_lock_pair
        )

    identity = (
        "faces remain consistent with the photo; preserve hairstyle and hairline; "
        "do not alter facial proportions; mouth closed, natural blinking, realistic skin; "
        "preserve all clothing and accessories exactly as in the photo; do not add new accessories"
    )

    return (
        f"{main}; {framing}; {bg_anim}; "
        f"{pace}; {camera_lock}; {ground_lock}; {identity}; {NEG_TAIL}"
    )

# ---------- RUNWAY ----------
RUNWAY_API = "https://api.dev.runwayml.com/v1"
HEADERS = {
    "Authorization": f"Bearer {RUNWAY_KEY}",
    "X-Runway-Version": "2024-11-06",
    "Content-Type": "application/json",
}

def encode_image_datauri(path: str) -> str:
    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    ext = path.lower().split(".")[-1]
    mime = "image/jpeg" if ext in ["jpg","jpeg"] else "image/png"
    return f"data:{mime};base64,{b64}"

def ensure_jpeg_copy(path: str, quality: int = 88) -> str:
    """
    –î–µ–ª–∞–µ—Ç JPEG-–∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ .jpg.
    """
    im = Image.open(path).convert("RGB")
    out = os.path.splitext(path)[0] + ".jpg"
    im.save(out, "JPEG", quality=quality, optimize=True, progressive=True)
    try:
        os.sync()  # –Ω–µ —É –≤—Å–µ—Ö –û–° –µ—Å—Ç—å, –æ–∫ –µ—Å–ª–∏ —Å–≤–∞–ª–∏—Ç—Å—è
    except Exception:
        pass
    return out

def encode_image_as_jpeg_datauri(path: str, quality: int = 88) -> str:
    """
    –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∫–æ–¥–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ JPEG (RGB) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç dataURI.
    –≠—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å PNG –∏ —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –ø—Ä–æ—Ö–æ–¥–∏—Ç –≤ Runway.
    """
    im = Image.open(path).convert("RGB")
    bio = io.BytesIO()
    im.save(bio, format="JPEG", quality=quality, optimize=True, progressive=True)
    b64 = base64.b64encode(bio.getvalue()).decode("utf-8")
    return f"data:image/jpeg;base64,{b64}"

def cut_foreground_to_png(in_path: str) -> str:
    """–í—ã—Ä–µ–∑–∞–µ—Ç —Ñ–æ–Ω –∏–∑ JPG/PNG –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç PNG —Å –∞–ª—å—Ñ–æ–π."""
    with open(in_path, "rb") as f:
        raw = f.read()
    out = remove(raw, session=RMBG_SESSION)
    out_path = os.path.splitext(in_path)[0] + "_cut.png"
    with open(out_path, "wb") as f:
        f.write(out)
    return out_path

def _to_jpeg_copy(src_path: str, quality: int = 88) -> str:
    im = Image.open(src_path).convert("RGB")
    out_path = os.path.join("uploads", f"startframe_{uuid.uuid4().hex}.jpg")
    im.save(out_path, "JPEG", quality=quality, optimize=True, progressive=True)
    return out_path

def ensure_runway_datauri_under_limit(path: str, limit: int = 5_000_000) -> tuple[str, str]:
    data = encode_image_datauri(path)
    if len(data) <= limit:
        return data, path

    last_path = path
    for q in (88, 80, 72):
        try:
            jpg = _to_jpeg_copy(path, quality=q)
            last_path = jpg
            data = encode_image_datauri(jpg)
            if len(data) <= limit:
                print(f"[Runway] using JPEG q={q}, data_uri={len(data)} bytes")
                return data, jpg
        except Exception as e:
            print(f"[Runway] jpeg fallback q={q} failed: {e}")

    print(f"[Runway] still heavy after JPEG attempts, length={len(data)}")
    return data, last_path

def _post_runway(payload: dict) -> dict | None:
    try:
        if "promptText" in payload or "prompt" in payload:
            _pl = payload.get("promptText") or payload.get("prompt") or ""
            print(f"[Runway] model={payload.get('model')} dur={payload.get('duration')} "
                  f"ratio={payload.get('ratio') or payload.get('aspect_ratio')} "
                  f"prompt[:200]={_pl[:200].replace(chr(10),' ')}...")
        if MF_DEBUG:
            try:
                os.makedirs("renders/temp", exist_ok=True)
                # –¥–µ–ª–∞–µ–º —Å–∞–Ω–∏—Ç–∞–π–∑ –ø—Ä–µ–≤—å—é, —á—Ç–æ–±—ã –Ω–µ –ø–∏—Å–∞—Ç—å –≥–∏–≥–∞–Ω—Ç—Å–∫–∏–π data URI
                preview = {
                    "model": payload.get("model"),
                    "duration": payload.get("duration"),
                    "ratio": payload.get("ratio") or payload.get("aspect_ratio"),
                    "prompt_len": len((_pl or "")),
                    "image_data_uri_len": len(payload.get("promptImage") or payload.get("image") or ""),
                }
                with open(os.path.join("renders/temp", f"runway_payload_{int(time.time())}.json"), "w", encoding="utf-8") as f:
                    json.dump(preview, f, ensure_ascii=False, indent=2)
                print("[Runway] payload preview saved")
            except Exception as _e:
                print(f"[Runway] payload preview save err: {_e}")
        r = requests.post(f"{RUNWAY_API}/image_to_video", headers=HEADERS, json=payload, timeout=60)
        if r.status_code == 200:
            return r.json()
        # –ø–æ–ª–µ–∑–Ω–æ –≤–∏–¥–µ—Ç—å –æ—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –ø—Ä–∏ 4xx
        print(f"[Runway {r.status_code}] {r.text}")
        return None
    except requests.RequestException as e:
        print(f"[Runway transport error] {e}")
        return None

def runway_start(prompt_image_datauri: str, prompt_text: str, duration: int):
    """
    –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ø—ã—Ç–æ–∫:
    1) gen4_turbo + promptImage/promptText + ratio (—Ç–µ–∫—É—â–∞—è —Å—Ö–µ–º–∞ —ç—Ç–æ–≥–æ API)
    2) gen4_turbo + image/prompt + aspect_ratio (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è)
    3) gen3a_turbo + image/prompt + aspect_ratio (–∑–∞–ø–∞—Å–Ω–æ–π)
    """
    variants = [
        {
            "model": "gen4_turbo",
            "promptImage": prompt_image_datauri,   # <-- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
            "promptText":  prompt_text,
            "ratio": "720:1280",
            "duration": int(duration),
        },
        {
            "model": "gen4_turbo",
            "image": prompt_image_datauri,
            "prompt": prompt_text,
            "aspect_ratio": "9:16",
            "duration": int(duration),
        },
        {
            "model": "gen3a_turbo",
            "image": prompt_image_datauri,
            "prompt": prompt_text,
            "aspect_ratio": "9:16",
            "duration": int(duration),
        },
    ]

    last_keys = ""
    for payload in variants:
        resp = _post_runway(payload)
        if resp:
            return resp
        last_keys = f"{list(payload.keys())}"

    raise RuntimeError(f"Runway returned 400/4xx for all variants (payload={last_keys}). Check logs above.")

def runway_poll(task_id: str, timeout_sec=900, every=5):
    start = time.time()
    while True:
        rr = requests.get(f"{RUNWAY_API}/tasks/{task_id}", headers=HEADERS, timeout=60)
        rr.raise_for_status()
        data = rr.json()
        st = data.get("status")
        if st in ("SUCCEEDED","FAILED","ERROR","CANCELED"):
            return data
        if time.time() - start > timeout_sec:
            return {"status":"TIMEOUT","raw":data}
        time.sleep(every)

def download(url: str, save_path: str):
    with requests.get(url, stream=True, timeout=300) as r:
        r.raise_for_status()
        with open(save_path, "wb") as f:
            for chunk in r.iter_content(8192):
                if chunk: f.write(chunk)
    return save_path

def _log_fail(uid: int, reason: str, payload: dict | None = None, response: dict | None = None):
    try:
        os.makedirs("renders/temp", exist_ok=True)
        path = os.path.join("renders/temp", f"fail_{uid}_{int(time.time())}_{uuid.uuid4().hex}.json")
        with open(path, "w", encoding="utf-8") as f:
            json.dump({
                "ts": datetime.utcnow().isoformat() + "Z",
                "uid": uid,
                "reason": reason,
                "payload": payload or {},
                "response": response or {}
            }, f, ensure_ascii=False, indent=2)
        print(f"[FAILLOG] {reason} -> {path}")
        # –µ—Å–ª–∏ –∑–∞–¥–∞–Ω ADMIN_CHAT_ID ‚Äî —à–ª—ë–º –∫–æ—Ä–æ—Ç–∫–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
        if ADMIN_CHAT_ID:
            try:
                bot.send_message(int(ADMIN_CHAT_ID), f"‚ö†Ô∏è FAIL {reason} (uid={uid})\n{os.path.basename(path)} —Å–æ—Ö—Ä–∞–Ω—ë–Ω.")
            except Exception:
                pass
    except Exception as e:
        print(f"[FAILLOG] write error: {e}")

MODERATION_SCHEMA = {
    "name": "visual_editor_decision",
    "strict": True,
    "schema": {
        "type": "object",
        "properties": {
            "status": {
                "type": "string",
                "enum": ["reject_user_photo", "accept", "accept_with_backend_fixes"],
                "description": "Decision status: reject if source photo has defects, accept if good, accept_with_backend_fixes if technical positioning issues need backend correction."
            },
            "user_notes": {
                "type": "array",
                "items": {
                    "type": "string",
                    "enum": ["missing_head", "missing_hands", "prohibited_content", "low_resolution", "too_dark", "blurred", "profile_view", "sitting_pose", "occluded_face", "cutout_artifacts"]
                },
                "description": "Issues with source photos that user needs to fix - only about photo quality, not positioning."
            },
            "backend_fixes": {
                "type": "object",
                "properties": {
                    "recompose": {"type": "boolean", "description": "Whether backend should recompose the frame automatically."},
                    "issues": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["overlap", "out_of_frame", "scale_mismatch", "far_apart", "z_order_wrong", "uneven_floor", "spacing_issue"]
                        },
                        "description": "Technical positioning issues for backend to fix automatically."
                    },
                    "target_height_frac": {
                        "type": "array",
                        "items": {"type": "number"},
                        "minItems": 2,
                        "maxItems": 2,
                        "description": "Target height fractions for [left, right] figures (0.6-0.9)."
                    },
                    "target_centers": {
                        "type": "array", 
                        "items": {"type": "number"},
                        "minItems": 2,
                        "maxItems": 2,
                        "description": "Target center X positions for [left, right] figures (0.2-0.8)."
                    },
                    "gap_frac": {"type": "number", "description": "Target gap between figures as fraction of frame width (0.01-0.15)."},
                    "align_feet": {
                        "type": "object",
                        "properties": {
                            "enabled": {"type": "boolean"},
                            "floor_y": {"type": "integer"}
                        },
                        "required": ["enabled", "floor_y"],
                        "additionalProperties": False
                    }
                },
                "required": ["recompose", "issues", "target_height_frac", "target_centers", "gap_frac", "align_feet"],
                "additionalProperties": False
            },
            "runway_prompt_additions": {
                "type": "string",
                "description": "Optional motion/tempo/constraint details for video generation prompt."
            }
        },
        "required": ["status", "user_notes", "backend_fixes", "runway_prompt_additions"],
        "additionalProperties": False
    }
}

def _normalize_gate(g: dict | None) -> dict | None:
    if not isinstance(g, dict):
        return None
    out = dict(g)

    # status
    st = (out.get("status") or "").strip().lower()
    if st not in ("reject_user_photo", "accept", "accept_with_backend_fixes"):
        st = "accept"
    out["status"] = st

    # user_notes
    un = out.get("user_notes")
    if not isinstance(un, list):
        un = []
    valid_notes = ["missing_head", "missing_hands", "prohibited_content", "low_resolution", "too_dark", "blurred", "profile_view", "sitting_pose", "occluded_face", "cutout_artifacts"]
    un = [note for note in un if note in valid_notes][:10]  # –º–∞–∫—Å–∏–º—É–º 10 –∑–∞–º–µ—Ç–æ–∫
    out["user_notes"] = un

    # backend_fixes
    bf = out.get("backend_fixes")
    if not isinstance(bf, dict):
        bf = {}
    bf.setdefault("recompose", False)
    bf.setdefault("issues", [])
    bf.setdefault("target_height_frac", [0.77, 0.77])
    bf.setdefault("target_centers", [0.35, 0.65])
    bf.setdefault("gap_frac", 0.05)
    bf.setdefault("align_feet", {"enabled": True, "floor_y": 1180})

    # –í–∞–ª–∏–¥–∞—Ü–∏—è backend_fixes
    if not isinstance(bf["issues"], list):
        bf["issues"] = []
    valid_issues = ["overlap", "out_of_frame", "scale_mismatch", "far_apart", "z_order_wrong", "uneven_floor", "spacing_issue"]
    bf["issues"] = [issue for issue in bf["issues"] if issue in valid_issues][:10]

    if not isinstance(bf["target_height_frac"], list) or len(bf["target_height_frac"]) != 2:
        bf["target_height_frac"] = [0.77, 0.77]
    if not isinstance(bf["target_centers"], list) or len(bf["target_centers"]) != 2:
        bf["target_centers"] = [0.35, 0.65]
    if not isinstance(bf["gap_frac"], (int, float)):
        bf["gap_frac"] = 0.05
    if not isinstance(bf["align_feet"], dict):
        bf["align_feet"] = {"enabled": True, "floor_y": 1180}

    out["backend_fixes"] = bf

    # runway_prompt_additions
    rpa = out.get("runway_prompt_additions") or ""
    rpa = " ".join(str(rpa).split())
    if len(rpa) > 600:
        rpa = rpa[:597] + "..."
    out["runway_prompt_additions"] = rpa

    return out

MODERATION_INSTRUCTIONS = """
–¢—ã ‚Äî –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä. –ü–æ–ª—É—á–∞–µ—à—å —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä (1‚Äì2 –≤—ã—Ä–µ–∑–∞–Ω–Ω—ã–µ –ø–µ—Ä—Å–æ–Ω—ã –Ω–∞ —Ñ–æ–Ω–µ) –∏ –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç.
–ó–∞–¥–∞—á–∞:
1. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–¥—Ä (–Ω–µ –ø–∏–∫—Å–µ–ª—å–Ω–æ): –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏, –≤–∏–¥–∏–º–æ—Å—Ç—å –ª–∏—Ü, –∫–æ–Ω—Ç–∞–∫—Ç —Å ¬´–ø–æ–ª–æ–º/—Å—Ç—É–ø–µ–Ω—å—é¬ª, –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.
2. –ï—Å–ª–∏ –∫–∞–¥—Ä –≥–æ–¥–∏—Ç—Å—è ‚Äî –¥–æ–ø–æ–ª–Ω–∏ –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Ç–æ–ª—å–∫–æ –¥–µ—Ç–∞–ª—è–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è/—Ç–µ–º–ø–∞/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (–∫–∞–º–µ—Ä–∞ —Å—Ç–∞—Ç–∏—á–Ω–∞, –∞–º–ø–ª–∏—Ç—É–¥–∞ –≥–æ–ª–æ–≤—ã/–ø–ª–µ—á, —Ñ–∏–∫—Å–∞—Ü–∏—è —Å—Ç–æ–ø –∏ –±—ë–¥–µ—Ä –∏ —Ç. –ø.). –ù–µ–ª—å–∑—è –º–µ–Ω—è—Ç—å –≤–Ω–µ—à–Ω–æ—Å—Ç—å, –æ–¥–µ–∂–¥—É, —Ñ–æ–Ω, –≥–µ–æ–º–µ—Ç—Ä–∏—é.
3. –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Å—Ç—Ä–æ–≥–æ:
   ‚Ä¢ ok ‚Äî –≥–æ–¥–∏—Ç—Å—è; –¥–æ–ø—É—Å—Ç–∏–º—ã –º–µ–ª–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—ã—á–Ω–æ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç: —Å–ª–µ–≥–∫–∞ —Å—Ä–µ–∑–∞–Ω–Ω—ã–µ –ø–∞–ª—å—Ü—ã/–ª–æ–∫–æ–Ω—ã, —Ç–æ–Ω–∫–∏–π –æ—Ä–µ–æ–ª, –ª—ë–≥–∫–∞—è —Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å –∫—Ä–∞—ë–≤, –Ω–µ–±–æ–ª—å—à–æ–π –ø–µ—Ä–µ–≤–µ—Å/–Ω–µ—Å–∏–º–º–µ—Ç—Ä–∏—è, –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ 5‚Äì10% –æ—Ç –Ω–æ—Å–∫–∞/–ø—è—Ç–∫–∏ –ø—Ä–∏ —è–≤–Ω–æ–º –∫–æ–Ω—Ç–∞–∫—Ç–µ —Å –æ–ø–æ—Ä–æ–π.
   ‚Ä¢ warn ‚Äî –≥–æ–¥–∏—Ç—Å—è, –Ω–æ –¥–∞–π 1‚Äì3 –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (¬´–ø–æ–¥–≤–∏–Ω—É—Ç—å –Ω–∞ 20px¬ª, ¬´—á—É—Ç—å —É–º–µ–Ω—å—à–∏—Ç—å –ø—Ä–∞–≤–æ–≥–æ –Ω–∞ 5%¬ª, ¬´–æ—Å—Ç–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –Ω–∞–¥ –≥–æ–ª–æ–≤–æ–π¬ª).
   ‚Ä¢ block ‚Äî –Ω–µ–ª—å–∑—è: –ª–∏—Ü–æ –∑–∞–∫—Ä—ã—Ç–æ/–Ω–µ—á–∏—Ç–∞–±–µ–ª—å–Ω–æ; –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–Ω–∞—á–∏–º–∞—è —á–∞—Å—Ç—å –∫–æ–Ω–µ—á–Ω–æ—Å—Ç–∏ (‚âà‚â•30%); —Ñ–∏–≥—É—Ä—ã –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è —Ç–∞–∫, —á—Ç–æ –æ–¥–Ω–∞ –Ω–µ—á–∏—Ç–∞–±–µ–ª—å–Ω–∞; —è–≤–Ω–æ ¬´–≤–∏—Å—è—Ç –≤ –≤–æ–∑–¥—É—Ö–µ¬ª (–Ω–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç–∞ —Å –æ–ø–æ—Ä–æ–π), —Å–∏–ª—å–Ω–∞—è –≤—ã—Ä–µ–∑–∫–∞: ¬´–¥—ã—Ä–∫–∏¬ª, ¬´–ø–æ–ª –ª–∏—Ü–∞¬ª, –∫—Ä—É–ø–Ω—ã–µ –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏–µ –æ–±—ä–µ–∫—Ç—ã –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç –∫–æ—Ä–ø—É—Å.

–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ JSON –ø–æ —Å—Ö–µ–º–µ.

- "ok": –∫–∞–¥—Ä –≥–æ–¥–∏—Ç—Å—è. –ù–µ–±–æ–ª—å—à–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –¥–æ–ø—É—Å—Ç–∏–º—ã.
- "warn": –µ—Å—Ç—å –Ω–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã (–ø–µ—Ä–µ—á–∏—Å–ª–∏ –∫—Ä–∞—Ç–∫–æ –≤ reasons), –Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–∂–Ω–æ.
- "block": —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–µ—Ä—å—ë–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, –∏–∑-–∑–∞ –∫–æ—Ç–æ—Ä—ã—Ö –≤–∏–¥–µ–æ –ø–æ—á—Ç–∏ –Ω–∞–≤–µ—Ä–Ω—è–∫–∞ –±—É–¥–µ—Ç –ø–ª–æ—Ö–∏–º:
  ‚Ä¢ —Å–∏–ª—å–Ω–æ–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –ª—é–¥–µ–π (>25% –ø–ª–æ—â–∞–¥–∏ —Ç–æ—Ä—Å–∞/–≥–æ–ª–æ–≤—ã),
  ‚Ä¢ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–Ω–∞—á–∏–º–∞—è —á–∞—Å—Ç—å –≥–æ–ª–æ–≤—ã/—Ç–æ—Ä—Å–∞,
  ‚Ä¢ –æ–±—Ä–µ–∑–∞–Ω–∞ –Ω–∏–∂–Ω—è—è –æ–ø–æ—Ä–∞ —Ç–∞–∫, —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ ‚Äú–≤–∏—Å–∏—Ç‚Äù –∏ —ç—Ç–æ –Ω–µ –ø—Ä–∞–≤–∏—Ç—Å—è —Å–ª–∞–π–¥–æ–º,
  ‚Ä¢ –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –≤—ã—Ä–µ–∑–∫–∏ (—Å–∫–≤–æ–∑–Ω—ã–µ –¥—ã—Ä–∫–∏, –ø–æ–ª–æ–≤–∏–Ω–∞ —Ç–µ–ª–∞ –ø—Ä–æ–∑—Ä–∞—á–Ω–∞),
  ‚Ä¢ —á–µ–ª–æ–≤–µ–∫ –ø–æ—á—Ç–∏ –≤–µ—Å—å –≤–Ω–µ –∫–∞–¥—Ä–∞,
  ‚Ä¢ –º–∞—Å—à—Ç–∞–± —Ç–µ–ª–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –º–∞–ª (<35% –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞) –∏–ª–∏ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–æ –≤–µ–ª–∏–∫ (>98%).

–ß—Ç–æ –ù–ï —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—Ä–∏—á–∏–Ω–æ–π –¥–ª—è "block" (–º–æ–∂–Ω–æ "ok" –∏–ª–∏ "warn"):
- —Å–ª–µ–≥–∫–∞ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ –ø–∞–ª—å—Ü—ã/–∫–∏—Å—Ç–∏, –º–µ–ª–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –ø–æ –∫–æ–Ω—Ç—É—Ä—É, –ª—ë–≥–∫–∞—è —â–µ—Ä–±–∞—Ç–æ—Å—Ç—å –º–∞—Å–∫–∏,
- —Ä–∞–∑–Ω—ã–µ —Å—Ç—É–ø–µ–Ω–∏ –Ω–∞ –ª–µ—Å—Ç–Ω–∏—Ü–µ, –Ω–µ–±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –ø–æ –≤—ã—Å–æ—Ç–µ –æ–ø–æ—Ä—ã,
- –Ω–µ–±–æ–ª—å—à–æ–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –ø–æ–∑/–ø–æ–≤–æ—Ä–æ—Ç–∞ –≥–æ–ª–æ–≤—ã,
- —Å–ª–∞–±–∞—è —Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å, –Ω–µ–±–æ–ª—å—à–∞—è —Ç–µ–Ω—å/–æ—Ä–µ–æ–ª –æ—Ç –≤—ã—Ä–µ–∑–∫–∏.

layout_feedback:
- –í–µ—Ä–Ω–∏ –Ω–µ–±–æ–ª—å—à–∏–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –∫–æ–º–ø–æ–Ω–æ–≤–∫–∏ (—Ü–µ–ª—ã–µ —á–∏—Å–ª–∞):
  shift_left_px, shift_right_px ‚àà [-80; 80]  ‚Äî —Å–¥–≤–∏–≥ –ø–æ X (–≤–ª–µ–≤–æ/–≤–ø—Ä–∞–≤–æ).
  scale_left_pct, scale_right_pct ‚àà [-20; 20] ‚Äî –º–∞—Å—à—Ç–∞–± –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö.
- –≠—Ç–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –º—è–≥–∫–∏–µ –∏ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ. –ï—Å–ª–∏ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚Äî —Å—Ç–∞–≤—å 0.
- –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–π —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –¶–µ–ª—å ‚Äî —Å–ª–µ–≥–∫–∞ –ø–æ–¥—Ç—è–Ω—É—Ç—å –∫ —Ü–µ–Ω—Ç—Ä—É –∏/–∏–ª–∏ —Å–±–ª–∏–∑–∏—Ç—å.

prompt_additions:
- –ö–û–†–û–¢–ö–ê–Ø —Å—Ç—Ä–æ–∫–∞ (–¥–æ ~300 —Å–∏–º–≤–æ–ª–æ–≤) —Ç–æ–ª—å–∫–æ –ø—Ä–æ –¥–≤–∏–∂–µ–Ω–∏–µ/—Ç–µ–º–ø/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è. –ü—Ä–∏–º–µ—Ä—ã:
  "allow tiny horizontal slide toward each other; keep size constant; ease-in/out"
  "very subtle head yaw only; no zoom; camera locked"
- –ù–µ –¥—É–±–ª–∏—Ä—É–π –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç, –Ω–µ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –≤–Ω–µ—à–Ω–∏–π –≤–∏–¥, –Ω–µ –¥–∞–≤–∞–π —Å–æ–≤–µ—Ç—ã –ø–æ –ø–µ—Ä–µ—Å—ä—ë–º–∫–µ –∑–¥–µ—Å—å.

–í–∞–∂–Ω–æ:
- –û—Ç–≤–µ—Ç —Ç–æ–ª—å–∫–æ JSON –ø–æ –≤—ã–¥–∞–Ω–Ω–æ–π —Å—Ö–µ–º–µ.
- reasons ‚Äî 1‚Äì4 –∫—Ä–∞—Ç–∫–∏—Ö –ø—É–Ω–∫—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å).
- –ù–µ —Ç—Ä–µ–±—É–π ¬´–≤—Å—Ç–∞—Ç—å –Ω–∞ –æ–¥–Ω—É —Å—Ç—É–ø–µ–Ω—å¬ª. –≠—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ.
"""

def oai_upload_image(path: str) -> str | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –¥–ª—è Assistants –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç file_id.
    """
    try:
        with open(path, "rb") as f:
            files = {"file": (os.path.basename(path), f, "image/png")}
            data = {"purpose": "assistants"}
            headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "OpenAI-Beta": "assistants=v2"}
            r = requests.post(f"{OAI_BASE}/files", headers=headers, files=files, data=data, timeout=60)
        if MF_DEBUG:
            try:
                os.makedirs("renders/temp", exist_ok=True)
                meta = {"file": os.path.basename(path), "size": os.path.getsize(path)}
                with open(os.path.join("renders/temp", f"oai_upload_{int(time.time())}.json"), "w", encoding="utf-8") as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)
                print("[OAI files] upload meta saved")
            except Exception as _e:
                print(f"[OAI files] upload meta err: {_e}")

        if r.status_code != 200:
            _log_oai("files", f"{OAI_BASE}/files", r.status_code, r.text)
            return None
        fid = r.json().get("id")
        if OAI_DEBUG:
            print(f"[OAI files] uploaded {path} -> {fid}")
        return fid
    except Exception as e:
        print(f"[OAI files] upload error: {e}")
        return None

def oai_create_thread_with_image(user_text: str, file_id: str) -> str | None:
    payload_thread = {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_text},
                    {"type": "image_file", "image_file": {"file_id": file_id}},
                ],
            }
        ]
    }
    try:
        r = requests.post(f"{OAI_BASE}/threads", headers=OAI_HEADERS, data=json.dumps(payload_thread), timeout=60)
        if r.status_code != 200:
            _log_oai("threads", f"{OAI_BASE}/threads", r.status_code, r.text, _json_preview(payload_thread))
            return None
        return r.json().get("id")
    except Exception as e:
        print(f"[OAI threads] create error: {e}")
        return None

def oai_gate_check(start_frame_path: str, base_prompt: str, meta: dict, timeout_sec: int = 120) -> dict | None:
    # –†—É—á–Ω–æ–π —Ç—É–º–±–ª–µ—Ä: –µ—Å–ª–∏ –≤—ã–∫–ª—é—á–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É.
    if not ASSISTANT_GATE_ENABLED:
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–¥—Ä–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º:
    1) upload —Ñ–∞–π–ª–∞ -> file_id
    2) threads.create (content: text + image_file)
    3) runs.create (response_format = JSON Schema)
    4) poll -> messages.list -> parse JSON
    """
    if not OPENAI_API_KEY or not OAI_ASSISTANT_ID:
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }

    # 1) Upload
    file_id = oai_upload_image(start_frame_path)
    if not file_id:
        print("[OAI] skip gate (upload failed)")
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }

    user_text = (
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n"
        f"- –§–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞: {meta.get('format')}\n"
        f"- –°—é–∂–µ—Ç: {meta.get('scene')}\n"
        f"- –§–æ–Ω: {meta.get('background')}\n\n"
        "–ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç (–µ–≥–æ –º–æ–∂–Ω–æ –î–û–ü–û–õ–ù–ò–¢–¨ –Ω—é–∞–Ω—Å–∞–º–∏ –¥–≤–∏–∂–µ–Ω–∏—è –∏ —Ç–µ–º–ø–∞, –Ω–æ –Ω–µ–ª—å–∑—è –º–µ–Ω—è—Ç—å –∫–æ–º–ø–æ–∑–∏—Ü–∏—é/–≤–Ω–µ—à–Ω–æ—Å—Ç—å):\n"
        f"{base_prompt}\n\n"
        "–ü–æ–ª–∏—Ç–∏–∫–∞ –º—è–≥–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏:\n"
        "‚Ä¢ –ù–ï –±–ª–æ–∫–∏—Ä—É–π –∑–∞ –º–µ–ª–∫–∏–µ –¥–µ—Ñ–µ–∫—Ç—ã: —Å–ª–µ–≥–∫–∞ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ –∫–æ–Ω—á–∏–∫–∏ –ø–∞–ª—å—Ü–µ–≤/–ø–æ–¥–æ—à–≤—ã, –ª—ë–≥–∫–∏–π –æ—Ä–µ–æ–ª, –º–∏–∫—Ä–æ-—Å–∫–æ–ª—ã –º–∞—Å–∫–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ Runway –¥–æ—Ä–∏—Å—É–µ—Ç.\n"
        "‚Ä¢ –ë–ª–æ–∫–∏—Ä—É–π –¢–û–õ–¨–ö–û —Å–µ—Ä—å—ë–∑–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã: –∫—Ä—É–ø–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —á–∞—Å—Ç–∏ —Ç–µ–ª–∞, —Å–∏–ª—å–Ω–æ–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –ª–∏—Ü, —è–≤–Ω–æ–µ ¬´–ø–∞—Ä–µ–Ω–∏–µ¬ª –±–µ–∑ –æ–ø–æ—Ä—ã –¥–≤—É–º—è –Ω–æ–≥–∞–º–∏, —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–π –Ω–∞–∫–ª–æ–Ω/–º–∞—Å—à—Ç–∞–±.\n"
        "‚Ä¢ –î–ª—è –æ–±—ä—è—Ç–∏–π/–ø–æ—Ü–µ–ª—É—è, –µ—Å–ª–∏ –ª—é–¥–∏ –¥–∞–ª–µ–∫–æ ‚Äî –≤–µ—Ä–Ω–∏ verdict='warn' –∏ –¥–æ–±–∞–≤—å –≤ prompt_additions –∫–æ—Ä–æ—Ç–∫—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É –ø—Ä–æ –º—è–≥–∫–∏–π –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π ¬´—Å—ä–µ–∑–¥¬ª –Ω–∞–≤—Å—Ç—Ä–µ—á—É (<=8% —à–∏—Ä–∏–Ω—ã –∫–∞–¥—Ä–∞ –Ω–∞ —á–µ–ª–æ–≤–µ–∫–∞), –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∏ —Å –Ω–æ–≥–∞–º–∏ –Ω–∞ –∑–µ–º–ª–µ.\n\n"
        "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ JSON –ø–æ –Ω–∞—à–µ–π —Å—Ö–µ–º–µ."
    )

    # 2) Thread
    thread_id = oai_create_thread_with_image(user_text, file_id)
    if not thread_id:
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }

    # 3) Run
    payload_run = {
        "assistant_id": OAI_ASSISTANT_ID,
        "instructions": MODERATION_INSTRUCTIONS,
        "response_format": {"type": "json_schema", "json_schema": MODERATION_SCHEMA},
        "temperature": 0.2
    }

    try:
        if MF_DEBUG:
            try:
                os.makedirs("renders/temp", exist_ok=True)
                with open(os.path.join("renders/temp", f"oai_run_{int(time.time())}.json"), "w", encoding="utf-8") as f:
                    json.dump(payload_run, f, ensure_ascii=False, indent=2)
                print("[OAI] run payload saved")
            except Exception as _e:
                print(f"[OAI] run payload save err: {_e}")
        r = requests.post(f"{OAI_BASE}/threads/{thread_id}/runs", headers=OAI_HEADERS, data=json.dumps(payload_run), timeout=60)
        if r.status_code != 200:
            _log_oai("runs", f"{OAI_BASE}/threads/{thread_id}/runs", r.status_code, r.text, _json_preview(payload_run))
            return None
        run_id = r.json().get("id")
    except Exception as e:
        print(f"[OAI runs] create error: {e}")
        return None

    # 4) Poll
    import time as _t
    start = _t.time()
    while True:
        rr = requests.get(f"{OAI_BASE}/threads/{thread_id}/runs/{run_id}", headers=OAI_HEADERS, timeout=60)
        if rr.status_code != 200:
            _log_oai("runs.get", f"{OAI_BASE}/threads/{thread_id}/runs/{run_id}", rr.status_code, rr.text)
            return None
        st = rr.json().get("status")
        if st in ("completed", "failed", "cancelled", "expired"):
            break
        if _t.time() - start > timeout_sec:
            print("[OAI] run timeout")
            return {
                "status": "accept",
                "user_notes": [],
                "backend_fixes": {
                    "recompose": False,
                    "issues": [],
                    "target_height_frac": [0.77, 0.77],
                    "target_centers": [0.35, 0.65],
                    "gap_frac": 0.05,
                    "align_feet": {"enabled": True, "floor_y": 1180}
                },
                "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
            }
        _t.sleep(1.5)

    if st != "completed":
        print(f"[OAI] run status={st}")
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }

    # 5) Read last message
    mm = requests.get(f"{OAI_BASE}/threads/{thread_id}/messages?limit=1&order=desc",
          headers=OAI_HEADERS, timeout=60)
    if mm.status_code != 200:
        _log_oai("messages", f"{OAI_BASE}/threads/{thread_id}/messages?limit=1", mm.status_code, mm.text)
        return {
            "status": "accept",
            "user_notes": [],
            "backend_fixes": {
                "recompose": False,
                "issues": [],
                "target_height_frac": [0.77, 0.77],
                "target_centers": [0.35, 0.65],
                "gap_frac": 0.05,
                "align_feet": {"enabled": True, "floor_y": 1180}
            },
            "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
        }
    data = mm.json().get("data", [])
    if not data:
        return None

    parts = data[0].get("content", [])
    for p in parts:
        # 1) structured JSON (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–∏ response_format=json_schema)
        if p.get("type") == "output_json":
            res = p.get("json")
            if isinstance(res, dict):
                try:
                    os.makedirs("renders/temp", exist_ok=True)
                    dbg = os.path.join("renders/temp", f"oai_gate_{int(time.time())}.json")
                    with open(dbg, "w", encoding="utf-8") as f:
                        json.dump(res, f, ensure_ascii=False, indent=2)
                    print(f"[OAI] parsed gate (output_json) -> {dbg}")
                except Exception as _e:
                    print(f"[OAI] debug save error: {_e}")
                res = _normalize_gate(res) or {
                    "status":"accept","user_notes":[],
                    "backend_fixes":{"recompose":False,"issues":[],"target_height_frac":[0.77,0.77],"target_centers":[0.35,0.65],"gap_frac":0.05,"align_feet":{"enabled":True,"floor_y":1180}},
                    "runway_prompt_additions":BACKUP_PROMPT_ADDITIONS
                }
                return res
            # –µ—Å–ª–∏ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–∏—á–∏–Ω–µ —Ç–∞–º —Å—Ç—Ä–æ–∫–∞ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            if isinstance(p.get("json"), str):
                try:
                    res = json.loads(p["json"])
                    return res
                except Exception as _:
                    pass

        # 2) —Ç–µ–∫—Å—Ç–æ–≤—ã–π JSON (fallback)
        if p.get("type") in ("output_text", "text"):
            raw = p.get("text")
            if isinstance(raw, dict):
                txt = raw.get("value")
            elif isinstance(raw, str):
                txt = raw
            else:
                txt = None
            if not txt:
                continue
            try:
                res = json.loads(txt)
                res = _normalize_gate(res)

                # –ª–æ–≥ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å + —Ñ–∞–π–ª
                try:
                    os.makedirs("renders/temp", exist_ok=True)
                    dbg = os.path.join("renders/temp", f"oai_gate_{int(time.time())}.json")
                    with open(dbg, "w", encoding="utf-8") as f:
                        json.dump(res or {}, f, ensure_ascii=False, indent=2)
                    print(f"[OAI] parsed gate -> {dbg}")
                except Exception as _e:
                    print(f"[OAI] debug save error: {_e}")
                return res
            except Exception as e:
                print(f"[OAI] JSON parse error: {e}\n{txt[:500]}")
                return {
                    "status": "accept",
                    "user_notes": [],
                    "backend_fixes": {
                        "recompose": False,
                        "issues": [],
                        "target_height_frac": [0.77, 0.77],
                        "target_centers": [0.35, 0.65],
                        "gap_frac": 0.05,
                        "align_feet": {"enabled": True, "floor_y": 1180}
                    },
                    "runway_prompt_additions": BACKUP_PROMPT_ADDITIONS
                }

# ---------- –í–´–†–ï–ó–ê–ù–ò–ï –ò –°–¢–ê–†–¢-–ö–ê–î–† ----------
def cutout(path: str) -> Image.Image:
    im = Image.open(path).convert("RGBA")
    cut = remove(im, session=RMBG_SESSION)  # –≤–∞–∂–Ω–æ–µ: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Å–µ—Å—Å–∏—é
    # rembg –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å bytes ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ PIL.Image
    if isinstance(cut, (bytes, bytearray)):
        cut = Image.open(io.BytesIO(cut)).convert("RGBA")
    return cut

def _resize_fit_center(img: Image.Image, W: int, H: int) -> Image.Image:
    """–í–ø–∏—Å–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ —Ö–æ–ª—Å—Ç W√óH —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π –∏ –∫—Ä–æ–ø–æ–º –ø–æ —Ü–µ–Ω—Ç—Ä—É."""
    wr, hr = W / img.width, H / img.height
    scale = max(wr, hr)
    new = img.resize((int(img.width * scale), int(img.height * scale)), RESAMPLE.LANCZOS)
    x = (new.width - W) // 2
    y = (new.height - H) // 2
    return new.crop((x, y, x + W, y + H))

def make_start_frame(photo_paths: List[str], framing_key: str, bg_file: str, layout: dict | None = None) -> str:

    def _min_target_for(framing: str, people_count: int) -> float:
        """
        –ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ —Ü–µ–ª–µ–≤–æ–π –≤—ã—Å–æ—Ç—ã (–¥–æ–ª—è H) ‚Äî —á—Ç–æ–±—ã —Ñ–∏–≥—É—Ä—ã –Ω–µ —Å—Ç–∞–ª–∏ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–º–∏.
        –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ–¥–æ–±—Ä–∞–Ω—ã –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ.
        """
        if "–í —Ä–æ—Å—Ç" in framing:
            return 0.82 if people_count >= 2 else 0.90
        elif "–ü–æ –ø–æ—è—Å" in framing:
            return 0.66 if people_count >= 2 else 0.72
        else:  # –ü–æ –≥—Ä—É–¥—å
            return 0.58 if people_count >= 2 else 0.62

    W, H = 720, 1280
    base_id = uuid.uuid4().hex  # –µ–¥–∏–Ω—ã–π id –¥–ª—è –ø—Ä–µ–≤—å—é/–º–µ—Ç—Ä–∏–∫
    floor_margin = 10  # –æ—Ç—Å—Ç—É–ø ¬´–ø–æ–ª–∞¬ª —Å–Ω–∏–∑—É
    # –í–µ—Ä—Ö–Ω–∏–π ¬´–≤–æ–∑–¥—É—Ö¬ª –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
    if "–ü–æ –≥—Ä—É–¥—å" in framing_key:
        HEADROOM_FRAC = 0.06
    elif "–ü–æ –ø–æ—è—Å" in framing_key:
        HEADROOM_FRAC = 0.04
    else:
        HEADROOM_FRAC = 0.02

    # 1) —Ñ–æ–Ω
    bg = Image.open(bg_file).convert("RGB")
    bg = _resize_fit_center(bg, W, H)
    bg = bg.filter(ImageFilter.GaussianBlur(radius=0.8))
    canvas = bg.convert("RGBA")

    # 2) –≤—ã—Ä–µ–∑–∞–µ–º –ª—é–¥–µ–π (–∏—Å–ø–æ–ª—å–∑—É–µ–º smart_cutout, –µ—Å–ª–∏ –æ–Ω —É —Ç–µ–±—è —É–∂–µ –µ—Å—Ç—å; –∏–Ω–∞—á–µ remove)
    cuts = []
    for p in photo_paths:
        im = Image.open(p).convert("RGBA")
        try:
            cut_rgba = smart_cutout(im)  # –µ—Å–ª–∏ –≤—Å—Ç–∞–≤–ª—è–ª —Ä–∞–Ω–µ–µ
        except NameError:
            cut_rgba = remove(im)
            if isinstance(cut_rgba, (bytes, bytearray)):
                cut_rgba = Image.open(io.BytesIO(cut_rgba)).convert("RGBA")
        cuts.append(cut_rgba)

    if MF_DEBUG:
        try:
            for i, c in enumerate(cuts):
                bb, yb = alpha_metrics(c)
                eff_h = max(1, (yb - bb[1] + 1))
                print(f"[LAYOUT] person#{i+1}: img={c.width}x{c.height} eff_h={eff_h} bbox={bb}")
        except Exception as _e:
            print(f"[LAYOUT] cut metrics err: {_e}")

    # 3) —Ü–µ–ª–µ–≤–∞—è –≤—ã—Å–æ—Ç–∞ —Ñ–∏–≥—É—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–∞–¥—Ä–∞
    two = (len(photo_paths) > 1)
    if "–í —Ä–æ—Å—Ç" in framing_key:
        target_h = TH_FULL_DOUBLE if two else TH_FULL_SINGLE
    elif "–ü–æ –ø–æ—è—Å" in framing_key:
        target_h = TH_WAIST_DOUBLE if two else TH_WAIST_SINGLE
    else:  # ¬´–ü–æ –≥—Ä—É–¥—å¬ª
        target_h = TH_CHEST_DOUBLE if two else TH_CHEST_SINGLE

    # –∂—ë—Å—Ç–∫–∏–π –º–∏–Ω–∏–º—É–º ‚Äî –Ω–µ –¥–∞—ë–º –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å—Å—è –≤ ¬´–∫–∞—Ä–ª–∏–∫–æ–≤¬ª
    target_h_min = _min_target_for(framing_key, len(photo_paths))
    if target_h < target_h_min:
        target_h = target_h_min

    def scale_to_target_effective(img: Image.Image, target: float) -> Image.Image:
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –ø–æ —Ü–µ–ª–µ–≤–æ–π –≤—ã—Å–æ—Ç–µ –±–µ–∑ —É–º–µ–Ω—å—à–µ–Ω–∏—è
        bbox, yb = alpha_metrics(img)
        eff_h = max(1, (yb - bbox[1] + 1))
        scale = (H * target) / eff_h
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∞–ø—Å–∫–µ–π–ª (–º–æ–∂–Ω–æ –ø–æ–¥–Ω—è—Ç—å —á–µ—Ä–µ–∑ env MAX_UPSCALE)
        if scale > MAX_UPSCALE:
            scale = MAX_UPSCALE
        nw, nh = max(1, int(img.width * scale)), max(1, int(img.height * scale))
        return img.resize((nw, nh), RESAMPLE.LANCZOS)


    def place_y_for_floor(img: Image.Image) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç y —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–∏–∂–Ω—è—è ¬´–ø–æ–¥–æ—à–≤–∞¬ª —Å—Ç–∞–ª–∞ –Ω–∞ –ª–∏–Ω–∏—é –ø–æ–ª–∞."""
        bbox, yb = alpha_metrics(img)
        eff_h = (yb - bbox[1] + 1)
        # –≥–¥–µ –¥–æ–ª–∂–µ–Ω –æ–∫–∞–∑–∞—Ç—å—Å—è –≤–µ—Ä—Ö bbox –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–∞–¥—Ä–∞
        y_top_content = H - floor_margin - eff_h
        # –ø–µ—Ä–µ–≤–æ–¥–∏–º –≤ y –≤–µ—Ä—Ö–Ω–µ–≥–æ –ª–µ–≤–æ–≥–æ —É–≥–ª–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        y_img = y_top_content - bbox[1]
        return int(y_img)

    def draw_with_shadow(base: Image.Image, person: Image.Image, x: int, y: int):
        alpha = person.split()[-1]
        soft = alpha.filter(ImageFilter.GaussianBlur(6))
        shadow = Image.new("RGBA", person.size, (0, 0, 0, 0))
        shadow.putalpha(soft.point(lambda a: int(a * 0.45)))
        base.alpha_composite(shadow, (x, y + 8))
        base.alpha_composite(person, (x, y))

    def _rect_at(x, y, img):
        bx, by, bx1, by1 = alpha_metrics(img)[0]
        return (x + bx, y + by, x + bx1, y + by1)

    def _draw_debug_boxes(base: Image.Image, rects: list[tuple[int,int,int,int]]):
        if not START_OVERLAY_DEBUG:
            return
        ov = Image.new("RGBA", base.size, (0,0,0,0))
        g = ImageDraw.Draw(ov)
        # –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ —Ä–∞–º–∫–∏ (–∫—Ä–∞—Å–Ω—ã–µ)
        for r in rects:
            g.rectangle(r, outline=(255, 0, 0, 200), width=3)
        # –∑–µ–ª—ë–Ω–∞—è ¬´safe¬ª-—Ä–∞–º–∫–∞ –ø–æ –ø–æ–ª—è–º –∫–∞–¥—Ä–∞
        m = 20
        g.rectangle((m, m, base.width - m, base.height - m), outline=(0, 255, 0, 180), width=2)
        base.alpha_composite(ov)

    if len(cuts) == 1:
        P = scale_to_target_effective(cuts[0], target_h)
        x = (W - P.width) // 2
        y = place_y_for_floor(P)

        # —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∏–¥–∏–º—É—é –≤—ã—Å–æ—Ç—É —Ñ–∏–≥—É—Ä—ã –≤ –∫–∞–¥—Ä–µ –¥–æ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏
        def rect_at_single(px, py, img):
            bx, by, bx1, by1 = alpha_metrics(img)[0]
            return (px + bx, py + by, px + bx1, py + by1)

        r = rect_at_single(x, y, P)
        group_h = r[3] - r[1]

        # –≤—ã–±—Ä–∞—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–æ–ª—é –ø–æ —Ñ–æ—Ä–º–∞—Ç—É
        fmt = "–í —Ä–æ—Å—Ç" if "–í —Ä–æ—Å—Ç" in framing_key else ("–ü–æ –ø–æ—è—Å" if "–ü–æ –ø–æ—è—Å" in framing_key else "–ü–æ –≥—Ä—É–¥—å")
        min_h_frac = MIN_SINGLE_FRAC[fmt]

        # –µ—Å–ª–∏ —Ñ–∏–≥—É—Ä–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ ‚Äî –º—è–≥–∫–æ –ø–æ–¥—Ä–∞—Å—Ç–∏–º
        if group_h < int(min_h_frac * H):
            need = (min_h_frac * H) / max(1, group_h)
            cap = SINGLE_UPSCALE_CAP
            new_target = min(target_h * need, target_h * cap)
            if new_target > target_h:
                P = scale_to_target_effective(cuts[0], new_target)
                x = (W - P.width) // 2
                y = place_y_for_floor(P)

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—Å—Ç—É–ø—ã –æ—Ç –∫—Ä–∞—ë–≤
        margin = 20
        x = max(margin, min(W - P.width - margin, x))
        top_margin = max(margin, int(HEADROOM_FRAC * H))
        y = max(top_margin, min(H - P.height - margin, y))

        # --- –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –º—è–≥–∫–∏–π –º–∞—Å—à—Ç–∞–±/—Å–¥–≤–∏–≥ –∏–∑ layout_feedback (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if layout and isinstance(layout, dict):
            # –û–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ —Ç—Ä–∞–∫—Ç—É–µ–º –∫–∞–∫ "–ª–µ–≤—ã–π"
            scl = int(layout.get("scale_left_pct", 0) or 0)
            dxl = int(layout.get("shift_left_px", 0) or 0)

            # –º—è–≥–∫–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∞ (¬±20%)
            if scl != 0:
                k = 1.0 + max(-0.20, min(0.20, scl / 100.0))
                nw, nh = max(1, int(P.width * k)), max(1, int(P.height * k))
                P = P.resize((nw, nh), RESAMPLE.LANCZOS)
                # –ø–µ—Ä–µ—Å—á—ë—Ç y (—Å—Ç–∞–≤–∏–º –Ω–∞ –ø–æ–ª –ø–æ—Å–ª–µ —Ä–µ—Å–∫–µ–π–ª–∞)
                y = place_y_for_floor(P)

            # —Å–¥–≤–∏–≥: shift_left_px>0 ‚Äî –¥–≤–∏–≥–∞–µ–º –í–õ–ï–í–û, –ø–æ—ç—Ç–æ–º—É dx = -shift_left_px
            if dxl != 0:
                x += int(-dxl)

            # –°—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç –≤—ã—Ö–æ–¥–∞ –∑–∞ –∫–∞–¥—Ä
            margin = 20
            x = max(margin, min(W - P.width - margin, x))
            y = max(margin, min(H - P.height - margin, y))

        # –ü—Ä–∏–º–µ–Ω—è–µ–º layout_hint –¥–ª—è 1-–π —Ñ–∏–≥—É—Ä—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª—è "left")
        if layout:
            try:
                sh = int(layout.get("shift_left_px", 0))
                sc = int(layout.get("scale_left_pct", 0))
                # –º–∞—Å—à—Ç–∞–±
                if sc:
                    factor = max(0.7, min(1.4, 1.0 + sc / 100.0))
                    nw = max(1, int(P.width * factor))
                    nh = max(1, int(P.height * factor))
                    P = P.resize((nw, nh), RESAMPLE.LANCZOS)
                    y = place_y_for_floor(P)
                    # –ø–µ—Ä–µ—Å—á—ë—Ç x –≤ —Ü–µ–Ω—Ç—Ä–µ
                    x = (W - P.width) // 2
                # —Å–¥–≤–∏–≥
                if sh:
                    x += sh
                # –≤ –≥—Ä–∞–Ω–∏—Ü–∞—Ö –∫–∞–¥—Ä–∞
                margin = 20
                x = max(margin, min(W - P.width - margin, x))
                y = max(margin, min(H - P.height - margin, y))
            except Exception as _e:
                print(f"[START_FRAME:1] layout_hint ignored: {_e}")

        # --- –ê–Ω—Ç–∏-–∫–∞—Ä–ª–∏–∫: –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é ¬´–≤–∏–¥–∏–º—É—é¬ª –≤—ã—Å–æ—Ç—É —Å–∏–ª—É—ç—Ç–∞
        min_frac = _min_frac_for(framing_key, 1)

        def _visible_frac(img: Image.Image) -> float:
            bb, yb = alpha_metrics(img)
            eff_h = max(1, (yb - bb[1] + 1))
            return eff_h / H

        grow_tries = 0
        while _visible_frac(P) < min_frac and grow_tries < 12:
            # –ø—Ä–æ–±—É–µ–º —á—É—Ç—å —É–≤–µ–ª–∏—á–∏—Ç—å —Ü–µ–ª–µ–≤–æ–π —Ç–∞—Ä–≥–µ—Ç
            new_target = min(target_h * 1.04, 0.98)  # –Ω–µ –ø—Ä–æ—Å–∏–º >98% –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞
            newP = scale_to_target_effective(cuts[0], new_target)
            # –ø–µ—Ä–µ—Å—á—ë—Ç –ø–æ–∑–∏—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ü–µ–Ω—Ç—Ä–∞
            cx = x + P.width // 2
            cy_floor = place_y_for_floor(newP)
            newx = cx - newP.width // 2
            margin = 20
            newx = max(margin, min(W - newP.width - margin, newx))
            newy = max(margin, min(H - newP.height - margin, cy_floor))

            # –µ—Å–ª–∏ —É–ø—Ä—ë–º—Å—è –≤ –≤–µ—Ä—Ö/–±–æ–∫–∞ ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–æ—Å—Ç
            if newy <= margin or newx <= margin or (newx + newP.width) >= (W - margin):
                break

            # –ø—Ä–∏–º–µ–Ω—è–µ–º —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
            P, x, y = newP, newx, newy
            target_h = new_target
            grow_tries += 1

        draw_with_shadow(canvas, P, x, y)
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –æ–≤–µ—Ä–ª–µ–π (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
        try:
            _draw_debug_boxes(canvas, [_rect_at(x, y, P)])
        except Exception:
            pass

    else:
        L = scale_to_target_effective(cuts[0], target_h)
        R = scale_to_target_effective(cuts[1], target_h)
        base_target = target_h  # –∑–∞–ø–æ–º–Ω–∏–º –∏—Å—Ö–æ–¥–Ω—É—é —Ü–µ–ª—å –¥–ª—è –ø–∞—Ä—ã, –Ω–∏–∂–µ –Ω–µ –¥–∞–¥–∏–º —É–π—Ç–∏ —Å–∏–ª—å–Ω–æ –º–µ–Ω—å—à–µ
        if MF_DEBUG:
            print(f"[LAYOUT] target_h={target_h:.3f} base_target={base_target:.3f}  L={L.width}x{L.height}  R={R.width}x{R.height}")

        # —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ —Ü–µ–Ω—Ç—Ä—ã ‚Äî —á—É—Ç—å –±–ª–∏–∂–µ –∫ –∫—Ä–∞—è–º
        lx = int(W * CENTER_BIAS_FRAC) - L.width // 2
        rx = int(W * (1 - CENTER_BIAS_FRAC)) - R.width // 2
        yl = place_y_for_floor(L)
        yr = place_y_for_floor(R)

        def rect_at(x, y, img):
            bx, by, bx1, by1 = alpha_metrics(img)[0]
            return (x + bx, y + by, x + bx1, y + by1)

        def horizontal_overlap(a, b):
            return not (a[2] + MIN_GAP_PX <= b[0] or b[2] + MIN_GAP_PX <= a[0])

        # 1) –Ω–∞—á–∞–ª—å–Ω–æ–µ —Ä–∞–∑–≤–µ–¥–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)

        tries = 0
        margin = 20
        shrink_once = False
        while horizontal_overlap(ra, rb) and tries < 30:
            # –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–¥–≤–∏–Ω—É—Ç—å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ
            new_lx = lx - 3
            new_rx = rx + 3

            if new_lx >= margin and new_rx + R.width <= W - margin:
                lx = new_lx
                rx = new_rx
            else:
                # –µ—Å–ª–∏ –≤ —Å—Ç–æ—Ä–æ–Ω—ã –Ω–µ –ª–µ–∑–µ—Ç, –ø–æ–∑–≤–æ–ª–∏–º –û–î–ò–ù —Ä–∞–∑ –æ—á–µ–Ω—å –º—è–≥–∫–æ —É–º–µ–Ω—å—à–∏—Ç—å
                if not shrink_once:
                    target_h = max(base_target * 0.94, target_h * 0.97)
                    if target_h < target_h_min:
                        target_h = target_h_min
                    L = scale_to_target_effective(cuts[0], target_h)
                    R = scale_to_target_effective(cuts[1], target_h)
                    yl = place_y_for_floor(L); yr = place_y_for_floor(R)
                    # –ø–µ—Ä–µ—Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ä—Ç –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É
                    lx = int(W * 0.42) - L.width // 2
                    rx = int(W * 0.58) - R.width // 2
                    shrink_once = True
                else:
                    # –¥–∞–ª—å—à–µ –Ω–µ —É–º–µ–Ω—å—à–∞–µ–º ‚Äî –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞, –æ—Å—Ç–∞–ª—å–Ω–æ–µ –ø–æ–ø—Ä–∞–≤–∏—Ç safety
                    break

            ra = rect_at(lx, yl, L)
            rb = rect_at(rx, yr, R)
            tries += 1

        # 2) –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –ª—é–¥–µ–π –∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é 
        def inner_gap_px(a, b):
            # –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–º–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞–º–∏ (–Ω–µ –ø–æ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –∫—Ä–∞—è–º)
            return max(0, b[0] - a[2])

        # –¶–µ–ª–µ–≤–æ–π –∑–∞–∑–æ—Ä = max(—Ñ—Ä–∞–∫—Ü–∏–∏ –∫–∞–¥—Ä–∞, —Ñ—Ä–∞–∫—Ü–∏–∏ —Å—Ä–µ–¥–Ω–µ–π —à–∏—Ä–∏–Ω—ã —Ñ–∏–≥—É—Ä, –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∑–∞–∑–æ—Ä–∞)
        mean_width = (L.width + R.width) / 2
        ideal_gap_w = int(IDEAL_GAP_FRAC * W)   # 5% –∫–∞–¥—Ä–∞ (—Å–º. –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É IDEAL_GAP_FRAC)
        ideal_gap_p = int(0.12 * mean_width)    # 12% —Å—Ä–µ–¥–Ω–µ–π —à–∏—Ä–∏–Ω—ã –ª—é–¥–µ–π
        ideal_gap   = max(MIN_GAP_PX, ideal_gap_w, ideal_gap_p)

        pull_tries = 0
        while inner_gap_px(ra, rb) > ideal_gap and pull_tries < 25:
            excess = inner_gap_px(ra, rb) - ideal_gap
            step = max(1, min(8, excess // 2))
            lx += step
            rx -= step
            ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
            # –Ω–µ –¥–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è ‚Äî –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥
            if horizontal_overlap(ra, rb):
                lx -= step; rx += step
                break
            pull_tries += 1

        # 3) —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –µ–¥–∏–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)

        def any_outside(r):
            x0,y0,x1,y1 = r
            margin = 20  # —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –æ—Ç—Å—Ç—É–ø
            return x0 < margin or x1 > W-margin or y0 < margin or y1 > H-margin

        def headroom_ok(r):
            return r[1] > int(HEADROOM_FRAC * H)

        max_person_width = int(0.48 * W)

        # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –¥–µ–ª–∞–µ–º –û–î–ù–£ –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —Ä–∞–∑–º–µ—Ä–∞
        problems = []
        if any_outside(ra) or any_outside(rb): 
            problems.append("outside")
        if not headroom_ok(ra) or not headroom_ok(rb): 
            problems.append("headroom")
        if L.width > max_person_width or R.width > max_person_width: 
            problems.append("too_wide")

        if problems:
            # –Ω–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ ‚Äî –Ω–µ –º–µ–Ω—å—à–µ 90% –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –¥–ª—è –ø–∞—Ä—ã
            min_allowed = base_target * 0.90

            if "headroom" in problems:
                top_margin = int(0.01 * H)
                max_height = H - floor_margin - top_margin
                bbox_l, _ = alpha_metrics(L)
                bbox_r, _ = alpha_metrics(R)
                eff_h_l = (bbox_l[3] - bbox_l[1])
                eff_h_r = (bbox_r[3] - bbox_r[1])
                new_target = min(max_height / max(eff_h_l, eff_h_r), target_h)
                new_target = max(new_target, min_allowed)
            else:
                new_target = max(target_h * 0.97, min_allowed)
                if target_h < target_h_min:
                    target_h = target_h_min

            target_h = new_target  # –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ —Ü–µ–ª–µ–≤–æ–µ
            L = scale_to_target_effective(cuts[0], target_h)
            R = scale_to_target_effective(cuts[1], target_h)
            yl = place_y_for_floor(L); yr = place_y_for_floor(R)
            lx = int(W * 0.42) - L.width // 2
            rx = int(W * 0.58) - R.width // 2

        # 3b) —Ü–µ–Ω—Ç—Ä–∏—Ä—É—é—â–∞—è –ø–æ–ª–æ—Å–∞ –ø–æ–¥ —Ñ–æ–Ω ‚Äî —Å–¥–≤–∏–≥–∞–µ–º –ø–∞—Ä—É –≤–Ω—É—Ç—Ä—å –ø–æ–ª–æ—Å—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Ç–µ–∫—É—â–∏–π –∑–∞–∑–æ—Ä
        _p = _bg_layout_presets(bg_file)
        band_left  = int(W * (_p["center_frac"] - _p["band_frac"] / 2.0))
        band_right = int(W * (_p["center_frac"] + _p["band_frac"] / 2.0))

        ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
        cxL = (ra[0] + ra[2]) // 2
        cxR = (rb[0] + rb[2]) // 2

        shift_pair = 0
        if cxL < band_left:
            shift_pair = max(shift_pair, band_left - cxL)
        if cxR > band_right:
            shift_pair = min(shift_pair, band_right - cxR)  # —ç—Ç–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ —Å–º–µ—â–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–∞–¥–æ –≤–ø—Ä–∞–≤–æ —Å—É–∑–∏—Ç—å

        lx += shift_pair
        rx += shift_pair
        margin = 20
        lx = max(margin, min(W - L.width - margin, lx))
        rx = max(margin, min(W - R.width - margin, rx))

        # 3c) –µ—Å–ª–∏ —Å–≤–µ—Ä—Ö—É —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤–æ–∑–¥—É—Ö–∞ ‚Äî —Å–ª–µ–≥–∫–∞ —É–≤–µ–ª–∏—á–∏–º –ª—é–¥–µ–π –û–î–ò–ù –†–ê–ó
        ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
        topY = min(ra[1], rb[1])
        if topY > int(_p["top_headroom_max"] * H):
            new_target = min(base_target * 1.08, 0.94)  # –Ω–µ —Ä–∞–∑–¥—É–≤–∞–µ–º –≤—ã—à–µ 94% –∫–∞–¥—Ä–∞ –∏ –Ω–µ –±–æ–ª–µ–µ +8% –∫ –∏—Å—Ö–æ–¥–Ω–æ–π —Ü–µ–ª–∏
            if new_target > target_h:
                target_h = new_target
                L = scale_to_target_effective(cuts[0], target_h)
                R = scale_to_target_effective(cuts[1], target_h)
                yl = place_y_for_floor(L); yr = place_y_for_floor(R)
                # —Å–Ω–æ–≤–∞ –≤—ã—Å—Ç–∞–≤–∏–º –±–∞–∑–æ–≤—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –±–ª–∏–∂–µ –∫ —Ü–µ–Ω—Ç—Ä—É
                lx = int(W * CENTER_BIAS_FRAC) - L.width // 2
                rx = int(W * (1 - CENTER_BIAS_FRAC)) - R.width // 2

                # –±—ã—Å—Ç—Ä—ã–π –¥–æ–≤–æ–¥–æ—á–Ω—ã–π —Ü–∏–∫–ª: —Ü–µ–ª–µ–≤–æ–π –∑–∞–∑–æ—Ä
                def _inner_gap(a, b): return max(0, b[0] - a[2])
                ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
                ideal_gap2 = max(MIN_GAP_PX, int(0.15 * ((L.width + R.width) / 2)))
                for _ in range(14):
                    if horizontal_overlap(ra, rb) or _inner_gap(ra, rb) <= ideal_gap2:
                        break
                    step = max(1, min(8, (_inner_gap(ra, rb) - ideal_gap2) // 2))
                    lx += step; rx -= step
                    ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)

        # –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ–∑–∏—Ü–∏–π –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∫–∞–¥—Ä–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –æ—Ç—Å—Ç—É–ø–æ–º
        margin = 20
        lx = max(margin, min(W - L.width - margin, lx))
        rx = max(margin, min(W - R.width - margin, rx))

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)
        if horizontal_overlap(ra, rb):
            # –µ—Å–ª–∏ –≤—Å–µ –µ—â–µ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–¥–≤–∏–≥–∞–µ–º –∏–ª–∏ —É–º–µ–Ω—å—à–∞–µ–º
            center = W // 2
            if lx + L.width // 2 < center:
                # –ª–µ–≤–∞—è —Ñ–∏–≥—É—Ä–∞ –ª–µ–≤–µ–µ —Ü–µ–Ω—Ç—Ä–∞ - —Å–¥–≤–∏–≥–∞–µ–º –≤–ª–µ–≤–æ
                lx = max(margin, lx - 10)
            if rx + R.width // 2 > center:
                # –ø—Ä–∞–≤–∞—è —Ñ–∏–≥—É—Ä–∞ –ø—Ä–∞–≤–µ–µ —Ü–µ–Ω—Ç—Ä–∞ - —Å–¥–≤–∏–≥–∞–µ–º –≤–ø—Ä–∞–≤–æ  
                rx = min(W - R.width - margin, rx + 10)
        if MF_DEBUG:
            try:
                def rect_at(x, y, img):
                    bx, by, bx1, by1 = alpha_metrics(img)[0]
                    return (x + bx, y + by, x + bx1, y + by1)

                ra = rect_at(lx, yl, L)
                rb = rect_at(rx, yr, R)
                gap = max(0, rb[0] - ra[2])
                print(f"[LAYOUT] final: lx={lx}, yl={yl}, rx={rx}, yr={yr}, gap={gap}px  Lw={L.width} Rw={R.width}")

                # —Ä–∏—Å—É–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—ã–π –æ–≤–µ—Ä–ª–µ–π
                dbg = canvas.copy()
                drw = ImageDraw.Draw(dbg)
                drw.rectangle(ra, outline=(255,0,0,255), width=3)  # L - –∫—Ä–∞—Å–Ω—ã–π
                drw.rectangle(rb, outline=(0,128,255,255), width=3)  # R - —Å–∏–Ω–∏–π
                drw.text((ra[0]+4, ra[1]+4), f"L {L.width}x{L.height}", fill=(255,0,0,255))
                drw.text((rb[0]+4, rb[1]+4), f"R {R.width}x{R.height}", fill=(0,128,255,255))
                drw.text((min(ra[2], rb[0])+4, max(ra[1], rb[1])+4), f"gap={gap}px", fill=(255,255,0,255))
                os.makedirs("renders/temp", exist_ok=True)
                dbg_path = os.path.join("renders/temp", f"start_debug_{int(time.time())}.png")
                dbg.save(dbg_path, "PNG")
                print(f"[LAYOUT] debug overlay -> {dbg_path}")
            except Exception as _e:
                print(f"[LAYOUT] debug overlay err: {_e}")

        # --- –∞–Ω—Ç–∏-–º–∏–∫—Ä–æ: –µ—Å–ª–∏ –ø–∞—Ä–∞ –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–æ –≤—ã—Å–æ—Ç—ã –∫–∞–¥—Ä–∞ ‚Äî –º—è–≥–∫–æ –ø–æ–¥—Ä–∞—Å—Ç–∏–º –æ–±–µ —Ñ–∏–≥—É—Ä—ã
        def rect_at(x, y, img):
            bx, by, bx1, by1 = alpha_metrics(img)[0]
            return (x + bx, y + by, x + bx1, y + by1)

        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)
        group_top = min(ra[1], rb[1])
        group_bottom = max(ra[3], rb[3])
        group_h = group_bottom - group_top

        fmt = "–í —Ä–æ—Å—Ç" if "–í —Ä–æ—Å—Ç" in framing_key else ("–ü–æ –ø–æ—è—Å" if "–ü–æ –ø–æ—è—Å" in framing_key else "–ü–æ –≥—Ä—É–¥—å")
        min_group_frac = MIN_PAIR_FRAC[fmt]

        if group_h < int(min_group_frac * H):
            # –Ω–∞—Å—á–∏—Ç–∞–ª–∏, –Ω–∞—Å–∫–æ–ª—å–∫–æ –Ω–∞–¥–æ –≤—ã—Ä–∞—Å—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ç–µ–∫—É—â–µ–π —Ü–µ–ª–µ–≤–æ–π –≤—ã—Å–æ—Ç—ã
            need = (min_group_frac * H) / max(1, group_h)
            new_target = min(target_h * need, target_h * PAIR_UPSCALE_CAP)

            if new_target > target_h:
                # –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º L/R —Å –Ω–æ–≤—ã–º target –∏ —Å–Ω–æ–≤–∞ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Ä–∞—Å—Å—Ç–∞–≤–ª—è–µ–º
                target_h = new_target
                L = scale_to_target_effective(cuts[0], target_h)
                R = scale_to_target_effective(cuts[1], target_h)

                lx = int(W * CENTER_BIAS_FRAC) - L.width // 2
                rx = int(W * (1 - CENTER_BIAS_FRAC)) - R.width // 2
                yl = place_y_for_floor(L)
                yr = place_y_for_floor(R)

                # –±—ã—Å—Ç—Ä—ã–π –ø—Ä–æ—Ö–æ–¥ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π + –ø–æ–¥—Ç—è–∂–∫–∞ –∫ –∏–¥–µ–∞–ª—å–Ω–æ–º—É –∑–∞–∑–æ—Ä—É (–∫–æ—Ä–æ—á–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ)
                def horizontal_overlap(a, b):
                    return not (a[2] + MIN_GAP_PX <= b[0] or b[2] + MIN_GAP_PX <= a[0])

                ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
                tries = 0
                while horizontal_overlap(ra, rb) and tries < 24:
                    if (lx + L.width//2) <= (rx + R.width//2):
                        lx -= 3; rx += 3
                    else:
                        lx += 3; rx -= 3
                    ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
                    tries += 1

                # –ø–æ–¥—Ç—è–Ω—É—Ç—å –∫ —Ä–∞–∑—É–º–Ω–æ–º—É –∑–∞–∑–æ—Ä—É, –Ω–æ –Ω–µ –¥–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
                def inner_gap_px(a, b): return max(0, b[0] - a[2])
                ideal_gap = max(MIN_GAP_PX, int(0.15 * ((L.width + R.width) / 2)))
                pulls = 0
                while inner_gap_px(ra, rb) > ideal_gap and pulls < 20:
                    step = max(1, min(8, (inner_gap_px(ra, rb) - ideal_gap) // 2))
                    lx += step; rx -= step
                    ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
                    if horizontal_overlap(ra, rb):
                        lx -= step; rx += step
                        break
                    pulls += 1

                # –æ—Ç—Å—Ç—É–ø—ã –æ—Ç –∫—Ä–∞—ë–≤
                margin = 20
                lx = max(margin, min(W - L.width - margin, lx))
                rx = max(margin, min(W - R.width - margin, rx))

                # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞ –ø–æ ¬´–≤–æ–∑–¥—É—Ö—É¬ª —Å–≤–µ—Ä—Ö—É (–Ω–µ –ø–æ–¥–ø–∏—Ä–∞–µ–º —Å–æ–≤—Å–µ–º)
                def headroom_ok(r): return r[1] > int(0.01 * H)
                ra = rect_at(lx, yl, L); rb = rect_at(rx, yr, R)
                if not headroom_ok(ra) or not headroom_ok(rb):
                    # –µ—Å–ª–∏ —É–ø—ë—Ä–ª–∏—Å—å –≤ –≤–µ—Ä—Ö ‚Äî —Å–ª–µ–≥–∫–∞ –ø–æ–¥–∂–∞—Ç—å (2%)
                    t2 = target_h * 0.98
                    if target_h < target_h_min:
                        target_h = target_h_min
                    L = scale_to_target_effective(cuts[0], t2)
                    R = scale_to_target_effective(cuts[1], t2)
                    yl = place_y_for_floor(L); yr = place_y_for_floor(R)
                    lx = int(W * CENTER_BIAS_FRAC) - L.width // 2
                    rx = int(W * (1 - CENTER_BIAS_FRAC)) - R.width // 2

        # --- –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –º—è–≥–∫–∏–π –º–∞—Å—à—Ç–∞–±/—Å–¥–≤–∏–≥ –∏–∑ layout_feedback (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if layout and isinstance(layout, dict):
            scl_l = int(layout.get("scale_left_pct", 0)  or 0)
            scl_r = int(layout.get("scale_right_pct", 0) or 0)
            dx_l  = int(layout.get("shift_left_px", 0)   or 0)
            dx_r  = int(layout.get("shift_right_px", 0)  or 0)

            # –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö ¬±20%
            def _apply_scale(img: Image.Image, scl_pct: int) -> Image.Image:
                if scl_pct == 0:
                    return img
                k = 1.0 + max(-0.20, min(0.20, scl_pct / 100.0))
                nw, nh = max(1, int(img.width * k)), max(1, int(img.height * k))
                return img.resize((nw, nh), RESAMPLE.LANCZOS)

            L = _apply_scale(L, scl_l)
            R = _apply_scale(R, scl_r)
            # –ø–æ—Å–ª–µ —Ä–µ—Å–∫–µ–π–ª–∞ –ø–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º "–ø–æ–ª"
            yl = place_y_for_floor(L)
            yr = place_y_for_floor(R)

            # —Å–º–µ—â–µ–Ω–∏—è:
            # shift_left_px>0 ‚Äî –¥–≤–∏–≥–∞–π –õ–ï–í–û–ì–û –≤–ª–µ–≤–æ ‚Üí x -= shift_left_px
            # shift_right_px>0 ‚Äî –¥–≤–∏–≥–∞–π –ü–†–ê–í–û–ì–û –≤–ø—Ä–∞–≤–æ ‚Üí x += shift_right_px
            if dx_l != 0:
                lx += int(-dx_l)
            if dx_r != 0:
                rx += int(dx_r)

            # —Å—Ç—Ä–∞—Ö—É–µ–º—Å—è –æ—Ç –≤—ã—Ö–æ–¥–∞ –∑–∞ –∫–∞–¥—Ä
            margin = 20
            lx = max(margin, min(W - L.width - margin, lx))
            rx = max(margin, min(W - R.width - margin, rx))

            # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –ø–æ—Å–ª–µ —Ä—É—á–Ω—ã—Ö —Å–¥–≤–∏–≥–æ–≤
            ra = rect_at(lx, yl, L)
            rb = rect_at(rx, yr, R)
            if horizontal_overlap(ra, rb):
                # –º—è–≥–∫–æ —Ä–∞–∑–¥–≤–∏–Ω–µ–º –Ω–∞ MIN_GAP_PX
                gap = max(0, min(12, MIN_GAP_PX // 2))
                lx -= gap
                rx += gap
                # –∏ –∑–∞–Ω–æ–≤–æ –≤ –≥—Ä–∞–Ω–∏—Ü—ã
                lx = max(margin, min(W - L.width - margin, lx))
                rx = max(margin, min(W - R.width - margin, rx))

        # --- –ü—Ä–∏–º–µ–Ω—è–µ–º layout_hint (–º–∞—Å—à—Ç–∞–±/—Å–¥–≤–∏–≥ –¥–ª—è L/R), –∑–∞—Ç–µ–º ¬´–∞–≤—Ç–æ–ø–æ–¥—Ç—è–∂–∫–∞¬ª –±–ª–∏–∂–µ –±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
        try:
            if layout:
                sl = int(layout.get("scale_left_pct", 0))
                sr = int(layout.get("scale_right_pct", 0))
                shl = int(layout.get("shift_left_px", 0))
                shr = int(layout.get("shift_right_px", 0))

                def _apply_scale(img, delta_pct):
                    if not delta_pct:
                        return img
                    factor = max(0.7, min(1.4, 1.0 + delta_pct / 100.0))
                    nw = max(1, int(img.width * factor))
                    nh = max(1, int(img.height * factor))
                    return img.resize((nw, nh), RESAMPLE.LANCZOS)

                if sl:
                    L = _apply_scale(L, sl)
                    yl = place_y_for_floor(L)
                if sr:
                    R = _apply_scale(R, sr)
                    yr = place_y_for_floor(R)

                if shl:
                    lx += shl
                if shr:
                    rx += shr

                # –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –∫–∞–¥—Ä–∞
                margin = 20
                lx = max(margin, min(W - L.width - margin, lx))
                rx = max(margin, min(W - R.width - margin, rx))

                # –µ—Å–ª–∏ –ø–µ—Ä–µ–∫—Ä—ã–ª–∏—Å—å ‚Äî —Ä–∞–∑–¥–≤–∏–≥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –ø–æ—Ä–æ–≤–Ω—É
                ra = rect_at(lx, yl, L)
                rb = rect_at(rx, yr, R)
                if horizontal_overlap(ra, rb):
                    step = 2
                    tries2 = 0
                    while horizontal_overlap(ra, rb) and tries2 < 80:
                        if lx + L.width // 2 <= W // 2:
                            lx -= step
                        else:
                            lx += step
                        if rx + R.width // 2 >= W // 2:
                            rx += step
                        else:
                            rx -= step
                        lx = max(margin, min(W - L.width - margin, lx))
                        rx = max(margin, min(W - R.width - margin, rx))
                        ra = rect_at(lx, yl, L)
                        rb = rect_at(rx, yr, R)
                        tries2 += 1
        except Exception as _e:
            print(f"[START_FRAME:2] layout_hint ignored: {_e}")

        # –ê–≤—Ç–æ–ø–æ–¥—Ç—è–∂–∫–∞ –±–ª–∏–∂–µ (–µ—Å–ª–∏ –º–µ–∂–¥—É –ª—é–¥—å–º–∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∑–∞–∑–æ—Ä)
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)

        def _inner_gap_px(a, b):
            return max(0, b[0] - a[2])

        min_ideal_gap = max(MIN_GAP_PX, int(IDEAL_GAP_FRAC * W))  # ~5% —à–∏—Ä–∏–Ω—ã –∫–∞–¥—Ä–∞
        gap = _inner_gap_px(ra, rb)
        if gap > min_ideal_gap:
            tries3 = 0
            while gap > min_ideal_gap and tries3 < 40:
                lx += 2
                rx -= 2
                ra = rect_at(lx, yl, L)
                rb = rect_at(rx, yr, R)
                if horizontal_overlap(ra, rb):
                    # –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∫—Ä—ã—Ç—å—Å—è
                    lx -= 2
                    rx += 2
                    break
                gap = _inner_gap_px(ra, rb)
                tries3 += 1

        # --- –ê–Ω—Ç–∏-–∫–∞—Ä–ª–∏–∫: –æ–±–µ —Ñ–∏–≥—É—Ä—ã –Ω–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å ¬´—Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–º–∏¬ª
        min_frac = _min_frac_for(framing_key, 2)

        def _visible_frac(img: Image.Image) -> float:
            bb, yb = alpha_metrics(img)
            eff_h = max(1, (yb - bb[1] + 1))
            return eff_h / H

        def _any_outside_rects():
            ra_ = rect_at(lx, yl, L)
            rb_ = rect_at(rx, yr, R)
            return any_outside(ra_) or any_outside(rb_)

        def _overlap_now():
            ra_ = rect_at(lx, yl, L)
            rb_ = rect_at(rx, yr, R)
            return horizontal_overlap(ra_, rb_)

        grow_tries = 0
        # –±—É–¥–µ–º —Ä–∞—Å—Ç–∏—Ç—å –û–ë–ï —Ñ–∏–≥—É—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Ö —Ü–µ–Ω—Ç—Ä—ã –∏ –∑–∞–∑–æ—Ä
        while (min(_visible_frac(L), _visible_frac(R)) < min_frac) and grow_tries < 12:
            new_target = min(target_h * 1.04, 0.96)
            newL = scale_to_target_effective(cuts[0], new_target)
            newR = scale_to_target_effective(cuts[1], new_target)

            # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ü–µ–Ω—Ç—Ä—ã –∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–∑–æ—Ä
            lcx = lx + L.width // 2
            rcx = rx + R.width // 2
            # –Ω–æ–≤—ã–π Y –ø–æ –ø–æ–ª—É
            new_yl = place_y_for_floor(newL)
            new_yr = place_y_for_floor(newR)
            # –≤—ã—Å—Ç–∞–≤–ª—è–µ–º –ø–æ —Ü–µ–Ω—Ç—Ä–∞–º
            new_lx = lcx - newL.width // 2
            new_rx = rcx - newR.width // 2

            margin = 20
            new_lx = max(margin, min(W - newL.width - margin, new_lx))
            new_rx = max(margin, min(W - newR.width - margin, new_rx))

            # –ø—Ä–æ–≤–µ—Ä–∏–º –≥—Ä–∞–Ω–∏—Ü—ã/–≤–µ—Ä—Ö/–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
            L_tmp, R_tmp = newL, newR
            yl_tmp, yr_tmp = new_yl, new_yr
            lx_tmp, rx_tmp = new_lx, new_rx

            ra_tmp = rect_at(lx_tmp, yl_tmp, L_tmp)
            rb_tmp = rect_at(rx_tmp, yr_tmp, R_tmp)

            # –µ—Å–ª–∏ ¬´–ø–æ–¥–ø–∏—Ä–∞–µ–º¬ª –≤–µ—Ä—Ö ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–æ—Å—Ç
            if not headroom_ok(ra_tmp) or not headroom_ok(rb_tmp):
                break
            # –µ—Å–ª–∏ –≤—ã–≤–∞–ª–∏–ª–∏—Å—å –∑–∞ –∫–∞–¥—Ä ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–æ—Å—Ç
            if _any_outside_rects():
                break
            # –µ—Å–ª–∏ –Ω–∞—á–∞–ª–∏ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—Ç—å—Å—è ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Å–ª–µ–≥–∫–∞ —Ä–∞–∑–¥–≤–∏–Ω—É—Ç—å
            if horizontal_overlap(ra_tmp, rb_tmp):
                # —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ —Ä–∞–∑–¥–≤–∏–Ω–µ–º –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–π —à–∞–≥
                step = max(4, int(0.01 * W))
                lx_tmp = max(margin, lx_tmp - step)
                rx_tmp = min(W - R_tmp.width - margin, rx_tmp + step)
                ra_tmp = rect_at(lx_tmp, yl_tmp, L_tmp)
                rb_tmp = rect_at(rx_tmp, yr_tmp, R_tmp)
                # –µ—Å–ª–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–æ—Å—Ç
                if horizontal_overlap(ra_tmp, rb_tmp):
                    break

            # –ø—Ä–∏–º–µ–Ω—è–µ–º —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
            L, R = L_tmp, R_tmp
            lx, rx = lx_tmp, rx_tmp
            yl, yr = yl_tmp, yr_tmp
            target_h = new_target
            grow_tries += 1

        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –ø–æ—Å–ª–µ —Ä–æ—Å—Ç–∞ (–Ω–∞ –≤—Å—è–∫–∏–π)
        ra = rect_at(lx, yl, L)
        rb = rect_at(rx, yr, R)
        if horizontal_overlap(ra, rb):
            center = W // 2
            if lx + L.width // 2 < center:
                lx = max(margin, lx - 8)
            if rx + R.width // 2 > center:
                rx = min(W - R.width - margin, rx + 8)

        draw_with_shadow(canvas, L, lx, yl)
        draw_with_shadow(canvas, R, rx, yr)
        # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –æ–≤–µ—Ä–ª–µ–π (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
        try:
            _draw_debug_boxes(canvas, [_rect_at(lx, yl, L), _rect_at(rx, yr, R)])
        except Exception:
            pass

    out = f"uploads/start_{base_id}.png"
    # --- –ú–ï–¢–†–ò–ö–ò –ö–û–ú–ü–û–ù–û–í–ö–ò ---
    metrics = {
        "W": W, "H": H,
        "framing": framing_key,
    }

    def _abs_rect(x, y, img):
        (bx, by, bx1, by1), yb = alpha_metrics(img)
        return [x + bx, y + by, x + bx1, y + by1], yb + y

    if len(cuts) == 1:
        rP, fy = _abs_rect(x, y, P)
        h_px = rP[3] - rP[1]
        w_px = rP[2] - rP[0]
        metrics["L"] = {
            "rect_abs": rP,
            "height_px": int(h_px),
            "width_px": int(w_px),
            "height_frac": float(h_px) / H,
            "center_x_frac": float((rP[0]+rP[2])/2) / W,
            "scale": float(P.width) / max(1.0, cuts[0].width),
            "floor_y": int(fy)
        }
    else:
        rL, fyl = _abs_rect(lx, yl, L)
        rR, fyr = _abs_rect(rx, yr, R)
        hL = rL[3]-rL[1]; wL = rL[2]-rL[0]
        hR = rR[3]-rR[1]; wR = rR[2]-rR[0]
        gap_px = max(0, rR[0] - rL[2])
        metrics["L"] = {
            "rect_abs": rL,
            "height_px": int(hL),
            "width_px": int(wL),
            "height_frac": float(hL)/H,
            "center_x_frac": float((rL[0]+rL[2])/2)/W,
            "scale": float(L.width)/max(1.0, cuts[0].width),
            "floor_y": int(fyl)
        }
        metrics["R"] = {
            "rect_abs": rR,
            "height_px": int(hR),
            "width_px": int(wR),
            "height_frac": float(hR)/H,
            "center_x_frac": float((rR[0]+rR[2])/2)/W,
            "scale": float(R.width)/max(1.0, cuts[1].width),
            "floor_y": int(fyr)
        }
        metrics["gap_px"]  = int(gap_px)
        metrics["gap_frac"]= float(gap_px)/W

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∞–π–¥–∫–∞—Ä—ã –≤—Å–µ–≥–¥–∞ –≤ debug-—Ä–µ–∂–∏–º–µ –∏–ª–∏ –ø—Ä–∏ –ø—Ä–µ–≤—å—é
    if OAI_DEBUG or PREVIEW_START_FRAME:
        _save_layout_debug(canvas, metrics, base_id)
    canvas.save(out, "PNG")
    return out

# ---------- –ü–û–°–¢-–û–ë–†–ê–ë–û–¢–ö–ê —á–µ—Ä–µ–∑ ffmpeg (wm + –º—É–∑—ã–∫–∞ + —Ç–∏—Ç—Ä + —Å–∫–ª–µ–π–∫–∞) ----------
def create_title_image(width: int, height: int, text: str, output_path: str):
    """–°–æ–∑–¥–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–∏—Ç—Ä–æ–º —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–æ–¥–±–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞"""
    title_img = Image.new("RGB", (width, height), (0, 0, 0))
    d = ImageDraw.Draw(title_img)

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥–±–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ —à—Ä–∏—Ñ—Ç–∞
    max_width = width - 40  # –û—Ç—Å—Ç—É–ø 20 –ø–∏–∫—Å–µ–ª–µ–π —Å –∫–∞–∂–¥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã
    font_size = 60  # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–æ–ª—å—à–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞

    while font_size > 12:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞
        try:
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            font = ImageFont.load_default()

        # –ò–∑–º–µ—Ä—è–µ–º —à–∏—Ä–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ —Å —Ç–µ–∫—É—â–∏–º —à—Ä–∏—Ñ—Ç–æ–º
        bbox = d.textbbox((0, 0), text, font=font)
        text_width = bbox[2] - bbox[0]

        if text_width <= max_width:
            break  # –®—Ä–∏—Ñ—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç

        font_size -= 2  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞

    # –†–∏—Å—É–µ–º —Ç–µ–∫—Å—Ç –ø–æ —Ü–µ–Ω—Ç—Ä—É
    d.text((width//2, height//2), text, fill=(255,255,255), font=font, anchor="mm")
    title_img.save(output_path)
    return output_path

def postprocess_concat_ffmpeg(video_paths: List[str], music_path: str|None, title_text: str, save_as: str, bg_overlay_file: str|None = None) -> str:
    """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ ffmpeg –≤–º–µ—Å—Ç–æ MoviePy"""
    import tempfile

    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    temp_dir = "renders/temp"
    os.makedirs(temp_dir, exist_ok=True)

    # 1. –°–æ–∑–¥–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–∏—Ç—Ä –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    title_img_path = f"{temp_dir}/title.png"
    create_title_image(720, 1280, title_text, title_img_path)

    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–∏—Ç—Ä –≤ 2-—Å–µ–∫—É–Ω–¥–Ω–æ–µ –≤–∏–¥–µ–æ
    title_video_path = f"{temp_dir}/title_video.mp4"
    subprocess.run([
        "ffmpeg", "-y", "-loop", "1", "-i", title_img_path, 
        "-c:v", "libx264", "-t", "2", "-pix_fmt", "yuv420p", "-r", "24",
        title_video_path
    ], check=True, capture_output=True)

    # 3. –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å–æ —Å–ø–∏—Å–∫–æ–º –≤–∏–¥–µ–æ –¥–ª—è —Å–∫–ª–µ–π–∫–∏
    concat_list_path = f"{temp_dir}/concat_list.txt"
    with open(concat_list_path, "w") as f:
        for video_path in video_paths:
            f.write(f"file '{os.path.abspath(video_path)}'\n")
        f.write(f"file '{os.path.abspath(title_video_path)}'\n")

    # 4. –°–∫–ª–µ–∏–≤–∞–µ–º –≤—Å–µ –≤–∏–¥–µ–æ (–≤–∫–ª—é—á–∞—è —Ç–∏—Ç—Ä)
    concat_video_path = f"{temp_dir}/concat_video.mp4"
    subprocess.run([
        "ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", concat_list_path,
        "-c", "copy", concat_video_path
    ], check=True, capture_output=True)

    # 4.5. –û—á–µ–Ω—å –¥–µ–ª–∏–∫–∞—Ç–Ω–∞—è –∞–Ω–∏–º–∞—Ü–∏—è —Ñ–æ–Ω–∞ —Å–≤–µ—Ä—Ö—É (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω bg_overlay_file)
    bg_anim_video_path = concat_video_path
    if bg_overlay_file and os.path.isfile(bg_overlay_file):
        try:
            # –°–æ–∑–¥–∞—ë–º –ø–ª—ã–≤—É—â—É—é –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—É—é ¬´—Ç—É–º–∞–Ω–Ω–æ—Å—Ç—å¬ª –∏–∑ —Ç–æ–≥–æ –∂–µ —Ñ–æ–Ω–∞:
            # - –º–∞—Å—à—Ç–∞–± –¥–æ 720x1280
            # - —Å–∏–ª—å–Ω—ã–π blur
            # - –∞–ª—å—Ñ–∞ ~0.08
            # - –º–µ–¥–ª–µ–Ω–Ω—ã–π —Å–¥–≤–∏–≥ –ø–æ X (2 px/—Å–µ–∫)
            bg_anim_video_path = f"{temp_dir}/with_bg_anim.mp4"
            subprocess.run([
                "ffmpeg", "-y",
                "-i", concat_video_path,
                "-loop", "1", "-i", bg_overlay_file,
                "-filter_complex",
                "[1:v]scale=720:1280,boxblur=25:1,format=rgba,colorchannelmixer=aa=0.08,setsar=1[ov];"
                "[0:v][ov]overlay=x='t*2':y=0:shortest=1,format=yuv420p[v]",
                "-map", "[v]", "-map", "0:a?", "-c:a", "copy",
                bg_anim_video_path
            ], check=True, capture_output=True)
        except Exception as e:
            print(f"BG overlay skipped: {e}")
    else:
        print("BG overlay disabled (no file)")

    # 5. –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫ –µ—Å–ª–∏ –µ—Å—Ç—å
    wm_video_path = bg_anim_video_path
    if os.path.isfile(WATERMARK_PATH):
        wm_video_path = f"{temp_dir}/with_watermark.mp4"
        subprocess.run([
            "ffmpeg", "-y", "-i", bg_anim_video_path, "-i", WATERMARK_PATH,
            "-filter_complex", "[1:v]scale=120:-1[wm];[0:v][wm]overlay=W-w-24:24",
            "-c:a", "copy", wm_video_path
        ], check=True, capture_output=True)

    # 6. –î–æ–±–∞–≤–ª—è–µ–º –º—É–∑—ã–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
    final_video_path = wm_video_path
    if music_path and os.path.isfile(music_path):
        final_video_path = save_as
        # –ü—Ä–æ—Å—Ç–∞—è –∑–∞–º–µ–Ω–∞ –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏ –º—É–∑—ã–∫–æ–π (–∑–∞—Ü–∏–∫–ª–µ–Ω–Ω–æ–π)
        subprocess.run([
            "ffmpeg", "-y", "-stream_loop", "-1", "-i", music_path, "-i", wm_video_path,
            "-map", "1:v", "-map", "0:a", "-c:v", "copy", "-c:a", "aac", 
            "-shortest", "-af", "volume=0.6", final_video_path
        ], check=True, capture_output=True)
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç –º—É–∑—ã–∫–∏, –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ
        subprocess.run(["cp", wm_video_path, save_as], check=True)

    return save_as

def cleanup_dir_keep_last_n(dir_path: str, keep_n: int = 10, extensions: tuple[str, ...] = ()):
    try:
        items = []
        for name in os.listdir(dir_path):
            p = os.path.join(dir_path, name)
            if os.path.isfile(p):
                if not extensions or name.lower().endswith(extensions):
                    items.append((p, os.path.getmtime(p)))
        items.sort(key=lambda x: x[1], reverse=True)
        for p, _ in items[keep_n:]:
            try:
                os.remove(p)
            except Exception:
                pass
    except FileNotFoundError:
        pass

def cleanup_artifacts(keep_last: int = 10):
    # –ü–æ–ª–Ω–æ—Å—Ç—å—é —á–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É —Ä–µ–Ω–¥–µ—Ä–æ–≤ (–∫—Ä–æ–º–µ —Ä–µ–∂–∏–º–∞ –æ—Ç–ª–∞–¥–∫–∏)
    if not OAI_DEBUG:
        shutil.rmtree("renders/temp", ignore_errors=True)
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ –∏ —Ñ–∏–Ω–∞–ª–æ–≤
    cleanup_dir_keep_last_n("uploads", keep_n=keep_last, extensions=(".jpg", ".jpeg", ".png", ".webp"))
    cleanup_dir_keep_last_n("renders", keep_n=keep_last, extensions=(".mp4", ".mov", ".mkv", ".webm"))

def _download_tg_photo(file_id: str, uid: int) -> str:
    fi = bot.get_file(file_id)
    content = requests.get(f"https://api.telegram.org/file/bot{TG_TOKEN}/{fi.file_path}", timeout=120).content
    pth = f"uploads/{uid}_{int(time.time())}_{uuid.uuid4().hex}.jpg"
    with open(pth, "wb") as f:
        f.write(content)
    return pth

# ---------- –•–≠–ù–î–õ–ï–†–´ ----------
@bot.message_handler(commands=["start","reset"])
def start_cmd(m: telebot.types.Message):
    uid = m.from_user.id
    # –°–±—Ä–æ—Å —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –ø–æ–∫–∞–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
    users[uid] = new_state()
    show_main_menu(uid, '–í—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –∫ —Å–æ–∑–¥–∞–Ω–∏—é –≤–∏–¥–µ–æ, –Ω–∞–∂–∞–≤ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª.')

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é (–∫–Ω–æ–ø–∫–∞)
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_MAIN)
def on_menu_main(m: telebot.types.Message):
    uid = m.from_user.id
    # –ù–µ —Ç—Ä–æ–≥–∞–µ–º —Ç–µ–∫—É—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é
    show_main_menu(uid)

# –ó–∞–ø—É—Å–∫ –º–∞—Å—Ç–µ—Ä–∞ (–∫–Ω–æ–ø–∫–∞ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª)
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_START)
def on_menu_start_wizard(m: telebot.types.Message):
    uid = m.from_user.id
    users[uid] = new_state()
    bot.send_message(
        uid,
        "–®–∞–≥ 1/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞</b>.",
        reply_markup=kb_formats()
    )

# –°—Ç–æ–∏–º–æ—Å—Ç—å
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_PRICE)
def on_menu_price(m: telebot.types.Message):
    uid = m.from_user.id
    price_text = (
        "<b>–°—Ç–æ–∏–º–æ—Å—Ç—å</b>\n\n"
        "‚Ä¢ 5 —Å–µ–∫ ‚Äî <b>–±–µ—Å–ø–ª–∞—Ç–Ω–æ</b>\n"
        "‚Ä¢ –õ—é–±–æ–π –¥—Ä—É–≥–æ–π —Å—é–∂–µ—Ç (10—Å) ‚Äî <b>100</b>\n"
        "‚Ä¢ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—é–∂–µ—Ç–æ–≤ ‚Äî —Å—É–º–º–∞ —Ü–µ–Ω –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å—é–∂–µ—Ç–æ–≤\n"
        "‚Ä¢ –ú—É–∑—ã–∫–∞ ‚Äî <b>50</b>\n"
        "‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–∏—Ç—Ä—ã ‚Äî <b>50</b>\n"
        "‚Ä¢ –í—Ç–æ—Ä–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è (–¥—Ä—É–≥–æ–π —Å–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏) ‚Äî <b>+50%</b> –∫ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏\n"
    )
    bot.send_message(uid, price_text, reply_markup=kb_main_menu())

# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_GUIDE)
def on_menu_guide(m: telebot.types.Message):
    uid = m.from_user.id
    guide = (
        "<b>–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ</b>\n"
        "1) –ù–∞–∂–º–∏—Ç–µ ¬´–°–¥–µ–ª–∞—Ç—å –≤–∏–¥–µ–æ¬ª.\n"
        "2) –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞.\n"
        "3) –í—ã–±–µ—Ä–∏—Ç–µ —Å—é–∂–µ—Ç—ã (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ) ‚Üí ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.\n"
        "4) –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ–Ω.\n"
        "5) –í—ã–±–µ—Ä–∏—Ç–µ –º—É–∑—ã–∫—É (–∏–ª–∏ ¬´–ë–µ–∑ –º—É–∑—ã–∫–∏¬ª).\n"
        "6) –ü—Ä–∏—à–ª–∏—Ç–µ 1‚Äì2 —Ñ–æ—Ç–æ –∞–Ω—Ñ–∞—Å (–∫–∞–∂–¥–æ–≥–æ ‚Äî –æ—Ç–¥–µ–ª—å–Ω–æ).\n"
        "7) –î–æ–∂–¥–∏—Ç–µ—Å—å —Ä–µ–Ω–¥–µ—Ä–∞ ‚Äî –∏—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ –ø—Ä–∏–¥—ë—Ç —Å—é–¥–∞.\n\n"
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: —á–µ–º –ª—É—á—à–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç —Å —Ñ–æ–Ω–æ–º –Ω–∞ —Ñ–æ—Ç–æ ‚Äî —Ç–µ–º —á–∏—â–µ –≤—ã—Ä–µ–∑–∞–Ω–∏–µ."
    )
    bot.send_message(uid, guide, reply_markup=kb_main_menu())

# –ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_DEMO)
def on_menu_demo(m: telebot.types.Message):
    uid = m.from_user.id
    demo_dir = "assets/examples"
    paths = [
        os.path.join(demo_dir, "example1.mp4"),
        os.path.join(demo_dir, "example2.mp4"),
        os.path.join(demo_dir, "example3.mp4"),
    ]
    sent = False
    for p in paths:
        if os.path.isfile(p):
            with open(p, "rb") as f:
                bot.send_video(uid, f)
            sent = True
    if not sent:
        bot.send_message(uid, "–ó–∞–≥—Ä—É–∑–∏—Ç–µ 3 —Ñ–∞–π–ª–∞ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ –ø–∞–ø–∫—É <code>assets/examples</code> –ø–æ–¥ –∏–º–µ–Ω–∞–º–∏ example1.mp4, example2.mp4, example3.mp4", reply_markup=kb_main_menu())

# –¢–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∞
@bot.message_handler(func=lambda msg: msg.text == BTN_MENU_SUPPORT)
def on_menu_support(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["support"] = True
    bot.send_message(uid, "–ù–∞–ø–∏—à–∏—Ç–µ –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ú—ã —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏. (–î–ª—è –≤—ã—Ö–æ–¥–∞ –Ω–∞–∂–º–∏—Ç–µ ¬´–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é¬ª).", reply_markup=kb_main_menu())

@bot.message_handler(func=lambda msg: msg.text=="üîÅ –°–±—Ä–æ—Å–∏—Ç—å –≤—ã–±–æ—Ä —Å—é–∂–µ—Ç–æ–≤")
def reset_scenes(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["scenes"] = []
    bot.send_message(uid, "–°—é–∂–µ—Ç—ã –æ—á–∏—â–µ–Ω—ã. –í—ã–±–µ—Ä–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.", reply_markup=kb_scenes(st.get("format")))

@bot.message_handler(func=lambda msg: msg.text=="‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ")
def after_scenes(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    if not st["scenes"]:
        bot.send_message(uid, "–ü–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ. –û—Ç–º–µ—Ç—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Å—é–∂–µ—Ç.",
                         reply_markup=kb_scenes(st.get("format")))
        return
    bot.send_message(uid, "–®–∞–≥ 3/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Ñ–æ–Ω</b>.", reply_markup=kb_backgrounds())

@bot.message_handler(func=lambda msg: msg.text in SCENES.keys())
def choose_scene(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞—Ç –µ—â—ë –Ω–µ –≤—ã–±—Ä–∞–Ω (–Ω–∞ –≤—Å—è–∫–∏–π) ‚Äî –ø—Ä–æ—Å–∏–º –≤—ã–±—Ä–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç
    if not st.get("format"):
        bot.send_message(uid, "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∫–∞–¥—Ä–∞ (–®–∞–≥ 1/5).", reply_markup=kb_formats())
        return

    allowed = set(available_scene_keys(st["format"]))
    if m.text not in allowed:
        # –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è ¬´–ª–µ—Å—Ç–Ω–∏—Ü—ã¬ª
        if SCENES.get(m.text, {}).get("kind") == "stairs":
            bot.send_message(uid, "–°—é–∂–µ—Ç ¬´–£—Ö–æ–¥–∏—Ç –≤ –Ω–µ–±–µ—Å–∞¬ª –¥–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∞ ¬´üßç –í —Ä–æ—Å—Ç¬ª. "
                                  "–ü–æ–º–µ–Ω—è–π—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π —Å—é–∂–µ—Ç.",
                             reply_markup=kb_scenes(st["format"]))
        else:
            bot.send_message(uid, "–≠—Ç–æ—Ç —Å—é–∂–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞.", reply_markup=kb_scenes(st["format"]))
        return

    if m.text not in st["scenes"]:
        st["scenes"].append(m.text)

    picked = " ¬∑ ".join(st["scenes"])
    bot.send_message(uid, f"–í—ã–±—Ä–∞–Ω–æ: {picked}\n–î–æ–±–∞–≤—å—Ç–µ –µ—â—ë –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.",
                     reply_markup=kb_scenes(st["format"]))

@bot.message_handler(func=lambda msg: msg.text in FORMATS.keys())
def choose_format(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["format"] = m.text
    st["scenes"] = []  # –æ–±–Ω—É–ª—è–µ–º –≤—ã–±–æ—Ä —Å—Ü–µ–Ω –ø–æ–¥ –Ω–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
    bot.send_message(
        uid,
        "–®–∞–≥ 2/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>—Å—é–∂–µ—Ç—ã</b> (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ). –ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–∂–º–∏—Ç–µ ¬´‚úÖ –í—ã–±—Ä–∞–Ω–æ, –¥–∞–ª—å—à–µ¬ª.",
        reply_markup=kb_scenes(st["format"])
    )

@bot.message_handler(func=lambda msg: msg.text in BACKGROUNDS.keys())
def choose_background(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["bg"] = m.text
    bot.send_message(uid, "–®–∞–≥ 4/5. –í—ã–±–µ—Ä–∏—Ç–µ <b>–º—É–∑—ã–∫—É</b> (–∏–ª–∏ ¬´–ë–µ–∑ –º—É–∑—ã–∫–∏¬ª).", reply_markup=kb_music())

@bot.message_handler(func=lambda msg: msg.text in MUSIC.keys() or msg.text=="üîá –ë–µ–∑ –º—É–∑—ã–∫–∏")
def choose_music(m):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())
    st["music"] = None if m.text=="üîá –ë–µ–∑ –º—É–∑—ã–∫–∏" else m.text
    # –°–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ –Ω–∞–¥–æ?
    if not st["scenes"]:
        bot.send_message(uid, "–û—à–∏–±–∫–∞: –Ω–µ –≤—ã–±—Ä–∞–Ω—ã —Å—é–∂–µ—Ç—ã. –ù–∞—á–Ω–∏—Ç–µ —Å /start")
        return
    need_people = max(SCENES[k]["people"] for k in st["scenes"])
    bot.send_message(uid, f"–®–∞–≥ 5/5. –ü—Ä–∏—à–ª–∏—Ç–µ {need_people} —Ñ–æ—Ç–æ (–∞–Ω—Ñ–∞—Å).")

@bot.message_handler(func=lambda msg: msg.text == BTN_GO_HOME)
def go_home(m: telebot.types.Message):
    uid = m.from_user.id
    # –ù–µ –ª–æ–º–∞–µ–º —Ç–µ–∫—É—â—É—é –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é
    show_main_menu(uid)

@bot.message_handler(content_types=["photo"])
def on_photo(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ—à–ª–∏ —à–∞–≥–∏ –¥–æ —Ñ–æ—Ç–æ
    if not (st["scenes"] and st["format"] and st["bg"] and (st["music"] is not None or st["music"] == None)):
        bot.send_message(uid, "–°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–π–¥–∏—Ç–µ —à–∞–≥–∏: –§–æ—Ä–º–∞—Ç ‚Üí –°—é–∂–µ—Ç(—ã) ‚Üí –§–æ–Ω ‚Üí –ú—É–∑—ã–∫–∞.")
        return

    need_people = max(SCENES[k]["people"] for k in st["scenes"])

    # 1) –ï—Å–ª–∏ —Å—Ü–µ–Ω–∞ —Å 1 —á–µ–ª–æ–≤–µ–∫–æ–º –∏ —Ñ–æ—Ç–æ —É–∂–µ –µ—Å—Ç—å ‚Äî –≤–µ–∂–ª–∏–≤–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
    if need_people == 1 and len(st["photos"]) >= 1:
        bot.send_message(uid, "–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Å—é–∂–µ—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–¥–Ω–æ–≥–æ —Ñ–æ—Ç–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É—é –ø–µ—Ä–≤–æ–µ.")
        return

    # 2) –°–∫–∞—á–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–æ—Ç–∫—É
    file_id = m.photo[-1].file_id
    saved_path = _download_tg_photo(file_id, uid)

    # --- –ú—è–≥–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–æ—Ç–æ ---
    ok_photo, warns = validate_photo(saved_path)
    if warns:
        bot.send_message(uid, "‚ö†Ô∏è –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ —Ñ–æ—Ç–æ:\n" + "\n".join(f"‚Ä¢ {w}" for w in warns))
    if not ok_photo:
        bot.send_message(uid, "–§–æ—Ç–æ –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –ú–æ–∂–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Ö—É–∂–µ. "
                              "–ï—Å–ª–∏ –µ—Å—Ç—å –¥—Ä—É–≥–æ–µ —Ñ–æ—Ç–æ ‚Äî –ø—Ä–∏—à–ª–∏—Ç–µ –µ—â—ë –æ–¥–Ω–æ. –ü—Ä–æ–¥–æ–ª–∂–∞—é —Å —ç—Ç–∏–º —Ñ–æ—Ç–æ.")

    # 3) –ï—Å–ª–∏ —ç—Ç–æ –∞–ª—å–±–æ–º (–Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ —Å –æ–¥–Ω–∏–º media_group_id)
    if m.media_group_id:
        rec = PENDING_ALBUMS.setdefault(m.media_group_id, {"uid": uid, "need": need_people, "paths": []})
        # –ï—Å–ª–∏ –∞–ª—å–±–æ–º –ø—Ä–∏—à—ë–ª –∫ –¥—Ä—É–≥–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é/–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ‚Äî –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º –ø–æ–¥ —Ç–µ–∫—É—â–µ–≥–æ
        rec["uid"] = uid
        rec["need"] = need_people
        rec["paths"].append(saved_path)

        # –ö–æ–≥–¥–∞ —Å–æ–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å—é–∂–µ—Ç–∞ ‚Äî –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ —Å—Ç–µ–π—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        if len(rec["paths"]) >= need_people:
            # –ë–µ—Ä—ë–º —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            st["photos"].extend(rec["paths"][:need_people])
            # –ß–∏—Å—Ç–∏–º –±—É—Ñ–µ—Ä –∞–ª—å–±–æ–º–∞
            PENDING_ALBUMS.pop(m.media_group_id, None)

            bot.send_message(uid, "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é‚Ä¶")
            try:
                run_all_and_send(uid, st)
            except Exception as e:
                print("GEN ERR:", e)
                bot.send_message(uid, f"–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫: {e}")
            finally:
                users[uid] = new_state()
                show_main_menu(uid)
        # –ï—Å–ª–∏ –ø–æ–∫–∞ —Ñ–æ—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –≥–æ–≤–æ—Ä–∏–º (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ ¬´–û—Å—Ç–∞–ª–æ—Å—å 1¬ª –Ω–∞ –ø–µ—Ä–≤–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ –∞–ª—å–±–æ–º–∞)
        return

    # 4) –û–±—ã—á–Ω–æ–µ –æ–¥–∏–Ω–æ—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–æ—Ç–æ (–Ω–µ –∞–ª—å–±–æ–º)
    st["photos"].append(saved_path)

    if len(st["photos"]) < need_people:
        left = need_people - len(st["photos"])
        bot.send_message(uid, f"–§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ ‚úÖ  –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏—Å–ª–∞—Ç—å –µ—â—ë {left}.")
        return

    # –°–æ–±—Ä–∞–ª–∏ –≤—Å—ë ‚Äî –≥–µ–Ω–µ—Ä–∏–º
    bot.send_message(uid, "–ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é‚Ä¶")
    try:
        run_all_and_send(uid, st)
    except Exception as e:
        print("GEN ERR:", e)
        bot.send_message(uid, f"–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫: {e}")
    finally:
        users[uid] = new_state()
        show_main_menu(uid)

@bot.message_handler(commands=["cfg"])
def cmd_cfg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    txt = (
        f"<b>Config</b>\n"
        f"ASSISTANT_GATE_ENABLED: {ASSISTANT_GATE_ENABLED}\n"
        f"PREVIEW_START_FRAME: {PREVIEW_START_FRAME}\n"
        f"DEBUG_TO_ADMIN: {DEBUG_TO_ADMIN}\n"
        f"RUNWAY_SEND_JPEG: {RUNWAY_SEND_JPEG}\n"
    )
    bot.reply_to(m, txt)

@bot.message_handler(commands=["gate_on", "gate_off"])
def cmd_gate(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global ASSISTANT_GATE_ENABLED
    ASSISTANT_GATE_ENABLED = (m.text == "/gate_on")
    bot.reply_to(m, f"ASSISTANT_GATE_ENABLED = {ASSISTANT_GATE_ENABLED}")

@bot.message_handler(commands=["preview_on", "preview_off"])
def cmd_preview(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global PREVIEW_START_FRAME
    PREVIEW_START_FRAME = (m.text == "/preview_on")
    bot.reply_to(m, f"PREVIEW_START_FRAME = {PREVIEW_START_FRAME}")

@bot.message_handler(commands=["admdbg_on", "admdbg_off"])
def cmd_admdbg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global DEBUG_TO_ADMIN
    DEBUG_TO_ADMIN = (m.text == "/admdbg_on")
    bot.reply_to(m, f"DEBUG_TO_ADMIN = {DEBUG_TO_ADMIN}")

@bot.message_handler(commands=["jpeg_on", "jpeg_off"])
def cmd_jpeg(m: telebot.types.Message):
    uid = m.from_user.id
    if not _is_admin(uid):
        return bot.reply_to(m, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
    global RUNWAY_SEND_JPEG
    RUNWAY_SEND_JPEG = (m.text == "/jpeg_on")
    bot.reply_to(m, f"RUNWAY_SEND_JPEG = {RUNWAY_SEND_JPEG}")

# ---------- –ü–ê–ô–ü–õ–ê–ô–ù ----------
def run_all_and_send(uid: int, st: dict):
    framing_text = FORMATS[st["format"]]
    bg_prompt    = BG_TEXT[st["bg"]]          # —Ç–µ–∫—Å—Ç-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –ª—ë–≥–∫–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏
    music_path   = MUSIC.get(st["music"]) if st["music"] else None
    bg_file      = BG_FILES[st["bg"]]         # —Å–∞–º ¬´–ø–ª–µ–π—Ç¬ª (–∫–∞—Ä—Ç–∏–Ω–∫–∞ —Ñ–æ–Ω–∞)

    out_videos = []
    for scene_key in st["scenes"]:
        scene = SCENES[scene_key]
        # 1) —Å—Ç—Ä–æ–∏–º –ß–ï–†–ù–û–í–û–ô —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä –±–µ–∑ layout-–¥–æ–±–∞–≤–æ–∫ ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        start_frame_draft = make_start_frame(st["photos"], st["format"], bg_file, layout=None)
        base_prompt = build_prompt(scene["kind"], framing_text, bg_prompt, scene["duration"])

        # 2) –ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–º—è–≥–∫–∞—è –º–æ–¥–µ—Ä–∞—Ü–∏—è + –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∫ –ø—Ä–æ–º–ø—Ç—É)
        gate = None
        try:
            gate = oai_gate_check(start_frame_draft, base_prompt, {
                "format": st["format"], "scene": scene_key, "background": st["bg"]
            }, timeout_sec=180)
        except Exception as _e:
            print(f"[OAI] gate error: {_e}")

        # 3) –ø–æ–ª–∏—Ç–∏–∫–∞ –ø–æ –Ω–æ–≤–æ–π —Å—Ö–µ–º–µ status/user_notes/backend_fixes
        if gate is None:
            prompt = compact_prompt(base_prompt)
        else:
            gate = _normalize_gate(gate) or {
                "status": "accept", 
                "user_notes": [], 
                "backend_fixes": {
                    "recompose": False, "issues": [], 
                    "target_height_frac": [0.77, 0.77], 
                    "target_centers": [0.35, 0.65], 
                    "gap_frac": 0.05, 
                    "align_feet": {"enabled": True, "floor_y": 1180}
                }, 
                "runway_prompt_additions": ""
            }

            status = gate.get("status", "accept")

            if status == "reject_user_photo":
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–º–µ—á–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ–æ—Ç–æ
                user_notes = gate.get("user_notes", [])
                if user_notes:
                    note_messages = {
                        "missing_head": "–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≥–æ–ª–æ–≤–∞",
                        "missing_hands": "–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä—É–∫–∏", 
                        "prohibited_content": "–∑–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ",
                        "low_resolution": "–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ",
                        "too_dark": "—Å–ª–∏—à–∫–æ–º —Ç–µ–º–Ω–æ–µ —Ñ–æ—Ç–æ",
                        "blurred": "—Ä–∞–∑–º—ã—Ç–æ–µ —Ñ–æ—Ç–æ",
                        "profile_view": "—Å–∏–ª—É—ç—Ç –±–æ–∫–æ–º –≤–º–µ—Å—Ç–æ –∞–Ω—Ñ–∞—Å",
                        "sitting_pose": "—Å–∏–¥—è—â–∞—è –ø–æ–∑–∞", 
                        "occluded_face": "–∑–∞–∫—Ä—ã—Ç–æ–µ –ª–∏—Ü–æ",
                        "cutout_artifacts": "–∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –≤—ã—Ä–µ–∑–∫–∏"
                    }
                    messages = [note_messages.get(note, note) for note in user_notes[:3]]
                    bot.send_message(uid, f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã —Å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏: {'; '.join(messages)}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ç–æ.")
                else:
                    bot.send_message(uid, "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∏–∑ —ç—Ç–∏—Ö —Ñ–æ—Ç–æ —Å–ª–æ–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Ü–µ–Ω—É.")
                continue

            # –î–ª—è accept –∏ accept_with_backend_fixes - –ù–ï –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–º–µ—á–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é

            if status == "accept_with_backend_fixes":
                # –ü—Ä–∏–º–µ–Ω—è–µ–º backend_fixes –¥–ª—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –∫–∞–¥—Ä–∞
                backend_fixes = gate.get("backend_fixes", {})
                if backend_fixes.get("recompose", False):
                    print(f"[Assistant] Backend fixes requested: {backend_fixes.get('issues', [])}")
                    # TODO: –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ª–æ–≥–∏–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
                    # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã –ø–æ–∑–∂–µ

            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç —Å –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è–º–∏ –æ—Ç Assistant'–∞
            additions = gate.get("runway_prompt_additions", "").strip()
            prompt = compact_prompt(base_prompt + ("; " + additions if additions else ""))

        # 4) —Å—Ç—Ä–æ–∏–º –ß–ò–°–¢–û–í–û–ô —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä —Å —É—á—ë—Ç–æ–º layout_feedback (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
        # –ë–∞–∑–æ–≤—ã–π —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º)
        start_frame = make_start_frame(st["photos"], st["format"], bg_file)
        # –ê–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–≤—å—é (–µ—Å–ª–∏ –µ—Å—Ç—å)
        try:
            base_id = os.path.splitext(os.path.basename(start_frame))[0].replace("start_", "", 1)
            annot_path  = f"renders/temp/annot_{base_id}.png"
            metrics_json= f"renders/temp/metrics_{base_id}.json"
            if PREVIEW_START_FRAME and os.path.isfile(annot_path):
                cap = "–°—Ç–∞—Ä—Ç-–∫–∞–¥—Ä (–∞–Ω–Ω–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–≤—å—é)"
                _send_debug_preview(uid, annot_path, cap)
            if OAI_DEBUG and os.path.isfile(metrics_json):
                with open(metrics_json, "r", encoding="utf-8") as f:
                    print("[DEBUG] metrics json:\n" + f.read()[:2000])
        except Exception as _e:
            print(f"[DEBUG] preview/metrics error: {_e}")
        start_data, start_frame_used = ensure_runway_datauri_under_limit(start_frame)

        # 5) –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ (—Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º JPEG –ø—Ä–∏ –≤–∫–ª—é—á—ë–Ω–Ω–æ–º —Ñ–ª–∞–≥–µ)
        send_path = ensure_jpeg_copy(start_frame) if RUNWAY_SEND_JPEG else start_frame
        try:
            fs = os.path.getsize(send_path)
            print(f"[Runway] start_frame path={send_path} size={fs} bytes (jpeg={RUNWAY_SEND_JPEG})")
        except Exception:
            pass

        start_data = encode_image_datauri(send_path)
        if not start_data or len(start_data) < 64:
            print("[Runway] data URI is empty/too short")
            raise RuntimeError("Start frame data URI is empty")
        if len(start_data) > 5_000_000:
            print(f"[Runway warn] data URI length {len(start_data)} > 5MB; try lower JPEG quality or smaller frame.")

        # 6) –æ—Ç–ª–∞–¥–∫–∞
        try:
            os.makedirs("renders/temp", exist_ok=True)
            dbg = {
                "scene": scene_key,
                "format": st["format"],
                "background": st["bg"],
                "start_frame": start_frame_used,
                "start_frame_draft": start_frame_draft,
                "start_frame_final": start_frame,
                "gate": gate,
                "base_prompt": base_prompt,
                "final_prompt": prompt
            }
            dbg["layout_hint_used"] = layout_hint if use_hint else None
            dbg["scene_start_frame"] = scene_frame
            dbg_path = os.path.join("renders/temp", f"runway_dbg_{uid}_{uuid.uuid4().hex}.json")
            with open(dbg_path, "w", encoding="utf-8") as f:
                json.dump(dbg, f, ensure_ascii=False, indent=2)
            print(f"[RUNWAY DBG] saved {dbg_path}\n[RUNWAY DBG] final_prompt_len={len(prompt)}")
        except Exception as _e:
            print(f"[RUNWAY DBG] save error: {_e}")

        base_prompt = build_prompt(scene["kind"], framing_text, bg_prompt, scene["duration"])

        # --- –≤—ã–∑–æ–≤ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –ø—Ä–æ–≤–µ—Ä–∫–∏) ---
        gate = None
        try:
            gate = oai_gate_check(base_start_frame, base_prompt, {
                "format": st["format"], "scene": scene_key, "background": st["bg"]
            }, timeout_sec=180)  # –º–æ–∂–Ω–æ 180, —á—Ç–æ–±—ã –º–µ–Ω—å—à–µ —Ç–∞–π–º–∞—É—Ç–æ–≤
        except Exception as _e:
            print(f"[OAI] gate error: {_e}")

        # –ø–æ–ª–∏—Ç–∏–∫–∞ –ø–æ verdict (ok/warn/block) —Å –∞–≤—Ç–æ-–ø–æ–Ω–∏–∂–µ–Ω–∏–µ–º "block ‚Üí warn" –¥–ª—è –º–µ–ª–æ—á–µ–π
        if gate is None:
            prompt = compact_prompt(base_prompt)
        else:
            verdict = gate.get("verdict") or ("ok" if gate.get("ok", True) else "block")
            reasons = gate.get("reasons") or []
            additions = gate.get("prompt_additions") or ""
            # –µ—Å–ª–∏ –±–ª–æ–∫ —Ç–æ–ª—å–∫–æ –∏–∑-–∑–∞ ¬´–º–µ–ª–æ—á–µ–π¬ª ‚Äî –ø–æ–Ω–∏–∂–∞–µ–º –¥–æ warn
            if verdict == "block" and _is_minor_only(reasons):
                verdict = "warn"

            if verdict == "block":
                user_msg = gate.get("user_msg") or "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∏–∑ —ç—Ç–∏—Ö —Ñ–æ—Ç–æ —Å–ª–æ–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é —Å—Ü–µ–Ω—É."
                bot.send_message(uid, user_msg)
                # –ª–æ–≥–∏—Ä—É–µ–º –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                _log_fail(uid, "assistant_block", {"scene": scene_key, "reasons": reasons}, gate)
                continue

            if verdict == "warn":
                if reasons:
                    bot.send_message(uid, "‚ö†Ô∏è –ó–∞–º–µ—á–∞–Ω–∏–µ: " + "; ".join(reasons[:3]))

            prompt = compact_prompt(base_prompt + ("; " + additions if additions else ""))

        # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤—Å—ë –≤ debug-—Ñ–∞–π–ª
        try:
            os.makedirs("renders/temp", exist_ok=True)
            dbg = {
                "scene": scene_key,
                "format": st["format"],
                "background": st["bg"],
                "base_start_frame": base_start_frame,
                "gate": gate,
                "base_prompt": base_prompt,
                "final_prompt": prompt
            }
            dbg_path = os.path.join("renders/temp", f"runway_dbg_{uid}_{uuid.uuid4().hex}.json")
            with open(dbg_path, "w", encoding="utf-8") as f:
                json.dump(dbg, f, ensure_ascii=False, indent=2)
            print(f"[RUNWAY DBG] saved {dbg_path}\n[RUNWAY DBG] final_prompt_len={len(prompt)}")
        except Exception as _e:
            print(f"[RUNWAY DBG] save error: {_e}")

        try:
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ü–µ–Ω–Ω—ã–π —Å—Ç–∞—Ä—Ç-–∫–∞–¥—Ä —Å –≤–æ–∑–º–æ–∂–Ω—ã–º —É—á—ë—Ç–æ–º layout_feedback
            layout_hint = (gate or {}).get("layout_feedback") if gate else None
            use_hint = bool(layout_hint and any(int(layout_hint.get(k, 0)) != 0 
                       for k in ("shift_left_px", "shift_right_px", "scale_left_pct", "scale_right_pct")))

            scene_frame = make_start_frame(st["photos"], st["format"], bg_file, layout_hint if use_hint else None)

            # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ (JPEG –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –ß.10
            send_path = ensure_jpeg_copy(scene_frame) if RUNWAY_SEND_JPEG else scene_frame
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–µ–≤—å—é –∫–∞–¥—Ä–∞ –∏ –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–µ–¥ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –≤ data:URI)
            try:
                _send_debug_preview(uid, scene_key, send_path, prompt, gate)
            except Exception as _e:
                print(f"[DBG] preview send err: {_e}")
            try:
                fs = os.path.getsize(send_path)
                print(f"[Runway] scene_frame path={send_path} size={fs} bytes (jpeg={RUNWAY_SEND_JPEG})")
            except Exception:
                pass

            scene_data = encode_image_datauri(send_path)
            if not scene_data or len(scene_data) < 64:
                raise RuntimeError("Scene start frame data URI is empty")
            if len(scene_data) > 5_000_000:
                print(f"[Runway warn] scene data URI length {len(scene_data)} > 5MB; try lower JPEG quality.")
            additions = additions if 'additions' in locals() else ""
            # –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ + —Ñ–æ–ª–±—ç–∫ –Ω–∞ 5—Å –ø—Ä–∏ 4xx –æ—Ç Runway
            try:
                start_resp = runway_start(scene_data, prompt, scene["duration"])
            except RuntimeError as e:
                msg = str(e)
                if "400/4xx" in msg and int(scene["duration"]) > 5:
                    bot.send_message(uid, f"‚ö†Ô∏è Runway –æ—Ç–∫–∞–∑–∞–ª –≤ {scene['duration']} —Å –¥–ª—è ¬´{scene_key}¬ª. –ü—Ä–æ–±—É—é 5 —Å.")
                    base_prompt_short = build_prompt(scene["kind"], framing_text, bg_prompt, 5)
                    prompt_short = compact_prompt(base_prompt_short + ("; " + additions if additions else ""))
                    try:
                        start_resp = runway_start(scene_data, prompt_short, 5)
                        # —á—Ç–æ–±—ã –≤ –¥–µ–±–∞–≥–µ –∏ –ª–æ–≥–∞—Ö –≤–∏–¥–µ—Ç—å —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç/–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                        prompt = prompt_short
                        scene["duration"] = 5
                    except Exception as e2:
                        bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª —É–ø–∞–ª–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ: {e2}")
                        _log_fail(uid, "runway_4xx_fallback_failed",
                                  {"scene": scene_key, "prompt_len": len(prompt)}, str(e2))
                        continue
                else:
                    bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª —É–ø–∞–ª–∞ —Å –æ—à–∏–±–∫–æ–π: {e}")
                    _log_fail(uid, "runway_start_failed",
                              {"scene": scene_key, "prompt_len": len(prompt)}, str(e))
                    continue
            task_id = start_resp.get("id") or start_resp.get("task", {}).get("id")
            if not task_id:
                bot.send_message(uid, f"–ù–µ –ø–æ–ª—É—á–∏–ª id –∑–∞–¥–∞—á–∏ –æ—Ç Runway –¥–ª—è ¬´{scene_key}¬ª. –ü—Ä–æ–ø—É—Å–∫–∞—é.")
                _log_fail(uid, "no_task_id", {"scene": scene_key, "prompt_len": len(prompt)}, start_resp)
                continue

            poll = runway_poll(task_id)
            if poll.get("status") != "SUCCEEDED":
                msg = (f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª –Ω–µ —É–¥–∞–ª–∞—Å—å: {poll.get('status')}. "
                       f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–æ–Ω –∏–ª–∏ —Ñ–æ—Ä–º–∞—Ç ¬´üßç –í —Ä–æ—Å—Ç¬ª, –∏ —Ñ–æ—Ç–æ, –≥–¥–µ —á–µ–ª–æ–≤–µ–∫(–∏) –≤–∏–¥–Ω—ã —Ü–µ–ª–∏–∫–æ–º.")
                bot.send_message(uid, msg)
                _log_fail(uid, "poll_failed", {"scene": scene_key, "prompt_len": len(prompt)}, poll)
                continue

            out = poll.get("output") or []
            url = out[0] if isinstance(out[0], str) else (out[0].get("url") if out else None)
            if not url:
                bot.send_message(uid, f"Runway –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É –¥–ª—è ¬´{scene_key}¬ª.")
                _log_fail(uid, "no_url", {"scene": scene_key}, poll)
                continue

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            save_as = f"renders/{uid}_{timestamp}_{uuid.uuid4().hex}.mp4"
            download(url, save_as)
            out_videos.append(save_as)

        except Exception as e:
            bot.send_message(uid, f"–°—Ü–µ–Ω–∞ ¬´{scene_key}¬ª —É–ø–∞–ª–∞ —Å –æ—à–∏–±–∫–æ–π: {e}")
            continue

    if not out_videos:
        bot.send_message(uid, "–ù–∏ –æ–¥–Ω–∞ —Å—Ü–µ–Ω–∞ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ç–æ.")
        users[uid] = new_state()
        show_main_menu(uid)
        return

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    final_path = f"renders/{uid}_{timestamp}_{uuid.uuid4().hex}_FINAL.mp4"
    title_text = "Memory Forever ‚Äî –ü–∞–º—è—Ç—å –Ω–∞–≤—Å–µ–≥–¥–∞ —Å –≤–∞–º–∏"
    # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ ffmpeg: —Å–∫–ª–µ–π–∫–∞ + –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫ + –º—É–∑—ã–∫–∞ + —Ç–∏—Ç—Ä
    try:
        postprocess_concat_ffmpeg(out_videos, music_path, title_text, final_path, bg_overlay_file=bg_file)
    except Exception as e:
        print(f"Postprocess error: {e}")
        bot.send_message(uid, f"–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å ({e}). –®–ª—é —Å—ã—Ä—ã–µ —Å—Ü–µ–Ω—ã –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏.")
        for i, p in enumerate(out_videos, 1):
            with open(p,"rb") as f: 
                bot.send_video(uid, f, caption=f"–°—Ü–µ–Ω–∞ {i}")

        cleanup_artifacts(keep_last=10)
        # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –ø–æ–∫–∞–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
        users[uid] = new_state()
        show_main_menu(uid, "–ì–æ—Ç–æ–≤–æ! –í–∏–¥–µ–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã (–ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å).")
        return

    with open(final_path,"rb") as f:
        cap = " ¬∑ ".join(st["scenes"]) + f" ¬∑ {st['format']}"
        bot.send_video(uid, f, caption=cap)

    cleanup_artifacts(keep_last=10)
    # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –ø–æ–∫–∞–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
    users[uid] = new_state()
    show_main_menu(uid, "–ì–æ—Ç–æ–≤–æ! –í–∏–¥–µ–æ —Å–æ–∑–¥–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ.")

# ---------- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò CALLBACK-–ö–ù–û–ü–û–ö –ú–£–ó–´–ö–ò ----------
@bot.callback_query_handler(func=lambda call: call.data.startswith("listen_"))
def on_music_listen(call):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è –º—É–∑—ã–∫–∏"""
    uid = call.from_user.id
    music_name = call.data.replace("listen_", "")
    music_path = find_music_by_name(music_name)

    if music_path and os.path.isfile(music_path):
        try:
            with open(music_path, 'rb') as audio:
                bot.send_audio(uid, audio, title=music_name, performer="Memory Forever")
            bot.answer_callback_query(call.id, f"üéß –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è: {music_name}")
        except Exception as e:
            bot.answer_callback_query(call.id, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞—É–¥–∏–æ: {e}")
    else:
        bot.answer_callback_query(call.id, "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

@bot.callback_query_handler(func=lambda call: call.data.startswith("select_music_"))
def on_music_select(call):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º—É–∑—ã–∫–∏"""
    uid = call.from_user.id
    st = users.setdefault(uid, new_state())

    music_choice = call.data.replace("select_music_", "")

    if music_choice == "none":
        st["music"] = None
        bot.answer_callback_query(call.id, "üîá –í—ã–±—Ä–∞–Ω–æ: –ë–µ–∑ –º—É–∑—ã–∫–∏")
    else:
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–ª–Ω–æ–µ –∏–º—è –º—É–∑—ã–∫–∏ —Å —ç–º–æ–¥–∑–∏
        full_name = None
        for key in MUSIC.keys():
            if key.replace("üéµ ", "") == music_choice:
                full_name = key
                break

        if full_name:
            st["music"] = full_name
            bot.answer_callback_query(call.id, f"‚úÖ –í—ã–±—Ä–∞–Ω–æ: {music_choice}")
        else:
            bot.answer_callback_query(call.id, "–ú—É–∑—ã–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

    # –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É
    if not st["scenes"]:
        bot.send_message(uid, "–û—à–∏–±–∫–∞: –Ω–µ –≤—ã–±—Ä–∞–Ω—ã —Å—é–∂–µ—Ç—ã. –ù–∞—á–Ω–∏—Ç–µ —Å /start")
        return

    need_people = max(SCENES[k]["people"] for k in st["scenes"])
    bot.send_message(uid, f"–®–∞–≥ 5/5. –ü—Ä–∏—à–ª–∏—Ç–µ {need_people} —Ñ–æ—Ç–æ (–∞–Ω—Ñ–∞—Å).")

@bot.callback_query_handler(func=lambda call: call.data == "go_home")
def on_go_home_callback(call):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–∫–∏ '–í –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é' –∏–∑ inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã"""
    uid = call.from_user.id
    bot.answer_callback_query(call.id, "üè† –ü–µ—Ä–µ—Ö–æ–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é")
    show_main_menu(uid)

@bot.message_handler(func=lambda msg: True, content_types=["text"])
def fallback_text(m: telebot.types.Message):
    uid = m.from_user.id
    st = users.setdefault(uid, new_state())

    # –ï—Å–ª–∏ –∂–¥—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ ‚Äî –ø–µ—Ä–µ—Å—ã–ª–∞–µ–º –∞–¥–º–∏–Ω—É –∏ –≤—ã—Ö–æ–¥–∏–º –≤ –º–µ–Ω—é
    if st.get("support"):
        if ADMIN_CHAT_ID:
            # —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ñ–æ—Ä–≤–∞—Ä–¥
            ok = True
            try:
                bot.forward_message(int(ADMIN_CHAT_ID), uid, m.message_id)
            except Exception:
                ok = False
            # –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ñ–æ—Ä–≤–∞—Ä–¥–æ–º ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
            if not ok:
                uname = (m.from_user.username or "")
                header = f"–°–æ–æ–±—â–µ–Ω–∏–µ –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –æ—Ç @{uname} (id {uid}):"
                bot.send_message(int(ADMIN_CHAT_ID), f"{header}\n\n{m.text}")
        else:
            bot.send_message(uid, "–ê–¥—Ä–µ—Å –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –£–∫–∞–∂–∏—Ç–µ ADMIN_CHAT_ID –≤ Secrets.")

        st["support"] = False
        show_main_menu(uid, "–°–ø–∞—Å–∏–±–æ! –°–æ–æ–±—â–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–Ω–æ. –ú—ã —Å–≤—è–∂–µ–º—Å—è —Å –≤–∞–º–∏.")
        return

    # –ò–Ω–∞—á–µ ‚Äî –≤–µ–∂–ª–∏–≤—ã–π –Ω–∞–º—ë–∫, —á—Ç–æ –Ω–∞–¥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–Ω–æ–ø–∫–∞–º–∏
    # (–Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–º–∞–µ–º, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ–Ω—é)
    show_main_menu(uid, "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ.")

# ---------- RUN ----------
if __name__ == "__main__":
    print("Memory Forever v0.3 started.")
    bot.infinity_polling(skip_pending=True, timeout=60) 
